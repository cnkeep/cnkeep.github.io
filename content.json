[{"title":"Redis数据结构之string_01","date":"2019-02-12T18:18:00.000Z","path":"2019/02/13/02-Redis数据结构之string_01/","text":"Redis数据结构之string 标签：Redis 前言在redis的各种数据结构中，使用最多的就是字符串类型了，本节就针对其常见的使用命令和实现原理做介绍。 命令使用示例set将键key设定为指定的字符串的值，如果key已经保存了一个值，那么这个操作会直接覆盖原来的饿值，并且会忽略原始类型。当set命令执行成功后，之前设置的过期时间将会失效。 选项1234567命令格式：set &lt;key&gt; &lt;value&gt; [EX &lt;seconds&gt;|PX &lt;milliseconds&gt;] [NX|XX]返回值： OK 或者 nil时间复杂度：O(1)EX seconds – 设置键key的过期时间，单位时秒PX milliseconds – 设置键key的过期时间，单位时毫秒NX – 只有键key不存在的时候才会设置key的值XX – 只有键key存在的时候才会设置key的值 示例1234redis&gt; SET mykey &quot;Hello&quot;OKredis&gt; GET mykey&quot;Hello&quot; get返回key的value，如果key不存在，返回特殊值nil。如果key的value不是string，就返回错误，因为get只能处理字符串类型的values。 超时设置 ttl &lt;key&gt;:返回指定键的剩余有效期，单位:秒。格式：ttl &lt;key&gt;返回值：-1：没有设置超时，永久有效；-2：不存在的key；其他：剩余有效期 expire &lt;key&gt; &lt;seconds&gt;设置指定键的有效期，单位：秒。返回值：1：成功；0：失败； pexpire &lt;key&gt; &lt;millisecond&gt;设置指定键的有效期，单位：毫秒。返回值：1：成功；0：失败； 其他命令 mset &lt;key1&gt; &lt;value1&gt; &lt;key2&gt; &lt;value2&gt;.... : 批量的设置键值 mget &lt;key1&gt; &lt;keky2&gt;: 批量的获取键值 incr &lt;key&gt;: 针对数值类型的执行原子加1操作，键不存在时则新建，返回执行加法后的值 incrby &lt;key&gt; &lt;increment&gt;: 针对数值类型执行原子的加法操作 decr &lt;key&gt;: 针对数值类型的执行原子减1操作，键不存在时则新建，返回执行减法后的值 decrby &lt;key&gt; &lt;increment&gt;: 针对数值类型执行原子的减法操作 strlen &lt;key&gt;: 返回key的string类型的value的字节长度。时间复杂度为O(1)。返回值：0：key不存在；其他：value的字节长度 实现原理Redis的字符串没有直接使用C语言传统的字符串表示，而是使用一个SDS(simple dynamic string)的结构来表示字符串。此外字符串会根据不同的长度选择不同的存储形式，当长度小于44时使用embstr格式存储，当长度大于44时使用raw格式存储，但是总长度不超过512M。 123456789127.0.0.1:6379&gt; set key 0123456789012345678901234567890123456789OK127.0.0.1:6379&gt; debug object keyValue at:0x233bff8 refcount:1 encoding:embstr serializedlength:21 lru:13421705 lru_seconds_idle:4127.0.0.1:6379&gt; set key 012345678901234567890123456789012345678901234567890123456789OK127.0.0.1:6379&gt; debug object keyValue at:0x23cf0c8 refcount:1 encoding:raw serializedlength:21 lru:13421732 lru_seconds_idle:3 使用debug object &lt;key&gt;命令查看encoding字段，可以观察到编码存储方式不同。 数据结构Redis的字符串数据结构为SDS, 它是一个带长度的字节数组，这样就避免了求长度需要每次遍历的问题，从而可以直接获取长度信息。 123456struct SDS&lt;T&gt; &#123; T capacity; // 数组容量 T len; // 数组长度 byte flags; // 标识位 byte[] content; // 数组内容&#125; 当我们存储一个redis对象时，它的内存结构如下所示: +-------------+ | capacity | +-------------+ | len | +-------------+ | flag | +-------------+ +-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | content | ---&gt; | r | e | d | i | s | \\0 | | | | | +-------------+ +-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ 内存分配策略在C语言字符串中，每次对字符串的修改都会影响到内存的分配。如果增长字符串，则会为字符串重新分配一个新的内存空间。如果减少字符串，则会对减少的内存空间做内存回收，否则会引起内存泄漏。那么SDS是如何减少内存分配的呢？ 是通过空间的预分配和惰性空间释放来完成的。 空间的预分配当SDS的API对一个SDS进行修改，并且需要扩展空间的时候，不仅会对SDS分配所需要的空间，还会为SDS分配额外的未使用空间。这个未使用空间的长度则记录在free属性中。这个预分配空间的策略根据SDS的长度决定。 当SDS小于1MB的时候。每次扩容长度则跟len相同。举一个例子如果一个SDS扩容为12个字节，那么 SDS函数将会再添加一个12字节的预分配长度。既 len=12 free=12 buf长度则为25字节 （多出来的1个是结束符”0”） 当SDS大于1MB的时候，每次预分配长度则为1MB。相当于如果这个SDS是10MB，那么每次扩容之后的free的长度回是1MB 惰性空间释放当一个SDS字符串缩短操作时，程序并不会马上重新收回多余出来的内容，而是用free字段将这些空余的空间记录下来。当下次如果需要往SDS添加字符，则可以再次使用这些空余空间, 这样就避免的频繁的创建回收内存，可以直接覆盖原有的部分即可。当然也不是意味着永远不会被回收，SDS有API来释放这些内存空间。 SDS优势与C语言字符串相比，SDS具有下列优势： O(1)时间复杂度的获取字符串的长度。 杜绝缓冲区溢出，每次对SDS字符串修改之前都会去判断字符串的容量是否足够。如果不够则会扩充SDS的内存大小。 通过空间预分配和惰性空间释放减少字符串修改带来的内存分配次数 二进制安全，无需特殊格式保存格式(C语言结束必须是’\\0’) 自此Redis的字符串类型数据结构就讨论完了，当然本文存在很多不存，以及没有分析到的地方，还请见谅！","tags":[{"name":"Redis","slug":"Redis","permalink":"https://cnkeep.github.io/tags/Redis/"}]},{"title":"Redis介绍与使用场景","date":"2019-02-12T17:02:00.000Z","path":"2019/02/13/01-Redis介绍与使用场景/","text":"Redis介绍与使用场景 标签：Redis Redis介绍 &nbsp;&nbsp;Redis是当前最火的Nosql系统之一，它是由Salvatore Sanfilippo开发的一个开源的key-存储系统。它以其高性能，丰富的数据结构成为当前最火的NoSql数据库。 它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets），有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询。Redis 内置了 复制（replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（transactions）和不同级别的 磁盘持久化（persistence）， 并通过 Redis哨兵（Sentinel）和自动 分区（Cluster）提供高可用性（high availability）。 使用场景Redis的业务应用范围十分广泛，我们这里只列举常见的几种： 缓存Redis作为一个key-value的内存存储系统，使用最多的当然是存储能力，所以使用最多的还是在缓存方面。各种丰富的数据类型几乎能满足我们的缓存需求，再加上支持超时设置，灵活的过期策略，支持集群分布式，高可用，这就使得其更适合应用在缓存领域。 分布式锁 在很多互联网公司中都使用了分布式技术，分布式技术带来的技术挑战是对同一个资源的并发访问，如全局ID、减库存、秒杀等场景，并发量不大的场景 可以使用数据库的悲观锁、乐观锁来实现，但在并发量高的场合中，利用数据库锁来控制资源的并发访问是不太理想的，大大影响了数据库的性能。 可以利用Redis的setnx功能来编写分布式的锁，如果设置返回1说明获取锁成功，否则获取锁失败，实际应用中要考虑的细节要更多(参看：Redisson)。 分布式会话传统的单机基于session的会话机制在分布式的系统中已经无法适用，所以需要将session抽离存储在外部的存储系统中，Redis的高性能就很符合，这样session就能在多个系统和应用之间共享，session不再由容器管理而是由session服务和redis管理(有兴趣可以了解: Spring-session+Redis实现Session共享)。当然更好的方式是让各个子系统是无状态的，利用token机制完成认证和身份识别，这里不做讨论。 计数器什么是计数器，如电商网站商品的浏览量、视频网站视频的播放数等。为了保证数据实时效，每次浏览都得给+1，并发量高时如果每次都请求数据库操作无疑是种挑战和压力。Redis提供的incr命令来实现计数器功能，内存操作，性能非常好，非常适用于这些计数场景。而且Redis的单线程模型天然的线程安全，无需其他的并发处理。 排行榜很多网站都有排行榜应用的，如京东的月度销量榜单、商品按时间的上新排行榜等。Redis提供的有序集合数据类构能实现各种复杂的排行榜应用。 社交网络点赞、踩、关注/被关注、共同好友等是社交网站的基本功能，社交网站的访问量通常来说比较大，而且传统的关系数据库类型不适合存储这种类型的数据，Redis提供的哈希、集合等数据结构能很方便的的实现这些功能。 简单的消息队列消息队列是大型网站必用中间件，如ActiveMQ、RabbitMQ、Kafka等流行的消息队列中间件，主要用于业务解耦、流量削峰及异步处理实时性低的业务。Redis提供了发布/订阅及阻塞队列功能，能实现一个简单的消息队列系统。注意这里是简单的消息队列，因为Redis的发布订阅模型不保证消息的消费。","tags":[{"name":"Redis","slug":"Redis","permalink":"https://cnkeep.github.io/tags/Redis/"}]},{"title":"Redis之pipeline批量处理","date":"2019-02-12T16:01:00.000Z","path":"2019/02/13/11-Redis之pipeline批量处理/","text":"Redis之Pipeline批量处理 标签：Redis, pipeline 介绍pipeline(管道)是Redis提供的一种批量操作的技术，类位于数据库的批量操作，主要目的是为了减少网络传输的消耗。 pipeline当我们使用客户端对Redis进行一次操作都会经历下面几个步骤： 客户端提交请求 请求消息网络传输 服务端接收请求 服务端处理请求，并返回响应 响应消息网络传输 客户端接收响应 如下图所示：12345+----------+ +----------+| | ----request--&gt; | || client | | redis || | &lt;--response--- | |+----------+ +----------+ 想象一下，如果多个操作的话就是多次网络传输，这样在大量相同操作时是及其耗费资源的，因此我们可以将多个命令打包成一次请求这样就节省了多次网络传输的I/O消耗，pipeline正是在客户端做了这样的操作，来实现提高性能的。 pipeline测试 接下来我们实践一下管道的力量。Redis 自带了一个压力测试工具redis-benchmark，使用这个工具就可以进行管道测试。首先我们对一个普通的 set 指令进行压测，QPS 大约 5w/s。12&gt; redis-benchmark -t set -qSET: 51975.05 requests per second 我们加入管道选项-P参数，它表示单个管道内并行的请求数量，看下面P=2，QPS 达到了 9w/s。12&gt; redis-benchmark -t set -P 2 -qSET: 91240.88 requests per second 再看看P=3，QPS 达到了 10w/s。SET: 102354.15 requests per second但如果再继续提升 P 参数，发现 QPS 已经上不去了。这是为什么呢？因为这里 CPU 处理能力已经达到了瓶颈，Redis 的单线程 CPU 已经飙到了 100%，所以无法再继续提升了。 总结pipeline是客户端相关的技术，旨在减少网络传输的消耗，将多个命令合并为一次网络传输请求，可以通过redis-benchmark工具测试。","tags":[{"name":"Redis","slug":"Redis","permalink":"https://cnkeep.github.io/tags/Redis/"}]},{"title":"Redis数据结构之集合Set","date":"2019-02-12T15:46:00.000Z","path":"2019/02/12/05-Redis数据结构之集合Set/","text":"Redis数据集合之Set 标签：Redis, Set 前言Redis的集合Set是一种无序集合，集合成员是唯一的，这就意味着集合中不能出现重复的数据，可以用作数据统计。 Redis中集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。集合的最大容量是2^32-1。 此外Redis还提供了交集，并集等集合运算，非常适合社交网络复杂的场景。 常用命令 sadd &lt;key&gt; &lt;member1&gt; [member2...]功能：向集合添加一个或多个成员返回值：被添加到集合中的新元素的数量，不包括被忽略的元素时间复杂度：O(1) smembers &lt;key&gt;功能：返回集合中所有的元素，线上慎用返回值：所有元素列表时间复杂度：O(n) srem &lt;key&gt; &lt;member1&gt; [member2]功能：移除集合中一个或多个成员返回值：被成功移除的元素个数，不包括被忽略的元素时间复杂度：O(n) scard &lt;key&gt;功能：获取集合的元素数量返回值：0：key不存在；其他：集合元素数量时间复杂度：O(1) sismember &lt;key&gt; &lt;member&gt;功能：判断集合内是否存在该元素返回值：1：存在；0：不存在时间复杂度：O(1) smove &lt;sourceKey&gt; &lt;destinationKey&gt; &lt;member&gt;功能：将member 元素从 source 集合移动到 destination集合时间复杂度：O(1) sdiff &lt;key1&gt; [key2...]功能：返回给定所有集合的差集时间复杂度：O(n) sdiffstore &lt;destination&gt; &lt;key1&gt; [key2]功能：返回给定所有集合的差集并存储在 destination 中时间复杂度：O(n) sinter &lt;key1&gt; [key2...]功能：返回给定所有集合的交集时间复杂度：O(n) sinterstore &lt;destination&gt; &lt;key1&gt; [key2]功能：返回给定所有集合的交集并存储在 destination 中时间复杂度：O(n) sunion &lt;key1&gt; [key2...]功能：返回所有给定集合的并集时间复杂度：O(n) sunionstore &lt;destination&gt; &lt;key1&gt; [key2...]功能：所有给定集合的并集存储在 destination 集合中时间复杂度：O(n) sscan &lt;key&gt; cursor [MATCH pattern] [COUNT count]功能：迭代集合中的元素，推荐使用 数据结构 无序集合Set底层通过哈希表实现，哈希表上一篇已经分析过，所以这里不再分析集合的实现。","tags":[{"name":"Redis","slug":"Redis","permalink":"https://cnkeep.github.io/tags/Redis/"}]},{"title":"Redis通讯协议","date":"2019-02-11T17:24:00.000Z","path":"2019/02/12/09-Redis通讯协议/","text":"Redis通讯协议介绍Redis作为一个client-server的应用，我们可能会好奇其通讯协议是否为了追求性能也做了十分复杂的设计，如果你这样想，那你估计要失望了。 Redis使用了一种纯文本的通讯协议-RESP(Redis Serialization Protocol)而且存在大量换行符，它是在一下三个目标之间进行了折中： 易于实现 可以高效的被计算机分析 可以很容易的被人类读懂，便于调试 RESP介绍服务端 -&gt; 客户端Redis将回复的传输协议分为以下几种最小单元类型，每种单元类型都以回车换行符(\\r\\n)结束： 单行字符串格式：正常返回状态信息以+开始，例如常见的+OK示例： 1234567891011121314151617181920 +OK ``` * `错误状态` 格式：错误状态信息以`-`开头 示例： ```text -(error) ERR wrong number of arguments for &apos;keys&apos; command ``` * `多行字符` 格式：多行字符以`$`开头，后跟字符串长度，下一行为字符串内容 示例： ```text $5\\r\\n value\\r\\n ``` * `数值` 格式：整数类型以`:`开头，后跟整数的字符串形式 示例： ```text :2 数组格式：数组以*开头，后跟数组长度示例： 12345678910111213141516171819 *2\\r\\n $3\\r\\n key\\r\\n $5\\r\\n value\\r\\n ``` &gt; 注意：以上示例中为了方便阅读，采用了人为分行，实际中不存在分行 ### 客户端 -&gt; 服务端 客户端到服务端只有一种形式，就是数组类型：```text//set key value*3\\r\\n$3\\r\\nset\\r\\n$3\\r\\nkey\\r\\n$5\\r\\nvalue\\r\\n 这里用一张网上的图示表示如下：","tags":[{"name":"Redis","slug":"Redis","permalink":"https://cnkeep.github.io/tags/Redis/"}]},{"title":"Redis数据结构之有序集合ZSet","date":"2019-02-11T16:48:00.000Z","path":"2019/02/12/06-Redis数据结构之有序集合ZSet/","text":"Redis数据结构之有序集合ZSET 标签：Redis, Zset, SkipList转载：Redis内部数据结构详解(6)——skiplist 前言Redis的zset是一个有序的集合，其内部元素按照顺序排列且不重复(score可以重复)，这种特性让我们在实现排行榜功能时得心应手。 说道有序的集合这很容易让我们联想到Java中的TreeSet数据结构, 使用TreeMap来实现，其底层是一个采用红黑树存储的数据结构，但是红黑树的复杂旋转却让我们望而却步，Redis作者提供了另外一种跳跃表(SkipList)来实现，其处理简单而且性能与红黑树没有太大差别。 接下类我们就一起学习一下Redis有序集合的常用API和实现原理。 常用命令 zadd &lt;key&gt; [NX|XX] [ch] [incr] &lt;score&gt; &lt;member&gt; [&lt;score&gt; &lt;member&gt;...]功能：将所有指定成员添加到键为key的有序集合中，添加时可以指定多个分数成员(score/member)对.如果添加的成员已经是有序集合里面的成员，则会更新该成员的分数(score)并更新到正确的排序配置。参数选项： XX:仅仅更新存在的成员，不添加新成员 NX:不更新存在的成员，只添加新成员 CH:修改返回值为发生变化的成员总数，不指定时返回新添加成员的总数 incr:当zadd指定这个选项时，针对成员的分数进行递增操作 zincrby &lt;key&gt; &lt;score&gt; &lt;member&gt;功能：将指定元素的score值增加返回值：新的score值时间复杂度：O(1) zrange &lt;key&gt; &lt;startIndex&gt; &lt;stopIndex&gt; [withscores]功能：返回存储在有序集合中的指定范围的元素，返回的元素按照score正序排列，如果score相同将按照字典排序。参数选项： startIndex,stopIndex:起始和结束的索引，0是第一个元素，1是第二个元素，也可以是是负数，-1代表最后一个元素(返回所有元素：zrange key 0 -1) withscores:是否同时输出score值，输出结果将是value占一行，紧接着score占一行时间复杂度：O(log(N)+M) zrank &lt;key&gt; &lt;member&gt;功能：返回有序集合中成员member的排名其中有序集成员按score值递增(从小到大)顺序排列。排名以0为底，也就是说，score值最小的成员排名为0。zrevrank为倒序返回值：nil:不存在；其他：排名时间复杂度：O(log(N)) zscore &lt;key&gt; &lt;member&gt;功能：返回集合中指定元素的score值返回值：nil:不存在；其他：score值时间复杂度：O(1) zcard &lt;key&gt;功能：返回有序集合的元素个数返回值：0：不存在；其他：元素个数时间复杂度：O(1) zcount &lt;key&gt; &lt;minScore&gt; &lt;maxScore&gt;功能：返回集合中score在minscore到maxScore之间的元素个数返回值：元素个数时间复杂度：O(log(N)) zrangebylex &lt;key&gt; &lt;minMember&gt; &lt;maxMember&gt; [limit offset count]功能：返回指定元素区间范围内的元素列表，正序输出。zrevrangelex为倒序参数选项： minMember, maxMember：最小，最大元素，该参数必须包含(或者[, 其中(表示开区间，表示[闭区间，也可以直接使用特殊值：-,+, -代表负无穷，+代表正无穷 limit offset count：该选项为可选值，表示结果分页，offset为返回分页下标，count为数量 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119 127.0.0.1:6379&gt; zadd rankList 1 user_1 4 user_4 8 user_8 5 user_5 (integer) 4 127.0.0.1:6379&gt; zadd rankList 6 user_6 10 user_10 (integer) 2 127.0.0.1:6379&gt; zrange rankList 0 -1 1) &quot;user_1&quot; 2) &quot;user_4&quot; 3) &quot;user_5&quot; 4) &quot;user_6&quot; 5) &quot;user_8&quot; 6) &quot;user_10&quot; 127.0.0.1:6379&gt; zrange rankList 0 -1 1) &quot;user_1&quot; 2) &quot;user_4&quot; 3) &quot;user_5&quot; 4) &quot;user_6&quot; 5) &quot;user_8&quot; 6) &quot;user_10&quot; 127.0.0.1:6379&gt; zrangebylex rankList - + 1) &quot;user_1&quot; 2) &quot;user_4&quot; 3) &quot;user_5&quot; 4) &quot;user_6&quot; 5) &quot;user_8&quot; 6) &quot;user_10&quot; 127.0.0.1:6379&gt; zrangebylex rankList - + limit 0 3 1) &quot;user_1&quot; 2) &quot;user_4&quot; 3) &quot;user_5&quot; 127.0.0.1:6379&gt; zrangebylex rankList - (user_5 1) &quot;user_1&quot; 2) &quot;user_4&quot; 127.0.0.1:6379&gt; zrangebylex rankList (user_1 (user_5 1) &quot;user_4&quot; 127.0.0.1:6379&gt; zrangebylex rankList [user_1 (user_5 1) &quot;user_1&quot; 2) &quot;user_4&quot; ``` + `zrangebyscore &lt;key&gt; &lt;minScore&gt; &lt;maxScore&gt; [withscores] [limit offset count]` 功能：与zrangebylex不同的是该命令是返回指定score区间内的元素列表 + `zrem &lt;key&gt; &lt;member&gt; [&lt;member&gt;...]` 功能：移除指定元素 返回值：返回删除成功的元素个数，不包含不存在的元素 + `zpopmax/zpopmin &lt;key&gt;` 功能：返回并移除最大score的元素 ## 数据结构 zset是一个复合结构，一方面为了快速的获取指定value的score,一方面为了支持score排序，所以Redis做了这样的实现： - 当数据较少时，sorted set是由一个ziplist来实现 - 当数据较多时(该数值可以进行配置)，采用了hash+skiplist(跳跃表)的复合结构来存储数据。 ![](images/zset_001.png) ### 跳跃表的实现 跳跃表是一种通过链表和记录层级来规避红黑树，但比红黑树实现更简单的数据结构，Redis中只在两个地方用到了跳跃表，一个是实现有序集合，另一个是集群节点中用作内部数据结构。 skiplist, 它是一个list，它是在有序链表的基础上发展起来的。 我们先来看一个有序链表，如下图（最左侧的灰色节点表示一个空的头结点）: ![](images/skiplist_003.png) 在这样一个链表中，如果我们要查找某个数据，那么需要从头开始逐个进行比较，直到找到包含数据的那个节点，或者找到第一个比给定数据大的节点为止（没找到）。也就是说，时间复杂度为O(n)。同样，当我们要插入新数据的时候，也要经历同样的查找过程，从而确定插入位置。 假如我们每相邻两个节点增加一个指针，让指针指向下下个节点，如下图 ![](images/skiplist_004.png) 这样所有新增加的指针连成了一个新的链表，但它包含的节点个数只有原来的一半（上图中是7, 19, 26）。现在当我们想查找数据的时候，可以先沿着这个新链表进行查找。当碰到比待查数据大的节点时，再回到原来的链表中进行查找。比如，我们想查找23，查找的路径是沿着下图中标红的指针所指向的方向进行的： ![](images/skiplist_005.png) + 23首先和7比较，再和19比较，比它们都大，继续向后比较。 + 但23和26比较的时候，比26要小，因此回到下面的链表（原链表），与22比较。 + 23比22要大，沿下面的指针继续向后和26比较。23比26小，说明待查数据23在原链表中不存在，而且它的插入位置应该在22和26之间 在这个查找过程中，由于新增加的指针，我们不再需要与链表中每个节点逐个进行比较了。需要比较的节点数大概只有原来的一半。 利用同样的方式，我们可以在上层新产生的链表上，继续为每相邻的两个节点增加一个指针，从而产生第三层链表。如下图： ![](images/skiplist_006.png) 在这个新的三层链表结构上，如果我们还是查找23，那么沿着最上层链表首先要比较的是19，发现23比19大，接下来我们就知道只需要到19的后面去继续查找，从而一下子跳过了19前面的所有节点。可以想象，当链表足够长的时候，这种多层链表的查找方式能让我们跳过很多下层节点，大大加快查找的速度。 skiplist正是受这种多层链表的想法的启发而设计出来的。实际上，按照上面生成链表的方式，上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到O(log n)。但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的2:1的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）重新进行调整，这会让时间复杂度重新蜕化成O(n)。删除数据也有同样的问题。 skiplist为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是为每个节点随机出一个层数(level)。比如，一个节点随机出的层数是3，那么就把它链入到第1层到第3层这三层链表中。为了表达清楚，下图展示了如何通过一步步的插入操作从而形成一个skiplist的过程： ![](images/skiplist_007.png) 从上面skiplist的创建和插入过程可以看出，每一个节点的层数（level）是随机出来的，而且新插入一个节点不会影响其它节点的层数。因此，插入操作只需要修改插入节点前后的指针，而不需要对很多节点都进行调整。这就降低了插入操作的复杂度。实际上，这是skiplist的一个很重要的特性，这让它在插入性能上明显优于平衡树的方案。 刚刚创建的这个skiplist总共包含4层链表，现在假设我们在它里面依然查找23，下图给出了查找路径： ![](images/skiplist_008.png) 需要指出的是，执行插入操作时计算随机层数的过程，是一个很关键的过程，它对skiplist的统计特性有着很重要的影响。这并不是一个普通的服从均匀分布的随机数，它的计算过程如下： * 首先，每个节点肯定都有第1层指针（每个节点都在第1层链表里）。 * 如果一个节点有第i层(i&gt;=1)指针（即节点已经在第1层到第i层链表中），那么它有第(i+1)层指针的概率为p。 * 节点最大的层数不允许超过一个最大值，记为MaxLevel。 实现伪代码如下： ```textrandomLevel() &#123; level := 1 // random()返回一个[0...1)的随机数 while random() &lt; p and level &lt; MaxLevel do level := level + 1 return level&#125; 在Redis的skiplist实现中，p=1/4, MaxLevel=32 Redis改进的跳跃表传统skiplist不能满足的情况上面提到的SkipList并不能完全满足redis有序集合的所有操作，考虑下列这几种情况： zrevrank由数据查询它对应的排名，这在前面介绍的skiplist中并不支持。 zscore由数据查询它对应的分数，这也不是skiplist所支持的。 zrevrange根据一个排名范围，查询排名在这个范围内的数据。这在前面介绍的skiplist中也不支持。 zrevrangebyscore根据分数区间查询数据集合，是一个skiplist所支持的典型的范围查找（score相当于key）。 Redis针对skiplist的优化为了达到上面的几种处理效果，Redis做了如下处理： 当数据较少时，sorted set是由一个ziplist来实现的。 当数据多的时候，sorted set是由一个dict + 一个skiplist来实现的。简单来讲，dict用来查询数据到分数的对应关系，而skiplist用来根据分数查询数据（可能是范围查找）。 zscore的查询，不是由skiplist来提供的，而是由那个dict来提供的。 为了支持排名(rank)，Redis里对skiplist做了扩展，为每个节点增加了跨度的属性，使得根据排名能够快速查到数据，或者根据分数查到数据之后，也同时很容易获得排名。而且，根据排名的查找，时间复杂度也为O(log n)。 zrevrange的查询，是根据排名查数据，由扩展后的skiplist来提供。 zrevrank是先在dict中由数据查到分数，再拿分数到skiplist中去查找，查到后也同时获得了排名。 Redis中zset的数据结构定义 123456789101112131415161718192021222324252627//from sever.h ,version=4.0.10#define ZSKIPLIST_MAXLEVEL 32 /* Should be enough for 2^32 elements */#define ZSKIPLIST_P 0.25 /* Skiplist P = 1/4 */typedef struct zskiplistNode &#123; sds ele; double score; struct zskiplistNode *backward; //层级节点数组 struct zskiplistLevel &#123; struct zskiplistNode *forward; unsigned int span;// 跨度 &#125; level[];&#125; zskiplistNode;typedef struct zskiplist &#123; struct zskiplistNode *header; struct zskiplistNode *tail; unsigned long length; //元素数量 int level; //层级数&#125; zskiplist;typedef struct zset &#123; dict *dict; zskiplist *zsl;&#125; zset; 这段代码出自server.h，我们来简要分析一下： 开头定义了两个常量，ZSKIPLIST_MAXLEVEL和ZSKIPLIST_P，分别对应我们前面讲到的skiplist的两个参数：一个是MaxLevel，一个是p。 zskiplistNode定义了skiplist的节点结构 ele存放节点数据 score字段存储数据对应的排序值 backward字段是指向链表前一个节点的指针（前向指针）。节点只有1个前向指针，所以只有第1层链表是一个双向链表。 level[]存放指向各层链表后一个节点的指针（后向指针）。每层对应1个后向指针，用forward字段表示。另外，每个后向指针还对应了一个span值，它表示当前的指针跨越了多少个节点。span用于计算元素排名(rank)，这正是Redis对于skiplist所做的一个扩展。 zskiplist定义了真正的skiplist结构 头指针header和尾指针tail 链表长度length，即链表包含的节点总数。注意，新创建的skiplist包含一个空的头指针，这个头指针不包含在length计数中 level表示skiplist的总层数，即所有节点层数的最大值 下图以前面插入的代数课成绩表为例，展示了Redis中一个skiplist的可能结构： 注意：图中前向指针上面括号中的数字，表示对应的span的值。即当前指针跨越了多少个节点，这个计数不包括指针的起点节点，但包括指针的终点节点。 假设我们在这个skiplist中查找score=89.0的元素（即Bob的成绩数据），在查找路径中，我们会跨域图中标红的指针，这些指针上面的span值累加起来，就得到了Bob的排名(2+2+1)-1=4（减1是因为rank值以0起始）。需要注意这里算的是从小到大的排名，而如果要算从大到小的排名，只需要用skiplist长度减去查找路径上的span累加值，即6-(2+2+1)=1。 可见，在查找skiplist的过程中，通过累加span值的方式，我们就能很容易算出排名。相反，如果指定排名来查找数据（类似zrange和zrevrange那样），也可以不断累加span并时刻保持累加值不超过指定的排名，通过这种方式就能得到一条O(log n)的查找路径。 总结Redis有序列表的实现 当数据较少时，sorted set是由一个ziplist来实现 当数据较多时(该数值可以进行配置)，采用了hash+skiplist(跳跃表)的复合结构来存储数据。 skiplist与平衡树，哈希表的比较 skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。 在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。 平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。 从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。 查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。 从算法实现难度上来比较，skiplist比平衡树要简单得多。","tags":[{"name":"Redis","slug":"Redis","permalink":"https://cnkeep.github.io/tags/Redis/"}]},{"title":"Redis事务","date":"2019-02-11T16:12:00.000Z","path":"2019/02/12/10-Redis事务/","text":"Redis事务 标签：Redsi事务 介绍Redis也提供了事务机制，但是其事务和我们理解的传统数据库的事务ACID有所不同，本节我们就探讨一下Redis的事务。 Redis事务事务操作Redis通过multi, exec, discard, watch命令来实现事务的功能。 事务提供了一种将多个命令请求打包，然后一次性，按顺序的执行多个命令的机制，并且在事务执行的过程中，服务器不会中断事务，而是会将事务中的所有命令都执行完毕，然后再去处理其他客户端的命令请求。 事务开始到执行结束需要经历以下几个步骤： multi开始事务 命令入队列 exec提交事务/discard回滚事务 我们举个例子来看一下使用：123456789&gt; multiOK&gt; set key valueQUEUED&gt; set key1 value1QUEUED&gt; exec1) OK2) OK 事务开始执行multi命令标识着事务的开始，multi命令可以将执行该命令的客户端从是无状态切换至事务状态，这是通过在客户端状态的flags属性中代开redis_multi标识来完成的。 命令入队当一个客户端处于非事务状态时，这个客户端发送的命令会立即被服务器执行：1234567891011121314151617181920212223242526272829303132&gt; set key valueOK``` 而当客户端切换到事务状态后，服务器会根据客户端发来的不同命令执行不同的操作： * 如果客户端发送的命令为`multi`, `exec`, `discard`, `watch`，服务器会立即执行这个命令 * 如果发送的是其他的命令，则会缓存至队列中，然后返回`queued`缓存成功标示 #### 执行事务 当一个事务状态的客户端向服务器发送exec命令时，服务器会执行这个客户端的事务队列，执行队列中的所有命令，最后将执行结果返回给客户端。&gt; 值得注意的是，Redis的事务中存在2中错误，针对这两种错误，事务的执行情况不同： * 检查时异常，命令可能排队失败。如，命令的语法可能是错误 (错误的参数个数，错误的命令名字 ...)，或一些重要的环境问题，如，内存不足 * 运行时异常，当EXEC 调用后 ，一些命令可能执行失败，如，在一个字符串上进行了列表命令的操作 对于第一种错误，其发生在exec执行之前，很容易发现，可以通过命令入队的返回值如果不是QUEUED,就是失败的，这种情况，当执行exec时，Redis会直接终止事务，不做任务操作，是事务一致，原子性的。 ```text&gt; set k1 v1OK&gt; multiOK&gt; set k1 v11QUEUED&gt; set key(error) ERR wrong number of arguments for &apos;set&apos; command&gt; set k2 v2QUEUED&gt; exec(error) EXECABORT Transaction discarded because of previous errors.&gt; get k1&quot;v1&quot; 对于第二种情况，所有命令都会被执行，这是什么意思呢，就是说其中一条执行失败了，后面的命令依旧会执行，不是事务一致，原子性的,我们可以通过遍历判断最终分返回结果集来判断命令是否执行成功。 1234567891011121314151617181920212223#旧数据&gt; set k1 v1OK#事务开始&gt; multiOK&gt; set k2 v2QUEUED#错误的命令&gt; lpop k2QUEUED&gt; set k1 changeQUEUED#发现所有命令都执行了，但是结果集中存在执行失败的&gt; exec1) OK2) (error) WRONGTYPE Operation against a key holding the wrong kind of value3) OK&gt; get k1&quot;change&quot; 总结 Redis事务不保证原子性，一致性 Redis是通过缓存命令到队列，最后一次性执行来完成事务操作的 Redis事务不能进行回滚 我们可以用下图来表示: 其中红色代表事务处理，黑色代表非事务处理 拓展事务乐观锁(watch)再做事务处理时，我们希望在事务处理中数据是加锁互斥的，即执行过程中不能被修改，Mysql中有行锁，Redis中也提供了Watch命令，不过它是基于乐观锁实现的。 1234567891011121314&gt; set k1 v1OK&gt; watch k1OK&gt; set k1 v1-change-01OK&gt; multiOK&gt; set k1 v1-txQUEUED&gt; exec(nil)&gt; get k1&quot;v1-change-01&quot; 我们看到上面的例子，通过watch监听k1的值，然后在事务执行时发现k1值已经被改变，事务执行失败，注意这里是所有的命令都不会执行哦。 我们可以这样理解，watch命令会生成一份快照信息v1，当事务提交执行之前会检查当前的k1的值是否与快照一致，不一致直接返回，不执行任何命令。 Redis为什么不支持回滚我们来讨论一下Redis不支持回滚的原因： 我们来回忆一下，mysql是如何支持回滚的，是通过undo日志的，即预写式日志，在操作之前记录一份数据，这样在回滚时可以执行undo日志从而让数据库状态返回到操作前的状态。但是redis却不是这样的，它是在操作完成后才写持久化日志的，所以根源上没法回滚。 事务为什么要回滚，我想是因为程序代码的问题，所以在开发过程应当被发现，在线上环境不应该出现，所以为了保持简洁性，不支持事务回滚也是可以理解的。","tags":[{"name":"Redis","slug":"Redis","permalink":"https://cnkeep.github.io/tags/Redis/"}]},{"title":"Redis数据结构之列表","date":"2019-02-11T16:05:00.000Z","path":"2019/02/12/04-Redis数据结构之列表/","text":"Redis数据结构之列表(list) 标签：Redis, list, ziplist, linkedlist, quicklist 前言 介绍 列表(list)同样是我们常用的一种数据结构，是一种有序的、可重复的集合。 使用场景 可以作为简易的消息队列 常用命令设置值 lpush/rpush &lt;key&gt; &lt;value&gt; [&lt;value&gt; ...]功能：向存于key的列表的左边/右边插入数据，如果key不存在则创建一个空的列表，然后完成插入操作。返回值：操作后列表的长度时间复杂度：o(1) lpushx/rpushx &lt;key&gt; &lt;value&gt; [&lt;value&gt;...]功能：如果key存在，则向列表的左边/右边插入数据 linsert &lt;key&gt; &lt;before|after&gt; &lt;pivot&gt; &lt;value&gt;功能：把value插入存于key的列表中在基准值pivot的前面或后面，当key时，什么也不做。返回值：-1：pivot值不存在；其他：操作完成后的列表长度时间复杂度：O(n) lset &lt;key&gt; &lt;index&gt; &lt;value&gt;功能：设置index位置的list元素的值为value，index超出返回时返回错误返回值：成功或失败时间复杂度：O(n) 获取值 lpop/rpop &lt;key&gt;功能：移除并返回最左侧/最右侧的元素返回值：元素值 或者 nil时间复杂度：O(1) lrange &lt;key&gt; &lt;start&gt; &lt;end&gt;功能：返回存储在 key 的列表里指定范围内的元素。 start 和 end 偏移量都是基于0的下标，即list的第一个元素下标是0（list的表头），第二个元素下标是1，以此类推。偏移量也可以是负数，表示偏移量是从list尾部开始计数。 例如， -1 表示列表的最后一个元素，-2 是倒数第二个，以此类推。 blpop/brpop &lt;key&gt;功能：阻塞式移除并返回最左侧/最右侧的元素，当列表中没有元素时，会一直阻塞等待 lindex &lt;key&gt; &lt;value&gt;功能：返回指定下标的元素值 移除操作 lrem &lt;key&gt; &lt;count&gt; &lt;value&gt;功能：从存在于key的列表里移除前count次出现的值为value的元素 count&gt;0: 从头到尾移除前count个值为value的元素； count&lt;0: 从尾到头移除前count个值为value的元素； count=0: 移除所有值为value的元素； 返回值：返回移除的元素个数 ltrim &lt;key&gt; &lt;start&gt; &lt;stop&gt;功能：修剪(trim)一个已存在的 list，这样 list 就会只包含指定范围的指定元素返回值：成功 或者 失败 其他操作 llen &lt;key&gt;功能：返回存储在 key 里的list的长度。 如果 key 不存在，那么就被看作是空list，并且返回长度为 0。 当存储在 key 里的值不是一个list的话，会返回error。返回值：列表元素长度时间复杂度：O(1) 实现原理数据结构 与java中列表的实现相似，redis也存在多种数组和链表类型的实现方式，在redis中当元素个数较少时使用压缩列表(ziplist)存储，当数据较多时使用 双向链表(linkedlist)存储，在后面的版本为了优化内存直接采用了这两者的结合版-快速列表(quicklist)来存储。 压缩列表(ziplist)Redis为了节约内存空间使用，zset,hash,list在元素对象较少时，采用压缩列表进程存储。压缩列表是一块连续的内存空间，元素之间紧挨着存储，没有任何冗余空隙。 压缩列表的构成来看看ziplist的数据结构：12345678910111213141516171819202122struct ziplist&lt;T&gt;&#123; int32 zlbytes; // 整个压缩列表占用字节数 int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点 int16 zllength; // 元素个数 T[] entries; // 元素内容列表，紧凑存储 int8 zlend; // 标志压缩列表的结束，值恒为 0xFF&#125;``` ![](images/ziplist_001.png) 压缩列表为了支持双向遍历，所以才会有 ztail_offset 这个字段，用来快速定位到最后一个元素，只要知道起始地址，再加上这个偏移量，就可以直接定位到最后一个元素，然后倒着遍历。 #### 压缩列表元素的构成 每一个压缩列表的元素可以保存一个字节数组或者一个整数值，每个元素都包含下列结构： ```textstruct entry &#123; int&lt;var&gt; prevlen; // 前一个 entry 的字节长度 int&lt;var&gt; encoding; // 元素类型编码 optional byte[] content; // 元素内容&#125; 每个元素都包含三个部分： prevlen该值记录了前一个元素的字节长度，有了这个长度，程序就可以通过指针运算，根据当前结点的起始地址计算出下一个结点的起始地址，以此类推从而可以实现倒序遍历。 encodingencoding属性记录了结点的content属性的数据类型和长度，通过这些信息就可以完成正序遍历，下表列出了不同类型的编码说明： 编码 编码长度 说明 00xxxxxx 1字节 表示最大长度为(2^6-1)字节的短字符串，后6位表示存储字符串的长度 01xxxxxx xxxxxxxx 2字节 表示长度小于(2^14-1)字节的字符串，后14位表示存储字符串的长度 10xxxxxx xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx 5字节 长度小于等于(2^38-1)字节的字符串 11000000 1字节 int16_t类型的整数，content部分为2个字节长的整数 11010000 1字节 int32_t类型的整数，content部分为4个字节长的整数 11100000 1字节 int64_t类型的整数，content部分为8个字节长的整数 11110000 1字节 int24_t类型的整数，content部分为3个字节长的整数 11111110 1字节 int8_t类型的整数，content部分为1个字节长的整数 11111111 1字节 表示ziplist结束，也就是zlend的值0xFF 1111xxxx 1字节 content部分不存储值，xxxx四位存储了0~12这13的整数 content存储结点的值，结点的值可以是字节数组或者整数，值的类型和长度有encoding属性决定。 级联更新前面提到每个 entry 都会有一个 prevlen 字段存储前一个 entry 的长度。如果内容小于 254 字节，prevlen 用 1 字节存储，否则就是 5 字节。这意味着如果某个 entry 经过了修改操作从 253 字节变成了 254 字节，那么它的下一个 entry 的 prevlen 字段就要更新，从 1 个字节扩展到 5个字节；如果这个 entry 的长度本来也是 253 字节，那么后面 entry 的 prevlen 字段还得继续更新。 如果 ziplist 里面每个 entry 恰好都存储了 253 字节的内容，那么第一个 entry 内容的修改就会导致后续所有 entry 的级联更新，这就是一个比较耗费计算资源的操作，当然是这种几率是很低的。 双向链表(linkedlist)为了支持双向遍历，所以实现的链表方式是双向的，其结构体如下： 链表结构体 1234567891011121314struct list&#123; listNode *head;//头结点 listNode *tail;//尾结点 unsigned long len;//链表包含结点的数量&#125;``` * 结点结构体 ```textstruct listNode&#123; struct listNode *prev;//前驱结点 strcut listNode *next;//后驱结点指针 void *value;//结点值&#125; 双向链表的结构如下图：显然这种数据结构可以支持大量的结点，但是也存在浪费内存(前后驱指针)，随机访问性能差的劣势。 快速列表(quicklist)鉴于linkedlist小号内存，ziplist存储能力有限的情况，redis从3.2开始针对列表数据结构进行了改造，使用了quicklist来代替linkedlist和ziplist 数据结构quickList 是 zipList 和 linkedList 的混合体，它将 linkedList 按段切分，每一段使用 zipList 来紧凑存储，多个 zipList 之间使用双向指针串接起来。 其结构体如下：12345678910111213141516171819202122232425262728// 快速列表struct quicklist &#123; quicklistNode* head; quicklistNode* tail; long count; // 元素总数 int nodes; // ziplist 节点的个数 int compressDepth; // LZF 算法压缩深度 ...&#125;// 快速列表节点struct quicklistNode &#123; quicklistNode* prev; quicklistNode* next; ziplist* zl; // 指向压缩列表 int32 size; // ziplist 的字节总数 int16 count; // ziplist 中的元素数量 int2 encoding; // 存储形式 2bit，原生字节数组还是 LZF 压缩存储 ...&#125;struct ziplist_compressed &#123; int32 size; byte[] compressed_data;&#125;struct ziplist &#123; ...&#125; 可以看到，为了节省内存，Redis还会对ziplist进行压缩存储，使用 LZF 算法压缩，可以选择压缩深度(不由得感叹，Redis作者对内存的使用真是精致啊)。 压缩深度 quicklist 默认的压缩深度是 0，也就是不压缩。压缩的实际深度由配置参数list-compress-depth决定：为了支持快速的 push/pop 操作，quicklist 的首尾两个 ziplist 不压缩，此时深度就是 1。如果深度为 2，就表示 quicklist 的首尾第一个 ziplist 以及首尾第二个 ziplist 都不压缩。 单个ziplist长度 quicklist 内部默认单个 ziplist 长度为 8k 字节，超出了这个字节数，就会新起一个 ziplist。ziplist 的长度由配置参数 list-max-ziplist-size 决定。","tags":[{"name":"Redis","slug":"Redis","permalink":"https://cnkeep.github.io/tags/Redis/"}]},{"title":"Redis数据结构之hash","date":"2019-02-11T15:10:00.000Z","path":"2019/02/11/03-Redis数据结构之hash/","text":"Redis数据结构之hash 标签：Redis 前言 介绍 hash表是redis服务器中出现很频繁的数据结构，它类似于JAVA中的HashMap，以键值对的形式出现和存储。 使用场景 使用hash，一般是有那种需要两层key的应用场景，也可以是‘删除一个key可以删除所有内容’的场景。比如我们不采用json作为value值的string类型来存储用户信息，而是采用hash多个键值对来存储。 常用命令设置值 hset &lt;key&gt; &lt;field&gt; &lt;value&gt; 设置 key 指定的哈希集中指定字段的值。如果 key 指定的哈希集不存在，会创建一个新的哈希集并与 key 关联。如果字段在哈希集中存在，它将被重写。返回值：1：field是一个新字段；0：field已存在，覆盖；时间复杂度： O(1) hmset &lt;key&gt; &lt;field1&gt; &lt;value1&gt; &lt;field2&gt; &lt;value2&gt;... 批量设置哈希集合中字段的值。时间复杂度： O(n) hsetnx &lt;key&gt; &lt;field&gt; &lt;value&gt; 只在 key 指定的哈希集中不存在指定的字段时，设置字段的值。如果 key 指定的哈希集不存在，会创建一个新的哈希集并与 key 关联。如果字段已存在，该操作无效果。返回值：1：如果字段是新字段，并成功赋值；0：如果已经存在该字段，什么也不做； 获取命令 hget &lt;key&gt; &lt;field&gt; 获取指定字段的值返回值：nil: 不存在；其他：对应的value时间复杂度：O(1) hmget &lt;key&gt; &lt;field&gt; &lt;field2&gt;...获取多个指定字段的value值 hgetall &lt;key&gt;返回 key 指定的哈希集中所有的字段和值。返回值中，每个字段名的下一个是它的值，所以返回值的长度是哈希集大小的两倍。 hkeys &lt;key&gt;返回 key 指定的哈希集中所有字段的名字。 hvals &lt;key&gt;返回key指定的哈希集中所有字段对应的value值。 其他命令 hlen &lt;key&gt;返回 key 指定的哈希集包含的字段的数量。 hdel &lt;key&gt; &lt;field&gt;从 key 指定的哈希集中移除指定的域。 hscan &lt;key&gt;增量的迭代一个集合的所有元素，每次只返回一小部分，避免集合过大导致的阻塞。每次被调用都需要使用上一次调用返回的游标作为该次调用的游标参数，以此来延续之前的迭代过程。当SCAN命令的游标参数被设置为 0 时， 服务器将开始一次新的迭代， 而当服务器向用户返回值为 0 的游标时， 表示迭代已结束。 实现原理数据结构hash内部通过字典结构实现，字典结构类似于HashMap的结构，来看看它们的机构体： //字段结构体 struct dict{ ... dictht ht[2]; } //hashtable结构体 struct dictht{ dictEntry** table; long size; long used; ... } //entry结构体 struct dictEntry{ void* key; void* val; dictEntry* next; } dict机构体包含两个hasttable,通常情况下只有一个有值。但是在dict扩容缩容时，需要分配新的hashtable，然后进行渐进式转移，这时候这两个hashtable存储的分别是旧的和新的hashtable.迁移完成后，旧的hashtable会被删除。 hashtable的结构和HashMap的结构相似，都是通过分桶的方式解决hash冲突，第一维是数组，第二维是链表，数组中存储的是第二维链表的首元素指针。 冲突解决与hash算法hash算法当字典被用作数据库的底层实现， 或者哈希键的底层实现时， Redis 使用 MurmurHash2 算法来计算键的哈希值。 MurmurHash 算法最初由 Austin Appleby 于 2008 年发明， 这种算法的优点在于， 即使输入的键是有规律的， 算法仍能给出一个很好的随机分布性， 并且算法的计算速度也非常快。 MurmurHash 算法目前的最新版本为 MurmurHash3 ， 而 Redis 使用的是 MurmurHash2 ， 关于 MurmurHash 算法的更多信息可以参考该算法的主页： http://code.google.com/p/smhasher/ 。 冲突解决无论多么完美的hash算法都无法避免冲突问题，redis也一样，当遇见hah冲突时，redis采用拉链的方式解决冲突。 rehash随着操作的不断执行， 哈希表保存的键值对会逐渐地增多或者减少， 为了让哈希表的负载因子（load factor）维持在一个合理的范围之内，当哈希表保存的键值对数量太多或者太少时， 程序需要对哈希表的大小进行相应的扩展或者收缩。 扩展和收缩哈希表的工作可以通过执行 rehash （重新散列）操作来完成， Redis 对字典的哈希表执行 rehash 的步骤如下： 为字典的 ht[1] 哈希表分配空间， 这个哈希表的空间大小取决于要执行的操作， 以及 ht[0] 当前包含的键值对数量 （也即是 ht[0].used 属性的值）： 如果执行的是扩展操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 2^n （2 的 n 次方幂）； 如果执行的是收缩操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n 。 将保存在 ht[0] 中的所有键值对 rehash 到 ht[1] 上面： rehash 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 ht[1] 哈希表的指定位置上。 当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 （ht[0] 变为空表）， 释放 ht[0] ， 将 ht[1] 设置为 ht[0] ， 并在 ht[1] 新创建一个空白哈希表， 为下一次 rehash 做准备。 渐进式rehash上面提及到了hashtable扩容和缩容时的步骤，如果单纯的按照这样的方式进行迁移数据，那么当遇到哈希表保存的键值对数量巨大时，单线程的redis将会变得及其卡顿，这肯定是无法接受的。但是Redis作为一个高性能的设计，肯定已经考虑到了这一点，它采用了一种渐进式的迁移方案，即不是一次性迁移完成，而是分为多次。 它是通过记录迁移下标rehashindex来实现的： 为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。 在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。 在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。 随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。 渐进式 rehash 的好处在于它采取分而治之的方式， 将 rehash 键值对所需的计算工作均滩到对字典的每个添加、删除、查找和更新操作上， 从而避免了集中式 rehash 而带来的庞大计算量。 因为在进行渐进式 rehash 的过程中， 字典会同时使用 ht[0] 和 ht[1] 两个哈希表， 所以在渐进式 rehash 进行期间， 字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行： 比如说， 要在字典里面查找一个键的话， 程序会先在 ht[0] 里面进行查找，如果没找到的话， 就会继续到 ht[1] 里面进行查找， 诸如此类。 另外， 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 ht[1] 里面， 而 ht[0] 则不再进行任何添加操作： 这一措施保证了 ht[0] 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。","tags":[{"name":"Redis","slug":"Redis","permalink":"https://cnkeep.github.io/tags/Redis/"}]},{"title":"Redis数据结构之HyperLogLog","date":"2019-02-11T14:49:00.000Z","path":"2019/02/11/07-Redis数据结构之HyperLogLog/","text":"Redis数据结构之HyperLoglog 标签：Redis, HypeLoglog 介绍HyperLoglog是一种特殊的数据结构，其提供不精确的去重计数方案，虽然不精确但是也不是非常不精确，标准误差是0.81%，可以应用于对精度要求不高的去重统计场景，例如：页面PV统计。 API 及使用HyperLoglog的API是非简单，只有下列几种： pfadd &lt;key&gt; &lt;value&gt; [&lt;value&gt;...]功能：将任意数量的元素添加到指定的 HyperLogLog 里面。作为这个命令的副作用， HyperLogLog 内部可能会被更新， 以便反映一个不同的唯一元素估计数量（也即是集合的基数）返回值：1：HypeLoglog内部存储被修改了；0：未做修改时间复杂度：O(1)示例： 123456789101112redis&gt; PFADD databases &quot;Redis&quot; &quot;MongoDB&quot; &quot;MySQL&quot;(integer) 1redis&gt; PFCOUNT databases(integer) 3redis&gt; PFADD databases &quot;Redis&quot; # Redis 已经存在，不必对估计数量进行更新(integer) 0redis&gt; PFCOUNT databases # 元素估计数量没有变化(integer) 3redis&gt; PFADD databases &quot;PostgreSQL&quot; # 添加一个不存在的元素(integer) 1redis&gt; PFCOUNT databases # 估计数量增一4 pfcount &lt;key&gt;功能：返回给定 HyperLogLog 包含的唯一元素的近似数量时间复杂度：O(1) pfmerge &lt;destKey&gt; &lt;sourceKey&gt; [&lt;sourceKey&gt;...]功能：将多个 HyperLogLog 合并（merge）为一个 HyperLogLog ， 合并后的 HyperLogLog 的基数接近于所有输入 HyperLogLog 的可见集合（observed set）的并集时间复杂度：O(n)示例： 12345678redis&gt; PFADD nosql &quot;Redis&quot; &quot;MongoDB&quot; &quot;Memcached&quot;(integer) 1redis&gt; PFADD RDBMS &quot;MySQL&quot; &quot;MSSQL&quot; &quot;PostgreSQL&quot;(integer) 1redis&gt; PFMERGE databases nosql RDBMSOKredis&gt; PFCOUNT databases(integer) 6 总结鉴于 HyperLogLog 不保存数据内容的特性，所以，它只适用于一些特定的场景。我这里给出一个最常遇到的场景需要：计算日活、7日活、月活数据。 HyperLoglog存在误差，不精确统计 HyperLoglog不能获取原数据，只能获取估值 Redis的实现版本因为分桶的原因需要消耗12K的内存","tags":[{"name":"Redis","slug":"Redis","permalink":"https://cnkeep.github.io/tags/Redis/"}]},{"title":"Redis的处理模型","date":"2019-02-10T16:07:00.000Z","path":"2019/02/11/08-Redis的处理模型/","text":"Redis的处理模型介绍作为程序员的你可能不相信，但是这是一个事实：Redis是一个单线程模型。本文就这一特点进行讨论。 讨论单线程的Redis为什么快Redis之所以快主要因为以下几点： 基于内存，这一点我想不用讲就知道，内存级别的操作是十分快速的 非阻塞IO，事件模型 各种设计精良的数据结构 I/O多路复用有人可能会疑问，单线程能处理得了那么多连接吗？事实上是可以的，对JAVA的NIO有所了解的应该知道I/O多路复用这个概念。 多个连接注册到同一个Selector上，一个selector可以监听多个I/O事件，而且selector是阻塞的，当某个连接存在I/O事件时就会激活Selector，Selector会返回存在I/O事件的连接及事件类型，之后我们就可以处理响应的事件。这样我们就只需要一个线程循环监听Selector就可以完成对多个连接的监听。 真的是单线程？Redis真的是单线程吗？那些异步操作是如何处理的？能提出这个问题真的是很棒了，我们说Redis是单线程的，是指它处理执行我们客户端的命令单线程的，所有的命令到达服务端先在队列中排队，由一个单线程去解析，执行命令，然后返回给客户端。但是在执行异步操作，数据持久化时，主从同步等操作时还是会存在多个线程的，这一点大家必须要了解。 上面我们提到Redis处理命令时是单线程的，因此在线上时一定要避免执行比较重的命令，即那些时间复杂度为O(n)甚至更大的命令，尽量使用时间复杂度为常量的操作，避免阻塞后序其他命令的执行，导致服务延迟。","tags":[{"name":"Redis","slug":"Redis","permalink":"https://cnkeep.github.io/tags/Redis/"}]},{"title":"Redis介绍与安装","date":"2019-02-02T14:40:00.000Z","path":"2019/02/02/01-Redis介绍与安装/","text":"Redis介绍与安装【目录】Redis介绍Redis安装&nbsp;&nbsp;压缩包安装&nbsp;&nbsp;Docker安装Redis Redis介绍&nbsp;&nbsp;Redis是当前最火的Nosql系统之一，它是一个key-value的存储系统，与其他Nosql不同的是它的优良性能以及多种数据结构的支持(只会在理论篇做对比介绍)。 Redis安装 相信大家已经对Redis做过相应了解了，那现在就来动手安装实践一下，本次安装分为:压缩包安装和Docker安装（推荐）。 压缩包安装 1.环境介绍12Centos 7Redis压缩包：http://download.redis.io/releases/redis-5.0.3.tar.gz 2.资源获取 参见Redis官网 3.配置分组和用户，默认目录(非必须)123456789# 这里我采用redis独立用户去操作，可以直接跳过$groupadd redis$useradd redis -g redis -d /home/redis -s /bin/bash$passwd redis更改用户 redis 的密码 。新的 密码：无效的密码： 密码少于 8 个字符重新输入新的 密码：passwd：所有的身份验证令牌已经成功更新。 4.安装编译12345678910111213141516171819$cd /home/redis$tar -zxvf redis-5.0.3.tar.gz $cd /home/redis/redis-5.0.3$make #编译$cd src$make install CC Makefile.depHint: It&apos;s a good idea to run &apos;make test&apos; ;) INSTALL install INSTALL install INSTALL install INSTALL install INSTALL install#建立软连接方便执行启动命令$ln -s /home/redis/redis-5.0.3/src/redis-cli /usr/sbin/redis-cli$ln -s /home/redis/redis-5.0.3/src/redis-server /usr/sbin/redis-server 5.修改配置12345678910111213141516$mkdir /home/redis/redis-5.0.3/data #用于存储数据$mkdir /home/redis/redis-5.0.3/conf #用于存储配置文件$mkdir /home/redis/redis-5.0.3/log #用于存储日志#copy一份配置文件$cp /home/redis/redis-5.0.3/redis.conf /home/redis/redis-5.0.3/conf/redis_template.conf #修改端口，可以跳过$sed s/6379/6389/g /home/redis/redis-5.0.3/conf/redis_template.conf&gt;/home/redis/redis-5.0.3/conf/redis_6389.conf$vi /home/redis/redis-5.0.3/conf/redis_6389.conf#配置日志项：logfile &quot;/home/redis/redis-5.0.3/logs/log&quot;#配置数据项：dir /home/redis/redis-5.0.3/data/#关闭保护：protected-mode no#配置信任ip：bind 172.16.*.*#配置密码：require redis@Pwd11 6.启动1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#设置加载的配置文件，设置后台启动$redis-server /home/redis/redis-5.0.3/conf/redis_6389.conf &amp;#查看进程信息$ps -ef|grep redisroot 6550 2150 0 17:15 pts/0 00:00:00 redis-server 127.0.0.1:6389root 6555 2150 0 17:15 pts/0 00:00:00 grep --color=auto redis#查看启动日志$tail -n 100 -f /home/redis/redis-5.0.3/logs/log6483:C 28 Dec 2018 16:53:55.715 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo6483:C 28 Dec 2018 16:53:55.715 # Redis version=5.0.3, bits=64, commit=00000000, modified=0, pid=6483, just started6483:C 28 Dec 2018 16:53:55.715 # Configuration loaded6483:M 28 Dec 2018 16:53:55.716 * Increased maximum number of open files to 10032 (it was originally set to 1024). _._ _.-``__ &apos;&apos;-._ _.-`` `. `_. &apos;&apos;-._ Redis 5.0.3 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ &apos;&apos;-._ ( &apos; , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|&apos;` _.-&apos;| Port: 6389 | `-._ `._ / _.-&apos; | PID: 6550 `-._ `-._ `-./ _.-&apos; _.-&apos; |`-._`-._ `-.__.-&apos; _.-&apos;_.-&apos;| | `-._`-._ _.-&apos;_.-&apos; | http://redis.io `-._ `-._`-.__.-&apos;_.-&apos; _.-&apos; |`-._`-._ `-.__.-&apos; _.-&apos;_.-&apos;| | `-._`-._ _.-&apos;_.-&apos; | `-._ `-._`-.__.-&apos;_.-&apos; _.-&apos; `-._ `-.__.-&apos; _.-&apos; `-._ _.-&apos; `-.__.-&apos; 6483:M 28 Dec 2018 16:53:55.716 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.6483:M 28 Dec 2018 16:53:55.716 # Server initialized6483:M 28 Dec 2018 16:53:55.716 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add &apos;vm.overcommit_memory = 1&apos; to /etc/sysctl.conf and then reboot or run the command &apos;sysctl vm.overcommit_memory=1&apos; for this to take effect.6483:M 28 Dec 2018 16:53:55.717 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command &apos;echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled&apos; as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.6483:M 28 Dec 2018 16:53:55.717 * DB loaded from disk: 0.000 seconds6483:M 28 Dec 2018 16:53:55.717 * Ready to accept connections6483:M 28 Dec 2018 16:56:31.287 # User requested shutdown...6483:M 28 Dec 2018 16:56:31.287 * Saving the final RDB snapshot before exiting.6483:M 28 Dec 2018 16:56:31.288 * DB saved on disk6483:M 28 Dec 2018 16:56:31.288 * Removing the pid file.6483:M 28 Dec 2018 16:56:31.288 # Redis is now ready to exit, bye bye...``` &gt; 7.客户端连接测试 ```text$redis-cli -h &lt;ip&gt; -p &lt;port&gt;127.0.0.1:6389&gt;keys *(empty list or set) 8.关闭redis1$redis-cli shutdown 以上redis就安装完毕了，快去使用吧！ Docker安装Redis 1.环境介绍1234567Centos 7Docker``` &gt; 2.获取资源 ```text$docker search redis$docker pull redis:latest 3.配置基础环境1234567891011121314151617181920212223242526272829303132$mkdir /home/redis/redis-5.0.3/data #用于存储数据$mkdir /home/redis/redis-5.0.3/conf #用于存储配置文件$mkdir /home/redis/redis-5.0.3/log #用于存储日志#copy一份配置文件, 配置文件可以从官方获取$cp /home/redis/redis-5.0.3/redis.conf /home/redis/redis-5.0.3/conf/redis_template.conf #修改端口，可以跳过$sed s/6379/6389/g /home/redis/redis-5.0.3/conf/redis_template.conf&gt;/home/redis/redis-5.0.3/conf/redis_6389.conf$vi /home/redis/redis-5.0.3/conf/redis_6389.conf#配置日志项：logfile &quot;/home/redis/redis-5.0.3/logs/log&quot;#配置数据项：dir /home/redis/redis-5.0.3/data/#关闭保护：protected-mode no#配置信任ip：bind 172.16.*.*#配置密码：require redis@Pwd11``` &gt; 4.启动 ```text$docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEredis latest c188f257942c 6 weeks ago 94.9MB#配置启动参数$docker run \\ #创建并启动容器--name redis_6379 \\#指定容器名称-p 6379:6379 \\#指定端口映射，宿主机：容器-privileged=true \\#给与权限-v /home/redis/redis-5.0.3/conf/redis_6389.conf:/etc/redis/redis.conf \\#配置文件映射-v /home/redis/redis-5.0.3/data:/etc/data \\#数据目录映射-d redis redis-server /etc/redis/redis.conf --appendonly yes#-d后台启动，并指定配置文件，AOF开启 5.验证启动1234567891011121314151617181920212223242526272829303132333435363738#查看日志$docker logs redis_63791:C 28 Dec 2018 17:40:44.775 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo1:C 28 Dec 2018 17:40:44.776 # Redis version=5.0.1, bits=64, commit=00000000, modified=0, pid=1, just started1:C 28 Dec 2018 17:40:44.776 # Configuration loaded _._ _.-``__ &apos;&apos;-._ _.-`` `. `_. &apos;&apos;-._ Redis 5.0.1 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ &apos;&apos;-._ ( &apos; , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|&apos;` _.-&apos;| Port: 6379 | `-._ `._ / _.-&apos; | PID: 1 `-._ `-._ `-./ _.-&apos; _.-&apos; |`-._`-._ `-.__.-&apos; _.-&apos;_.-&apos;| | `-._`-._ _.-&apos;_.-&apos; | http://redis.io `-._ `-._`-.__.-&apos;_.-&apos; _.-&apos; |`-._`-._ `-.__.-&apos; _.-&apos;_.-&apos;| | `-._`-._ _.-&apos;_.-&apos; | `-._ `-._`-.__.-&apos;_.-&apos; _.-&apos; `-._ `-.__.-&apos; _.-&apos; `-._ _.-&apos; `-.__.-&apos; 1:M 28 Dec 2018 17:40:44.780 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.1:M 28 Dec 2018 17:40:44.780 # Server initialized1:M 28 Dec 2018 17:40:44.780 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add &apos;vm.overcommit_memory = 1&apos; to /etc/sysctl.conf and then reboot or run the command &apos;sysctl vm.overcommit_memory=1&apos; for this to take effect.1:M 28 Dec 2018 17:40:44.780 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command &apos;echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled&apos; as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.1:M 28 Dec 2018 17:40:44.792 * DB loaded from disk: 0.012 seconds1:M 28 Dec 2018 17:40:44.792 * Ready to accept connections#进入容器查看 [root@localhost conf]# docker exec -it redis_6379 /bin/bashroot@c6c3bf9cb27c:/data# redis-cli127.0.0.1:6379&gt; keys *(empty list or set) 127.0.0.1:6379&gt; info memory......127.0.0.1:6379&gt; info replication 结束语自此redis的安装就完成了，其中关于Docker的安装，以及防火墙的配置不做介绍，读者可以自行解决。Over!","tags":[{"name":"Redis","slug":"Redis","permalink":"https://cnkeep.github.io/tags/Redis/"}]},{"title":"Redis设置访问ip限制","date":"2019-02-02T13:20:00.000Z","path":"2019/02/02/02-Redis设置访问ip限制/","text":"Redis设置访问ip限制介绍鉴于Redis没有用户的概念，我们在实际生产中不能直接将其暴露在外网的环境下，普遍都是通过反向代理限制在内网访问，那么如何设置限制ip访问呢？ 1.仅限部署Redis服务器的客户端连接：12345#永久生效配置redis.conf, 设置protected-mode=true#当次生效，重启失效config set protected-mode=true 2.指定客户端信任ip列表：1配置redis.conf, 设置bind &lt;ipList 多个采用空格分隔&gt; 3.开启密码保护：1配置redis.conf, 设置requirepass &lt;pwd&gt; 4.效果：123456789101112131415161718192021222324#重启客户端访问后无法操作： 172.17.0.2:6379&gt; config get mode*(error) DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command &apos;CONFIG SET protected-mode no&apos; from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to &apos;no&apos;, and then restarting the server. 3) If you started the server manually just for testing, restart it with the &apos;--protected-mode no&apos; option. 4) Setup a bind address or an authentication password.NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.#需要密码登录[root@localhost conf]# redis-cli 127.0.0.1:6379&gt; keys *(error) NOAUTH Authentication required.[root@localhost conf]# redis-cli127.0.0.1:6379&gt; auth java1024 #auth命令验证密码OK","tags":[{"name":"Redis","slug":"Redis","permalink":"https://cnkeep.github.io/tags/Redis/"}]},{"title":"Redis设置开机自启","date":"2019-02-01T15:36:00.000Z","path":"2019/02/01/03-Redis设置开机自启/","text":"Redis设置开机自启 我们将Redis作为DB服务时，有时候会碰上关机的情况，及时这样我们也希望可以开机自启,本次我们就来学习如何是实现。 从docker引发的思考 1.设置docker开机自启12$ systemctl enable dockerCreated symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service. 发现这里有两个目录：/etc/systemd/system/multi-user.target.wants/, /usr/lib/systemd/system/ 2./etc/systemd/system/multi-user.target.wants/ 该目录下存在许多软连接，指向/usr/lib/systemd/system/，开机时会扫描执行该目录下的脚本 3./usr/lib/systemd/system/ 真正的service单元配置文件都在这个目录下面，其中存在docker.service的文件：123456789101112131415161718192021222324252627282930313233[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comAfter=network-online.target firewalld.serviceWants=network-online.target[Service]Type=notify# the default is not to use systemd for cgroups because the delegate issues still# exists and systemd currently does not support the cgroup feature set required# for containers run by dockerExecStart=/usr/bin/dockerdExecReload=/bin/kill -s HUP $MAINPID# Having non-zero Limit*s causes performance problems due to accounting overhead# in the kernel. We recommend using cgroups to do container-local accounting.LimitNOFILE=infinityLimitNPROC=infinityLimitCORE=infinity# Uncomment TasksMax if your systemd version supports it.# Only systemd 226 and above support this version.#TasksMax=infinityTimeoutStartSec=0# set delegate yes so that systemd does not reset the cgroups of docker containersDelegate=yes# kill only the docker process, not all processes in the cgroupKillMode=process# restart the docker process if it exits prematurelyRestart=on-failureStartLimitBurst=3StartLimitInterval=60s[Install]WantedBy=multi-user.target 4.猜想 既然已经摸清了docker开机自启的猫腻，那么完全可以模仿实现redis的开机自启，按照以下步骤即可： 编写/user/lib/systemd/system/redis.service脚本 建立软连接至/etc/systemd/system/multi-user.target.wants/ 刷新配置，开启开启自启即可 设置开机自启 1.编写脚本1234567891011121314$ vi /lib/systemd/system/redis.service#写入以下内容[Unit]Description=Redis_5.0.1After=network.target[Service]#redis安装绝对路径ExecStart=/usr/local/app/redis-5.0.3/src/redis-server /usr/local/app/redis-5.0.3/redis.conf --daemonize noExecStop=/usr/local/app/redis-5.0.3/src/redis-cli -h 127.0.0.1 -p 6379 shutdown[Install]WantedBy=multi-user.target [Unit] 表示这是基础信息 Description 是描述 After 是在那个服务后面启动，一般是网络服务启动后启动 [Service] 表示这里是服务信息 ExecStart 是启动服务的命令 ExecStop 是停止服务的指令 [Install] 表示这是是安装相关信息 WantedBy 是以哪种方式启动：multi-user.target表明当系统以多用户方式（默认的运行级别）启动时，这个服务需要被自动运行。 详细请移步至：CoreOS实践指南（八）：Unit文件详解 2.设置开机启动12345678910#配置软连接$ ln -s /lib/systemd/system/redis.service /etc/systemd/system/multi-user.target.wants/redis.service#刷新配置$ systemctl daemon-reload#开启开机自启功能$ systemctl enable redis$ systemctl [start|stop|restart|status] redis `","tags":[{"name":"Redis","slug":"Redis","permalink":"https://cnkeep.github.io/tags/Redis/"}]},{"title":"04_binlog日志","date":"2019-01-15T17:28:00.000Z","path":"2019/01/16/02-04_binlog日志/","text":"mysql binlog日志介绍 属于逻辑日志，mysql上层模块记录，不由数据库引擎记录; 只记录会引起数据发生改变的记录(不包含select, show); 以事件形式记录，包含时间、时间开始和结束位置等信息; 只在事务提交的时候一次性写入; 用于恢复定点数据库和主从同步复制; 二进制日志log-bin文件MySQL默认没有启动二进制日志，要启用二进制日志使用要启用二进制日志使用--log-bin=[on|off|file_name]选项指定，如果没有给定file_name，则默认为datadir下的主机名加”-bin”，并在后面跟上一串数字表示日志序列号，如果给定的日志文件中包含了后缀(logname.suffix)将忽略后缀部分。 或者在配置文件中的[mysqld]部分设置log-bin也可以。注意：对于mysql 5.7，直接启动binlog可能会导致mysql服务启动失败，这时需要在配置文件中的mysqld为mysql实例分配server_id。12345678910111213141516[mysqld]server_id=1234log-bin=[on|filename]``` ### bin-log索引文件 MySQL除了创建二进制日志文件外还会创建二进制日志索引文件，该文件包含所有使用的二进制日志文件的文件名，当二进制日志文件滚动的时候会向改文件中写入对应的信息。默认情况下该文件与二进制日志文件的文件名相同，扩展名为&apos;.index&apos;。要指明该文件的文件名请指定配置``--log-bin-index=[file_name]``. ```text[root@localhost mysql]# vi mysql-bin.index /var/lib/mysql/mysql-bin.000001/var/lib/mysql/mysql-bin.000002/var/lib/mysql/mysql-bin.000003/var/lib/mysql/mysql-bin.000004/var/lib/mysql/mysql-bin.000005 bin-log日志滚动当重启MySQL服务，刷新日志或者达到日志最大值时，将滚动二进制日志文件，即生成新的二进制文件。 二进制日志文件的最大值通过变量max_binlog_size设置(默认为1G).但由于二进制日志可能是基于事务来记录的(如innodb表类型)，而事务是绝对不可能也不应该跨文件记录的，如果正好二进制日志文件达到了最大值但事务还没有提交则不会滚动日志，而是继续增大日志，所以 max_binlog_size 指定的值和实际的二进制日志大小不一定相等。 因为二进制日志文件增长迅速，且二进制目的是为了恢复定点数据库和主从复制，所以出于安全和功能考虑，极不建议将二进制日志和datadir放在同一磁盘上。 bin-log日志探究查看bin-log日志MySQL中查看二进制日志的方法主要有几种。 1.使用mysqlbinlog工具。 12345678910mysqlbinlog [option] log-file1 log-file2... -d,--database=name：只查看指定数据库的日志操作-o,--offset=#：忽略掉日志中的前n个操作命令-r,--result-file=name：将输出的日志信息输出到指定的文件中，使用重定向也一样可以。-s,--short-form：显示简单格式的日志，只记录一些普通的语句，会省略掉一些额外的信息如位置信息和时间信息以及基于行的日志。可以用来调试，生产环境千万不可使用--set-charset=char_name：在输出日志信息到文件中时，在文件第一行加上set names char_name--start-datetime,--stop-datetime：指定输出开始时间和结束时间内的所有日志信息--start-position=#,--stop-position=#：指定输出开始位置和结束位置内的所有日志信息-v,-vv：显示更详细信息，基于row的日志默认不会显示出来，此时使用-v或-vv可以查看 2.使用show显示对应的信息。 123SHOW &#123;BINARY | MASTER&#125; LOGS # 查看使用了哪些日志文件SHOW BINLOG EVENTS [IN &apos;log_name&apos;] [FROM pos] # 查看日志中进行了哪些操作SHOW MASTER STATUS # 显式主服务器中的二进制日志信息 bin-log日志的记录格式binlog的格式也有三种：STATEMENT，ROW，MIXED。 STATEMENT模式 每一条会修改数据的sql语句会记录到binlog中。优点是并不需要记录每一条sql语句和每一行的数据变化，减少了binlog日志量，节约IO，提高性能。缺点是在某些情况下会导致master-slave中的数据不一致(如sleep()函数， last_insert_id()，以及user-defined functions(udf)等会出现问题) ROW模式（RBR） 不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了(更新丢失不会记录)，修改成什么样了。而且不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题。缺点是会产生大量的日志，尤其是alter table的时候会让日志暴涨。 MIXED模式（MBR） 以上两种模式的混合使用，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog，MySQL会根据执行的SQL语句选择日志保存方式。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253[root@localhost mysql]# mysqlbinlog mysql-bin.000006 -vv/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#190409 18:48:27 server id 135 end_log_pos 123 CRC32 0xf42b6057 Start: binlog v 4, server v 5.7.17-log created 190409 18:48:27# Warning: this binlog is either in use or was not closed properly.BINLOG &apos;e3isXA+HAAAAdwAAAHsAAAABAAQANS43LjE3LWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXwAEGggAAAAICAgCAAAACgoKKioAEjQAAVdgK/Q=&apos;/*!*/;# at 123#190409 18:48:27 server id 135 end_log_pos 154 CRC32 0xe0336d42 Previous-GTIDs# [empty]# at 154#190409 18:50:38 server id 135 end_log_pos 219 CRC32 0x6d993e5a Anonymous_GTID last_committed=0 sequence_number=1SET @@SESSION.GTID_NEXT= &apos;ANONYMOUS&apos;/*!*/;# at 219#190409 18:50:38 server id 135 end_log_pos 294 CRC32 0xc6f46497 Query thread_id=4 exec_time=0 error_code=0SET TIMESTAMP=1554807038/*!*/;SET @@session.pseudo_thread_id=4/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1436549152/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;BEGIN/*!*/;# at 294#190409 18:50:38 server id 135 end_log_pos 347 CRC32 0x30af2100 Table_map: `test_01`.`user` mapped to number 6007# at 347#190409 18:50:38 server id 135 end_log_pos 396 CRC32 0xae5895a6 Write_rows: table id 6007 flags: STMT_END_FBINLOG &apos;/nisXBOHAAAANQAAAFsBAAAAAHcXAAAAAAEAB3Rlc3RfMDEABHVzZXIAAgMPApYAAAAhrzA=/nisXB6HAAAAMQAAAIwBAAAAAHcXAAAAAAEAAgAC//wCAAAACHpoYW5nc2FuppVYrg==&apos;/*!*/;### INSERT INTO `test_01`.`user`### SET### @1=2 /* INT meta=0 nullable=0 is_null=0 */### @2=&apos;zhangsan&apos; /* VARSTRING(150) meta=150 nullable=0 is_null=0 */# at 396#190409 18:50:38 server id 135 end_log_pos 427 CRC32 0x22e4afe6 Xid = 28COMMIT/*!*/;SET @@SESSION.GTID_NEXT= &apos;AUTOMATIC&apos; /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 统计bin-log日志中的操作1mysql&gt; show binlog events in &apos;mysql-bin.000001&apos; bin-log日志相关变量注意：在配置binlog相关变量的时候，相关变量名总是搞混，因为有的是binlog，有的是log_bin，当他们分开的时候，log在前，当它们一起的时候，bin在前。在配置文件中也同样如此。 log_bin= {on | off | base_name} #指定是否启用记录二进制日志或者指定一个日志路径(路径不能加.否则.后的被忽略) sql_log_bin={ on | off } #指定是否启用记录二进制日志，只有在log_bin开启的时候才有效 expire_logs_days= #指定自动删除二进制日志的时间，即日志过期时间 binlog_do_db= #明确指定要记录日志的数据库 binlog_ignore_db= #指定不记录二进制日志的数据库 log_bin_index= #指定mysql-bin.index文件的路径 binlog_format= { mixed | row | statement } #指定二进制日志基于什么模式记录 binlog_rows_query_log_events= { 1|0 } # MySQL5.6.2添加了该变量，当binlog format为row时，默认不会记录row对应的SQL语句，设置为1或其他true布尔值时会记录，但需要使用mysqlbinlog -v查看，这些语句是被注释的，恢复时不会被执行。 max_binlog_size= #指定二进制日志文件最大值，超出指定值将自动滚动。但由于事务不会跨文件，所以并不一定总是精确。 binlog_cache_size= 32768 #基于事务类型的日志会先记录在缓冲区，当达到该缓冲大小时这些日志会写入磁盘 max_binlog_cache_size= #指定二进制日志缓存最大大小，硬限制。默认4G，够大了，建议不要改 binlog_cache_use使用缓存写二进制日志的次数(这是一个实时变化的统计值) binlog_cache_disk_use使用临时文件写二进制日志的次数，当日志超过了binlog_cache_size的时候会使用临时文件写日志，如果该变量值不为0，则考虑增大binlog_cache_size的值 binlog_stmt_cache_size= 32768 #一般等同于且决定binlog_cache_size大小，所以修改缓存大小时只需修改这个而不用修改binlog_cache_size binlog_stmt_cache_use使用缓存写二进制日志的次数 binlog_stmt_cache_disk_use 使用临时文件写二进制日志的次数，当日志超过了binlog_cache_size的时候会使用临时文件写日志，如果该变量值不为0，则考虑增大binlog_cache_size的值 sync_binlog= { 0 | n } #这个参数直接影响mysql的性能和完整性 sync_binlog0:不同步，日志何时刷到磁盘由FileSystem决定，这个性能最好。 sync_binlogn:每写n次二进制日志事件(不是事务)，MySQL将执行一次磁盘同步指令fdatasync()将缓存日志刷新到磁盘日志文件中。Mysql中默认的设置是sync_binlog=0，即不同步，这时性能最好，但风险最大。一旦系统奔溃，缓存中的日志都会丢失。 在innodb的主从复制结构中，如果启用了二进制日志(几乎都会启用)，要保证事务的一致性和持久性的时候，必须将sync_binlog的值设置为1，因为每次事务提交都会写入二进制日志，设置为1就保证了每次事务提交时二进制日志都会写入到磁盘中，从而立即被从服务器复制过去。 bin-log定点还原数据库只需指定二进制日志的起始位置（可指定终止位置）并将其保存到sql文件中，由mysql命令来载入恢复即可。当然直接通过管道送给mysql命令也可。至于是基于位置来恢复还是基于时间点来恢复，这两种行为都可以。选择时间点来恢复比较直观些，并且跨日志文件恢复时更方便。1mysqlbinlog --stop-datetime=&quot;2014-7-2 15:27:48&quot; /tmp/mysql-bin.000008 | mysql -u user -p password 恢复多个二进制日志文件时：1mysqlbinlog mysql-bin.[*] | mysql -uroot -p password 或者将它们导入到一个文件中后恢复。123mysqlbinlog mysql-bin.000001 &gt; /tmp/a.sqlmysqlbinlog mysql-bin.000002 &gt;&gt;/tmp/a.sqlmysql -u root -p password -e &quot;source /tmp/a.sql&quot;","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"01_存储引擎的分类","date":"2019-01-15T17:25:00.000Z","path":"2019/01/16/02-01_存储引擎的分类/","text":"存储引擎的分类 标签：Mysql 前言Mysql的插件式存储引擎是其一大特色，为了适应不同的业务场景，我们可以针对业务选择不同的存储引擎，本次就来了解一下mysql都有哪些常见的存储引擎。 存储引擎InnodbInnoDB是事务型数据库的首选引擎，支持事务安全表（ACID），支持行锁定和外键，上图也看到了，InnoDB是默认的MySQL引擎。InnoDB主要特性有： InnoDB给MySQL提供了具有提交、回滚和崩溃恢复能力的事物安全（ACID兼容）存储引擎。InnoDB锁定在行级并且也在SELECT语句中提供一个类似Oracle的非锁定读。这些功能增加了多用户部署和性能。在SQL查询中，可以自由地将InnoDB类型的表和其他MySQL的表类型混合起来，甚至在同一个查询中也可以混合。 InnoDB是为处理巨大数据量的最大性能设计。它的CPU效率可能是任何其他基于磁盘的关系型数据库引擎锁不能匹敌的。 InnoDB存储引擎完全与MySQL服务器整合，InnoDB存储引擎为在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB将它的表和索引在一个逻辑表空间中，表空间可以包含数个文件（或原始磁盘文件）。这与MyISAM表不同，比如在MyISAM表中每个表被存放在分离的文件中。InnoDB表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上。 InnoDB支持外键完整性约束，存储表中的数据时，每张表的存储都按主键顺序存放，如果没有显示在表定义时指定主键，InnoDB会为每一行生成一个6字节的ROWID，并以此作为主键。 InnoDB被用在众多需要高性能的大型数据库站点上。 MyISAMMyISAM基于ISAM存储引擎，并对其进行扩展。它是在Web、数据仓储和其他应用环境下最常使用的存储引擎之一。MyISAM拥有较高的插入、查询速度，但不支持事物。MyISAM主要特性有: 大文件（达到63位文件长度）在支持大文件的文件系统和操作系统上被支持。 当把删除和更新及插入操作混合使用的时候，动态尺寸的行产生更少碎片。这要通过合并相邻被删除的块，以及若下一个块被删除，就扩展到下一块自动完成。 每个MyISAM表最大索引数是64，这可以通过重新编译来改变。每个索引最大的列数是16。 最大的键长度是1000字节，这也可以通过编译来改变，对于键长度超过250字节的情况，一个超过1024字节的键将被用上。 BLOB和TEXT列可以被索引。 NULL被允许在索引的列中，这个值占每个键的0~1个字节。 所有数字键值以高字节优先被存储以允许一个更高的索引压缩。 每个MyISAM类型的表都有一个AUTO_INCREMENT的内部列，当INSERT和UPDATE操作的时候该列被更新，同时AUTO_INCREMENT列将被刷新。所以说，MyISAM类型表的AUTO_INCREMENT列更新比InnoDB类型的AUTO_INCREMENT更快。 可以把数据文件和索引文件放在不同目录。 每个字符列可以有不同的字符集。 有VARCHAR的表可以固定或动态记录长度。 VARCHAR和CHAR列可以多达64KB。 使用MyISAM引擎创建数据库，将产生3个文件。文件的名字以表名字开始，扩展名之处文件类型：frm文件存储表定义、数据文件的扩展名为.MYD（MYData）、索引文件的扩展名时.MYI（MYIndex）。 MemoryMEMORY存储引擎将表中的数据存储到内存中，未查询和引用其他表数据提供快速访问。MEMORY主要特性有： MEMORY表的每个表可以有多达32个索引，每个索引16列，以及500字节的最大键长度。 MEMORY表内存被存储在内存中，内存是MEMORY表和服务器在查询处理时的空闲中，创建的内部表共享。","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"01_Mysql联接查询算法","date":"2019-01-15T15:48:00.000Z","path":"2019/01/15/03-01_Mysql联接查询算法/","text":"Mysql联接查询算法 转载：运维那点事-MySQL联接查询算法（NLJ、BNL、BKA、HashJoin） 前言&nbsp;&nbsp;这几天偶然发现了关于MySQL联接查询算法的文章，受益匪浅，在此转载记录，原文已置顶说明。 级联查询算法联接算法是MySQL数据库用于处理联接的物理策略。目前MySQL数据库仅支持Nested-Loops Join算法。而MySQL的分支版本MariaDB除了支持Nested-Loops Join算法外，还支持Classic Hash Join算法。当联接的表上有索引时，Nested-Loops Join是非常高效的算法。根据B+树的特性，其联接的时间复杂度为O(N)，若没有索引，则可视为最坏的情况，时间复杂度为O(N²)。 MySQL数据库根据不同的使用场合，支持两种Nested-Loops Join算法，一种是Simple Nested-Loops Join（NLJ）算法，另一种是Block Nested-Loops Join（BNL）算法。 上图的Fetch阶段是指当内表关联的列是辅助索引时，但是需要访问表中的数据，这是就需要回表(辅助索引叶子节点存储的是主键索引，需要回表查询)，无论表的存储引擎是Innodb还是MyISAM，这都是无法避免的，只是MyISAM的回表速度要快点，因为其辅助索引存放的就是指向记录的指针，而InnoDB存储引擎是索引组织表，需要再次通过索引查找才能定位数据。Fetch阶段也不是必须存在的，如果是聚集索引，那么子节点就存储着数据，无需回表。另外上述给出了两张表之间的join成本，多张表的join就是继续上述这个过程。 接着计算两张表的Join成本，这里有下列几种概念： 外表的扫描次数，记为O。通常外表（驱动表，数据量小）的扫描次数都是1，即Join时扫描一次驱动表的数据即可内表的扫描次数，记为I。根据不同的Join算法，内表的扫描次数不同读取表的记录数，记为R。根据不同Join算法，读取记录的数量可能不同Join的比较次数，记为M。根据不同Join算法，比较次数不同回表的读取记录的数，记为F。若Join的是辅助索引，可能需要回表取得最终的数据 评判一个Join算法是否优劣，就是查看上述这些操作的开销是否比较小。当让，这还要考虑I/O的访问方式，顺序 还是随机。总之Join的调优是门艺术。 Simple Nested-Loops Join (SNLJ)算法Simple Nested-Loops Join算法相当简单、直接。即外表（驱动表）中的每一条记录与内表中的记录进行比较判断。算法如下：12345678910111213141516171819202122232425For each row r in R do -- 扫描R表 For each row s in S do -- 扫描S表 If r and s satisfy the join condition -- 如果r和s满足join条件 Then output the tuple &lt;r, s&gt; -- 返回结果集``` 下图能更好地显示整个SNLJ的过程： ![]( images/join_002.jpg) 其中R表为外部表（Outer Table），S表为内部表（Inner Table）。这是一个最简单的算法，这个算法的开销其实非常大。假设在两张表R和S上进行联接的列都不含有索引，外表的记录数为RN，内表的记录数位SN。根据上一节对于Join算法的评判标准来看，SNLJ的开销如下表所示： ![]( images/join_003.png) 可以看到读取记录数的成本和比较次数的成本都是SN*RN，也就是笛卡儿积。假设外表内表都是1万条记录，那么其读取的记录数量和Join的比较次数都需要上亿。实际上数据库并不会使用到SNLJ算法。 ### Index Nested-Loops Join（INLJ）算法 SNLJ算法虽然简单明了，但是也是相当的粗暴。因此，在Join的优化时候，通常都会建议在内表建立索引，以此降低Nested-Loop Join算法的开销，MySQL数据库中使用较多的就是这种算法，以下称为INLJ。来看这种算法的伪代码： ```textFor each row r in R do -- 扫描R表 lookup s in S index -- 查询S表的索引（固定3~4次IO，B+树高度） If find s == r -- 如果r匹配了索引s Then output the tuple &lt;r, s&gt; -- 返回结果集 由于内表上有索引，所以比较的时候不再需要一条条记录进行比较，而可以通过索引来减少比较，从而加速查询。整个过程如下图所示： 可以可看到外表中的每一条记录通过内表的索引进行访问，即读取外行表的一行数据，然后去内部表索引进行二分法匹配；而一般的B+数的高度为3~4层，也就是或匹配一次的IO也就是3~4次，因此索引查询的成本是比较固定的，故优化器都倾向于使用记录数少的表作为外表。故INLJ的算法成本如下表所示： 上表Smatch表示通过索引找到匹配的记录数量。同时可以发现，通过索引可以大幅降低内表的Join的比较次数，每次比较1条外表的记录，其实就是一次indexlookup（索引查找），而每次index lookup的成本就是树的高度，即IndexHeight。 INLJ的算法并不复杂，也算简单易懂。但是效率是否能达到用户的预期呢？其实如果是通过表的主键索引进行Join，即使是大数据量的情况下，INLJ的效率亦是相当不错的。因为索引查找的开销非常小，并且访问模式也是顺序的（假设大多数聚集索引的访问都是比较顺序的）。 大部分人诟病MySQL的INLJ慢，主要是因为在进行Join的时候可能用到的索引并不是主键的聚集索引，而是辅助索引，这时INLJ的过程又需要多一步Fetch的过程，而且这个过程开销会相当的大： 由于访问的是辅助索引，如果查询需要访问聚集索引上的列，那么必要需要进行回表取数据，看似每条记录只是多了一次回表操作，但这才是INLJ算法 最大的弊端。首先，辅助索引的index lookup是比较随机I/O访问操作。其次，根据index lookup再进行回表又是一个随机的I/O操作。所以说， INLJ最大的弊端是其可能需要大量的离散操作，这在SSD出现之前是最大的瓶颈。而即使SSD的出现大幅提升了随机的访问性能， 但是对比顺序I/O，其还是慢了很多，依然不在一个数量级上。 另外，在INNER JOIN中，两张联接表的顺序是可以变换的，即R INNER JOIN S ON Condition P等效于S INNER JOIN R ON Condition P。 根据前面描述的Simple Nested-Loops Join算法，优化器在一般情况下总是选择将联接列含有索引的表作为内部表。如果两张表R和S在联接列上都有索引， 并且索引的高度相同，那么优化器会选择记录数少的表作为外部表，这是因为内部表的扫描次数总是索引的高度，与记录的数量无关。所以，联接列只要 有一个字段有索引即可，但最好是数据集多的表有索引；但是，但有WHERE条件的时候又另当别论了。 Block Nested-Loops Join（BNL）算法 在有索引的情况下，MySQL会尝试去使用Index Nested-Loop Join算法，在有些情况下，可能Join的列就是没有索引，那么这时MySQL的选择绝对不会 是最先介绍的Simple Nested-Loop Join算法，因为那个算法太粗暴，不忍直视。数据量大些的复杂SQL估计几年都可能跑不出结果。 而Block Nested-Loop Join算法较Simple Nested-Loop Join的改进就在于可以减少内表的扫描次数，甚至可以和Hash Join算法一样， 仅需扫描内表一次。其使用Join Buffer（联接缓冲）来减少内部循环读取表的次数。 12345For each tuple r in R do -- 扫描外表R store used columns as p from R in Join Buffer -- 将部分或者全部R的记录保存到Join Buffer中，记为p For each tuple s in S do -- 扫描内标S If p and s satisfy the join condition -- p与s满足join条件 Then output the tuple -- 返回为结果集 可以看到相比Simple Nested-Loop Join算法，Block Nested-LoopJoin算法仅多了一个所谓的Join Buffer，为什么这样就能减少内表的扫描次数呢？下图相比更好地解释了Block Nested-Loop Join算法的运行过程： 可以看到Join Buffer用以缓存联接需要的列，然后以Join Buffer批量的形式和内表中的数据进行联接比较。就上图来看，记录r1，r2 … rT的联接仅需扫内表一次，如果join buffer可以缓存所有的外表列，那么联接仅需扫描内外表各一次，从而大幅提升Join的性能。 Mysql数据库使用Join Buffer的原则如下： 系统变量Join_buffer_size决定了Join Buffer的大小。 Join Buffer可被用于联接是ALL、index、和range的类型。 每次联接使用一个Join Buffer，因此多表的联接可以使用多个Join Buffer。 Join Buffer在联接发生之前进行分配，在SQL语句执行完后进行释放。 Join Buffer只存储要进行查询操作的相关列数据，而不是整行的记录。 Batched Key Access Join（BKA）算法Index Nested-Loop Join虽好，但是通过辅助索引进行联接后需要回表，这里需要大量的随机I/O操作。若能优化随机I/O，那么就能极大的提升Join的性能。为此，MySQL 5.6（MariaDB 5.3）开始支持Batched Key Access Join算法（简称BKA），该算法通过常见的空间换时间，随机I/O转顺序I/O，以此来极大的提升Join的性能。 在说明Batched Key Access Join前，首先介绍下MySQL 5.6的新特性mrr——multi range read。因为这个特性也是BKA的重要支柱。MRR优化的目的就是为了减少磁盘的随机访问，InnoDB由于索引组织表的特性，如果你的查询是使用辅助索引，并且有用到表中非索引列（投影非索引字段，及条件有非索引字段），因此需要回表读取数据做后续处理，过于随机的回表会伴随着大量的随机I/O。这个过程如下图所示： 而mrr的优化在于，并不是每次通过辅助索引读取到数据就回表去取记录，范围扫描（range access）中MySQL将扫描到的数据存入read_rnd_buffer_size，默认256K。然后对其按照Primary Key（RowID）排序，然后使用排序好的数据进行顺序回表，因为我们知道InnoDB中叶子节点数据是按照PRIMARY KEY（ROWID）进行排列的，那么这样就转换随机读取为顺序读取了。这对于IO-bound类型的SQL查询语句带来性能极大的提升。 MRR优化可用于range，ref，eq_ref类型的查询，工作方式如下图： 即增加一次排序，将回表的随机IO改为顺序IO,从而提升性能，其算法伪代码如下：123456For each tuple r in R do -- 扫描外部表R store used columns as p from R in join buffer -- 将部分或者全部R的记录保存到Join Buffer中，记为p For each tuple s in S do -- If p and s satisfy the join condition use mrr inter face to sort row Id Then output the tuple &lt;p,s&gt; 总结 Join时，扫描外表(驱动表)一次，然后和内表进行匹配 当关联键为主键索引时，与内表匹配走索引(非全表扫描)，减少IO,提升性能 当关联表为辅助索引时，引入缓存区，将关联查询的列存储在缓存区，批量与内表匹配，减少IO,提升性能（但是依旧无法避免因为回表而导致的随机IO问题） 当关联表为辅助索引时，引入缓存区，在上面的基础上在回表之前将主键索引排序后，随机IO转为顺序IO提升性能 一般选取记录数量小的的表做外表，关联键为索引的表做内表(最好是主键索引，比较次数就会稳定在3~4次)","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"03_索引的建立&优化","date":"2019-01-14T16:31:00.000Z","path":"2019/01/15/01-03_索引的建立&优化/","text":"索引的建立&amp;优化建索引的几大规则 查询中与其他表关联的字段，外键关系建立索引; 频繁更新的字段不适合创建索引，因为每次更新还需要更新索引文件; 数据量大于500W或者单表数据大于2G时，此时索引的效果已经不明显了，这是就改考虑分库分表了; 尽量选择区分度高的列作为索引，区分度的公式为：count(distinct &lt;col&gt;)/count(*), 表示字段不重复的额比例，比例越大扫描的记录数越少; 尽量扩展索引，而不要新建索引。例如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原有的a索引即可，索引维护也需要代价; 字符串建立索引时可指定长度，不一定非要将整个字段列作为索引; 索引优化 应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描; 能用between…and…就不要用in; 避免使用or来连接条件，否则将导致放弃索引采用索引扫描(使用union代替or); 依据最左前缀匹配原则，like字段使用时避免使用全模糊匹配(%word%)，而应尽量采用右模糊匹配(word%); 避免在where字句中对字段进行函数操作，这将导致放弃使用索引而使用全表扫描;","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"explain查看执行计划","date":"2019-01-14T15:33:00.000Z","path":"2019/01/14/04-explain查看执行计划/","text":"Explain关键字查看执行计划1.是什么explain命令是mysql提供的一个查看sql执行计划的命令。 2.使用场景&nbsp;&nbsp;在工作中我们免不了会遇到各种SQL调优，SQL调优的第一步就是定位执行效率差的SQL，并判断为何执行效率差，这时候explain命令就派上用场了，可以帮我们查看sql的执行计划，例如是否使用了索引，是全表扫描还是索引扫描，这些都可以通过执行计划判断。 3.如何使用&nbsp;&nbsp;使用方式在sql语句前加上explain关键词即可。 4.参数详解&nbsp;&nbsp;知道用法当然没什么作用，我们得知道执行计划中各个参数表达的含义，才能对症下药，有针对性的优化SQL，接下来我们来看重要参数的含义：1234567891011121314151617181920212223242526272829303132mysql&gt; select version();+-----------+| version() |+-----------+| 5.6.26 |+-----------+drop database if exists 'test';create database test;use test;-- 用户表drop table if exisits `user`;create table `user`( id int primary key auto_increment, `name` varchar(20) not null comment '用户名')engine=innodb charset=utf8 comment '用户表';mysql&gt; explain select * from user where id=1\\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user partitions: NULL type: constpossible_keys: PRIMARY key: PRIMARY key_len: 4 ref: const rows: 1 filtered: 100.00 Extra: NULL explain命令输出的记过包含：id, select_type, table, type, possible_keys, key, key_len, ref, rows, filtered, extra 4.1 id 为一组数字，表示查询中执行select字句或者操作表的顺序。 123456789101112131415161718192021222324252627mysql&gt; explain select * from user a where a.id in (select id from user b where b.name like 'user%')\\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: b partitions: NULL type: ALLpossible_keys: PRIMARY key: NULL key_len: NULL ref: NULL rows: 5 filtered: 20.00 Extra: Using where*************************** 2. row *************************** id: 1 select_type: SIMPLE table: a partitions: NULL type: eq_refpossible_keys: PRIMARY key: PRIMARY key_len: 4 ref: test_1.b.id rows: 1 filtered: 100.00 Extra: NULL 4.2select_type 表示select查询的类型 select_type属性有一下几种类型： SIMPLE：简单查询，该查询不包含 UNION 或子查询 PRIMARY：如果查询包含UNION 或子查询，则最外层的查询被标识为PRIMARY UNION：表示此查询是 UNION 中的第二个或者随后的查询 DEPENDENT：UNION 满足 UNION 中的第二个或者随后的查询，其次取决于外面的查询 UNION RESULT：UNION 的结果 SUBQUERY：子查询中的第一个select语句(该子查询不在from子句中) DEPENDENT SUBQUERY：子查询中的 第一个 select，同时取决于外面的查询 DERIVED：包含在from子句中子查询(也称为派生表) UNCACHEABLE SUBQUERY：满足是子查询中的第一个 select 语句，同时意味着 select 中的某些特性阻止结果被缓存于一个 Item_cache 中 UNCACHEABLE UNION：满足此查询是 UNION 中的第二个或者随后的查询，同时意味着 select 中的某些特性阻止结果被缓存于一个 Item_cache 中 4.3table 该列表示对应行正在访问的数据库表，存在别名时显示别名。 4.4type 这个参数表示关联类型或者访问类型，即MySQL决定采用何种策略查找表中的行，这也是我们调优时重点关注的列。 执行效率： const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL以下为常见取值： ALL: 全表扫描，这个类型是性能最差的查询之一，通常来讲我们的查询不应该出现ALL类型，因为这样的查询在数据量大的情况下对数据库的性能损耗是巨大的。 index: 全索引扫描，和ALl类型类似，只不过ALL类型是全表扫描。而 index 类型是扫描全部的索引，主要优点是避免了排序，但是开销仍然非常大。如果在 Extra 列看到 Using index，说明正在使用覆盖索引，只扫描索引的数据，它比按索引次序全表扫描的开销要少很多。 range: 范围查找，就是一个有限制的索引扫描，它开始于索引里的某一点，返回匹配这个值域的行。这个类型通常出现在 =、&lt;&gt;、&gt;、&gt;=、&lt;、&lt;=、ISNULL、&lt;=&gt;、BETWEEN、IN() 的操作中，key 列显示使用了哪个索引，当 type 为该值时，则输出的 ref 列为 NULL，并且 key_len列是此次查询中使用到的索引最长的那个。 ref：一种索引访问，也称索引查找，它返回所有匹配某个单个值的行。此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引, 或者是使用了最左前缀规则索引的查询。 eq_ref：使用这种索引查找，最多只返回一条符合条件的记录。在使用唯一性索引或主键查找时会出现该值，非常高效。 const、system：该表至多有一个匹配行，在查询开始时读取，或者该表是系统表，只有一行匹配。其中 const 用于在和 primary key 或 unique索引中有固定值比较的情形。 NULL: 在执行阶段不需要访问表。 4.5possible_keys 表示查询可能使用哪些索引来查找 4.6key 表示MySQL实际决定使用的索引。如果没有选择索引，键是NULL。 4.7key_len 表示在所引力使用的字节数，当key列为NULL时，此值为NULL 4.8ref 表示哪些字段或者常量被用来和key配合从表中查询记录 4.9rows 表示估计要找到所需的行而要读取的行数，这个值是个估计值，原则上值越小越好。 4.10extra 附加信息 常见的取值如下： Using index：使用覆盖索引，表示查询索引就可查到所需数据，不用扫描表数据文件，往往说明性能不错。 Using Where：在存储引擎检索行后再进行过滤，使用了where从句来限制哪些行将与下一张表匹配或者是返回给用户。 Using temporary：在查询结果排序时会使用一个临时表，一般出现于排序、分组和多表 join 的情况，查询效率不高，建议优化。 Using filesort：对结果使用一个外部索引排序，而不是按索引次序从表里读取行，一般有出现该值，都建议优化去掉，因为这样的查询 CPU 资源消耗大。","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"02_索引类型&种类","date":"2019-01-14T15:21:00.000Z","path":"2019/01/14/01-02_索引类型&种类/","text":"索引的类型 &amp; 种类 之前已经讨论过关于Innodb索引的实现原理了，那么我们今天就来了解一下mysql的索引到底有哪些 1.索引的类型 Mysql目前主要有以下几种索引类型： FullText(全文索引) Hash(哈希索引) B-Tree(B数索引) R-Tree(空间数据索引) 1.1FullText(全文索引) 介绍 即为全文索引，它的出现是为了解决WHERE name LIKE “%word%”这类针对文本的模糊查询效率较低的问题。它有如下的限制条件： 目前只有MyISAM引擎支持(Innodb5.6以上也支持); 只有 CHAR, VARCHAR, TEXT列上可以创建全文索引; 必须采用指定的函数才会生效:MATCH()…AGAINST 示例`sql– 模拟数据库DROP DATABASE IF EXISTS myisam_db;CREATE DATABASE myisam_db;USE myisam_db; – 文章表DROP TABLE IF EXISTS article;CREATE TABLE article (id INT ( 10 ) PRIMARY KEY AUTO_INCREMENT,title VARCHAR(100) NOT NULL COMMENT ‘标题’,content TEXT COMMENT ‘文章内容’) ENGINE = INNODB DEFAULT CHARSET = utf8 COMMENT ‘文章表’; – 在title，content列上建立全文索引ALTER TABLE article ADD FULLTEXT INDEX fulltext_article(title,content); – 插入模拟数据TRUNCATE TABLE article;INSERT INTO article(title,content) VALUES(‘title001标题’,’content内容1’);INSERT INTO article(title,content) VALUES(‘title002标题’,’content内容2’);INSERT INTO article(title,content) VALUES(‘title003标题’,’content内容3’);INSERT INTO article(title,content) VALUES(‘title004标题’,’content内容4’);INSERT INTO article(title,content) VALUES(‘title005标题’,’content内容5’); – 查询EXPLAIN SELECT FROM article WHERE title LIKE ‘t%’;** 1. ROW *** id: 1 select_type: SIMPLE TABLE: article PARTITIONS: NULL TYPE: ALLpossible_keys: fulltext_article KEY: NULL key_len: NULL ref: NULL ROWS: 5 filtered: 20.00 Extra: USING WHERE EXPLAIN SELECT FROM article WHERE MATCH(title,content) AGAINST(‘t c’);** 1. ROW *** id: 1 select_type: SIMPLE TABLE: article PARTITIONS: NULL TYPE: FULLTEXTpossible_keys: fulltext_article KEY: fulltext_article key_len: 0 ref: const ROWS: 1 filtered: 100.00 Extra: USING WHERE` 1.2Hash(哈希索引) 介绍 通过计算hash至一次定位; 由InnoDB存储引擎自己控制的, DBA无法外界干预; 只能用于等值查找，不能用于范围查找; 不支持排序; 无法避免全表扫描; 1.3B-Tree(B数索引) 介绍 在01-01_索引中已经介绍过索引的BTree结构，如下： 特点： 适合等值查找，范围顺序查找; 适合左前缀模糊查找; 1.4R-Tree(空间数据索引)不常用，忽略 2.索引的种类2.1按照使用类型分以下几种索引种类： 主键索引 单表中只能存在一个主键索引，因为其聚集顺序存储，查询效率非常高(最好保持主键为递增序列，减少分页)。 唯一索引 可以存在多个，列值唯一，不能为null, 加快查询效率。 普通索引 可以存在多个，加快查询效率(可能需要回表, 下文非聚集索引会提及)。 组合索引 多列值组成一个索引，专门用于组合搜索，其效率大于索引合并。 全文索引 分词搜索。 2.2按照存储实现分为2种： 聚集索引 如上图：聚集索引就是按照每张表的主键构造一颗B+树，同时叶子结点存放的即为整张表的行纪录数据（聚集索引的叶子结点也称为数据页）。聚集索引的这个特性也决定了索引组织表中数据也是索引的一部分，和B+树数据结构一样，每个数据页之间都通过一个双向链表来进行链接。 特点： 基于主键的查找速度非常快，范围查找快 非聚集索引 非聚集索引与聚集索引相比： 叶子结点并非数据结点 叶子结点为每一真正的数据行存储一个“键-指针”对 叶子结点中还存储了一个指针偏移量，根据页指针及指针偏移量可以定位到具体的数据行 类似的，在除叶结点外的其它索引结点，存储的也是类似的内容，只不过它是指向下一级的索引页的 当查找的列不在非聚集索引中时，需要再回表一次，这属于随机IO,性能较差","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"01_索引","date":"2019-01-14T14:20:00.000Z","path":"2019/01/14/01-01_索引/","text":"索引 参考：linhaifeng-第八篇：索引原理与慢查询优化参考：张洋-MySQL索引背后的数据结构及算法原理 【目录】1.介绍2.索引的原理 2.1索引的理念 2.2磁盘IO与预读取 2.3索引的数据结构 1.介绍 为什么要用索引 &nbsp;&nbsp;在数据库操作中，占据主要地位的当属Select操作了，系统80%的操作都来自于系统的查询操作。当数据量大之后，查询的性能将成为系统的瓶颈，这时候就需要一种快速且使用的规则去满足我们查询的需求，所以用索引就是为了提高我们系统的查询效率。索引主要做了两件事：查询和排序. 索引是什么 &nbsp;&nbsp;索引是存储引擎用于快速查找数据记录的一种数据结构。 索引就像字典中的音序表(MYSQL实际实现不是)，要查找某个字，先查找音序表就能快速找到页数，不必一页一页的查找。索引对于性能的影响尤为重要，索引查询优化也是一个程序员的必修课。 2.索引的原理 接下来我们就来了解一下Mysql的Innodb引擎是如何实现索引的 2.1索引的理念&nbsp;&nbsp;以前在学习数据结构时，关于查找算法，我们知道有Hash,二分法，其实质都是通过不断的缩小数据范围，减少需要扫描的数据和次数，数据库查询也是这种理念，但是是结合查询需求和IO考量而实现的。 2.2磁盘IO与预读取 &nbsp;&nbsp;说道数据存储我们不能不考量磁盘IO的影响，那我们来看看我们的磁盘是如何加载数据的。 &nbsp;&nbsp;上图是操作系统读取不同数据的性能对比，可以看到磁盘读取和内存读取差了好几个数据量，那么数据库几百万的数据读写，磁盘的性能读写优化也很重要。&nbsp;&nbsp;考虑到磁盘IO是非常昂贵的操作，计算机系统做了一些优化-预读取。当一次IO操作是，不止加载当前磁盘地址的数据进内存，而且会把相邻地址的数据也会读取到内存中，因为局部预读性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO，这个理论对于索引的数据结构设计非常有帮助。 2.3索引的数据结构 &nbsp;&nbsp;Innodb存储引擎采用B+Tree`实现索引结构，Innodb的数据文件本身就是索引文件(MyISAM索引和数据文件是分离的)。 如图是Innodb主索引的示意图，它有如下特点： 每一个节点都对应着一个磁盘块，一个磁盘块的大小与操作系统的页大小有关，可以一次加载整个数据块到内存中; 这棵树的叶子节点data域保存了完整的数据记录，叶子节点之间连接为一条链。这种索引交聚集索引，因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。正是因为如此，使用索引查找非常快; 非叶子结点记录着关键字和指向下层数据块的指针，不存储数据记录，这样可以一次加载更多的关键字，减少IO，快速定位叶子节点; 这棵树一般在2~4层，所以IO次数不高 因为索引有序，且子节点相互连接，所以非常适合范围查找 查找过程 例如要查找30，先将根数据块加载到内存，查找判断子数据块的位置，再将子数据块加载进内存，继续查找，直到到达叶子节点，因为叶子节点直接存储着数据记录，所以直接读取即可。 索引注意的点 因为B+的这些性质，这就导致我们在编写sql时要注意以下： 索引字段尽量小：索引字段小每个数据块存储的关键字更多，减少IO,和分页的发生，更快找到叶子节点； 索引的最左匹配特性：当我们使用组合索引时，一定要注意索引的顺序，例如index(A,B,C),查询使用(A,B),(A,C),(A,B,C)均是可以使用到该索引的，但是查询使用(B),(C),(B,C)根据最左匹配规则是无法使用该索引的。 索引尽量保证有序：因为B+数是建立在排序上的，假如主键无序，可能要进行频繁的分页，同时也增加了查找的复杂度(不能使用二分法)。 选择性建立索引：因为索引在插入删除时也需要维护 下节介绍索引的分类","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"04_Innodb_redo日志","date":"2019-01-14T13:45:00.000Z","path":"2019/01/14/02-04_Innodb_redo日志/","text":"Innodb_redo日志 转载：https://www.cnblogs.com/f-ck-need-u/archive/2018/05/08/9010872.html 引言我们知道在mysql可以保证数据的一致性，即使断电停机故障，重启后也能恢复，那么它底层是如何实现的呢？这就引入了我们今天的主角redo日志。 为了最大程度避免数据写入时IO瓶颈带来的性能问题，MySQL采用预写式日志的方式来缓解磁盘读写压力。 预写式日志：当数据库中数据需要修改时，Innodb先将该数据从磁盘读取到内存中，修改内存中的数据拷贝，并将改修改行为持久化到磁盘上的事务日志(redo log buffer, 再定时批量刷新到磁盘)，这种方式因为采取批量，追加方式写入，会带来更好的性能。 redo log基本概念redo log(重做日志)，提供前滚操作，主要保证数据的完整性和可恢复性。其通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成什么样，使用它可以用来恢复断电后的数据，提交后的物理数据页（只能恢复到最后一次提交的位置）。 redo log包含两部分： 内存中的日志缓冲(redo log buffer)，该部分日志是易失性的，但可以通过配置减少丢失率； 磁盘上的重做日志文件(redo log file, 即ib_logfile*文件), 该部分日志是持久的； 原理 Innodb通过force log at commit机制实现事务的持久性，即在事务提交的时候，必须先将事务的所有事务日志写入到磁盘的redo log file和undo log file中 进行持久化。 commit日志持久化 为了确保每次日志都能写入到事务日志文件中，在每次将log buffer中的日志写入到日志文件的过程中都会调用一次操作系统的fsync操作，强制刷新数据到磁盘上。因为MySQL是工作在用户空间的，MySQL的log buffer处于用户空间的内存中，要写入到磁盘的log file中(redo:ib_logfileN文件,undo:share tablespace或.ibd文件)，中间还要经过操作系统内核空间的 OS buffer，调用fsync()的作用就是将 OS buffer 中的日志刷到磁盘上的 log file 中。过程如下图： 配置 配置commit日志刷盘策略 MySQL支持用户自定义在commit时如何将log buffer中的日志刷新到log file中。 用户可以通过变量innodb_flush_log_at_trx_commit的值来决定，该变量有3种值： 1: 默认值，当设置为1时，事务每次提交都会将log buffer中的日志写入os buffer并调用fsync()刷出到log file on disk中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差，在对数据一致性要求极高的场景使用。 2: 当设置为2时，事务每次提交都会写入到os buffer，然后每秒调用fsync()将os buffer中的日志刷新到log file on disk。只有系统出现问题时，才会丢失数据。 0: 当设置为0时，事务每次提交都不会将log buffer中的日志写入到os buffer中，而是每秒写入os buffer中并调用fsync()写入到log file on disk中。当系统崩溃，会丢失1秒数据。 在主从复制结构中，要保证事务的持久性和一致性，需要对日志相关变量设置为如下： 如果启用了二进制日志，则设置sync_binlog=1，即每提交一次事务同步写到磁盘中。 总是设置innodb_flush_log_at_trx_commit=1，即每提交一次事务都写到磁盘中。 redo log相关的参数配置 既然说到redo log 那就看看相关的一些参数配置 innodb_flush_log_at_trx_commit={0|1|2} # 指定何时将事务日志刷到磁盘，默认为1。 0表示每秒将”log buffer”同步到”os buffer”且从”os buffer”刷到磁盘日志文件中。 1表示每事务提交都将”log buffer”同步到”os buffer”且从”os buffer”刷到磁盘日志文件中。 2表示每事务提交都将”log buffer”同步到”os buffer”但每秒才从”os buffer”刷到磁盘日志文件中。 innodb_log_buffer_size：# log buffer的大小，默认8M innodb_log_file_size：#事务日志的大小，默认5M innodb_log_files_group =2：# 事务日志组中的事务日志文件个数，默认2个 innodb_log_group_home_dir =./：# 事务日志组路径，当前目录表示数据目录 innodb的恢复行为","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"03_Innodb引擎RR下如何避免幻读","date":"2019-01-13T16:51:00.000Z","path":"2019/01/14/02-03_Innodb引擎RR下如何避免幻读/","text":"Innodb引擎RR下如何避免幻读前言&nbsp;&nbsp;我们知道Innodb默认的事务隔离级别是Repeatable-Read, 这种隔离级别下解决了不可重复读的问题，同时部分解决了幻读的问题，这次我们就来谈论它是如何避免幻读的。关键词：锁，MVCC, Next-key Lock 基础概念排它锁(X锁)和共享锁(S锁) 所谓X锁,是事务T对数据A加上X锁时,只允许事务T读取和修改数据A,类似于写锁； 1select * from tableName where ... for update; 所谓S锁,是事务T对数据A加上S锁时,其他事务只能再对数据A加S锁,而不能加X锁,直到T释放A上的S锁，类似于读锁；1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253select * from tableName where ... + lock in share mode;``` ### 行锁和表锁 &gt; 行锁，小粒度锁，只锁部分数据行 &gt; 表锁，大粒度锁，锁定整张数据表 **对比**： | 对比 | 行锁 | 表锁 | | :--: | :--: | :--: | | 优势 | 粒度小，并发能力强，锁冲突概率低|操作简单，开销小 | | 劣势 | 开销大，加锁满，会出现死锁|并发能力弱 | ### 行锁(Record Lock)和间隙锁(Gap Lock)，Next-Key Lock * **行锁**：锁定当前行，行锁锁定的是``索引``，而不是行数据，也就是针对索引加的锁，不是针对记录加的锁。所以当做更新删除操作时，检索条件不是索引，则都会从行锁升级为表锁。**特例，及时使用了索引，但是索引值不存在时会升级为间隙锁。** * **间隙锁**：锁定索引记录间隙，确保索引记录的间隙不变。间隙锁是针对事务隔离级别为可重复读或以上级别而已的，（无论是S还是X）``只会阻塞insert操作。``另一个事务通过范围条件加锁时，如果使用相等条件请求给一个不存在的记录加锁都会使用间隙锁。* **Next-Key Lock**: 行锁和间隙锁和组合，首先对选中的索引记录加上行锁（Record Lock），再对索引记录两边的间隙（向左扫描扫到第一个比给定参数小的值， 向右扫描扫描到第一个比给定参数大的值， 然后以此为界，构建一个区间）加上间隙锁（Gap Lock）。如果一个间隙被事务T1加了锁，其它事务是不能在这个间隙内插入记录的。Innodb引擎采用这种方式来避免当前出现的幻读。**当查询的索引含有唯一属性时，将next-key lock降级为record key** ### 快照读和当前读 * 快照读：即普通的select操作,读取的是历史快照数据,利用MVCC模式实现。 * 当前读：select时指定了锁，for update，lock in share mode。读取的是最新的数据。 ### MVCC(多版本控制) &amp;nbsp;&amp;nbsp;Mysql的Innodb引擎在Repeatable-Read隔离级别下采用MVCC不加锁的方式来代替加锁操作。 #### 实现方式 &amp;nbsp;&amp;nbsp;Innodb的MVCC, 是通过在每行记录后面保存两个隐藏的列来实现的，这两个列分别保存了这行记录的创建时间和删除时间。但在实际的实现里存储的当前的系统版本号(可以理解为事务的ID)。一旦开始一个新的事务，系统的版本号就会递增，事务开始时刻的系统版本号会作为事务的ID,为了避免幻读查询时只会查询创建版本号小于当前事务版本号，删除版本号大于当前事务版本号(保证事务开始前该记录未删除)的记录。 ### 实例分析 ```sqlmysql&gt; select version();+-----------+| version() |+-----------+| 5.6.26 |+-----------+drop database if exists 'test';create database test;use test;-- 用户表drop table if exisits `user`;create table `user`( id int primary key auto_increment, `name` varchar(20) not null comment '用户名')engine=innodb charset=utf8 comment '用户表'; insert&nbsp;&nbsp;Innodb为插入的每一行记录保存当前系统的版本号作为创建版本号，查询只会查询出创建版本号小于当前事务id的记录。12345678910111213141516171819begin;insert into user(name) values('user_01');insert into user(name) values('user_02');insert into user(name) values('user_03');commit;``` 我们看看实际的存储情况： | id | name | 创建版本号 | 删除版本号 | |:--:|:--:|:--:|:--:| | 1 | user_01 | 1 | undefined | | 2 | user_02 | 1 | undefined | | 3 | user_03 | 1 | undefined | #### delete &amp;nbsp;&amp;nbsp;InnoDB会为删除的每一行保存当前系统的版本号(事务的ID)作为删除标识，只会查询出删除版本号大于当前事务版本号(保证事务开始前该记录未删除)的记录。 ![delete]( images/tx_mvcc_delete.png) 步骤2：事务1查询结果为三条记录；步骤3：事务2删除id=2的记录；步骤4：事务1查询结果为三条记录；这是事务2未提交步骤5：事务2提交；步骤6：事务1查询结果依旧为三条记录；事务1提交后查询结果为最新数据1234567891011121314151617181920212223我们看看事务2提交后实际的存储情况： | id | name | 创建版本号 | 删除版本号 | |:--:|:--:|:--:|:--:| | 1 | user_01 | 1 | undefined | | 2 | user_02 | 1 | 3 | | 3 | user_03 | 1 | undefined | 因为查询时会查询出来删除版本号大于当前事务号的记录，所以事务2提交了删除，事务1还是保证了重复读。#### select InnoDB会根据以下两个条件检查每行记录: a.InnoDB只会查找版本早于当前事务版本的数据行(也就是,行的系统版本号小于或等于事务的系统版本号)，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的. b.行的删除版本要么未定义,要么大于当前事务版本号,这可以确保事务读取到的行，在事务开始之前未被删除. 只有a,b同时满足的记录，才能返回作为查询结果. #### update InnoDB执行UPDATE，实际上是新插入了一行记录，并保存其创建时间为当前事务的ID，同时保存当前事务ID到要UPDATE的行的删除时间. ```sqlbegin; //当前事务id=4update user set name='user_3' where id=3;commit; 实际的存储情况如下所示： id name 创建版本号 删除版本号 1 user_01 1 undefined 2 user_02 1 3 3 user_03 1 4 3 user_3 5 undefined 结论有了MVCC就可以在不加锁的情况下读取数据，同时采用乐观更新的策略提高并发度。 Innodb在Repeatable-Read隔离级别下如何避免幻读 在快照读情况下，mysql通过mvcc来避免幻读。 在当前读情况下，mysql通过next-key lock来避免幻读。","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"04_mysql日志","date":"2019-01-13T15:37:00.000Z","path":"2019/01/13/02-04_mysql日志/","text":"mysql日志介绍无论是哪个数据库产品，都一定会有各种各样的日志文件，而在MySQL中主要有这5中日志文件： 错误日志(error log): 记录MySQL服务启动，运行和停止过程中的日志信息。 查询日志(general log): 记录客户端连接和执行的信息。 慢查询日志(slow log): 记录所有执行时间超过long_query_time的所有查询或者不使用索引的查询。 二进制日志(bin log): 记录所有更改数据的语句，可用于数据复制。 中继日志(relay log): 主从复制时，从机使用的日志。 事务日志: redo, undo日志 错误日志(error log)日志是很重要的日志之一，它记录了MySQL服务启动，运行和停止过程中的日志信息。可以通过在配置文件指定--log-error=&lt;file_name&gt;来指定错误日志文件，如果没有指定，则默认的错误日志为datadir目录下的hostname.err文件(hostname为当前主机名)。 如果不清楚错误日志的位置，可以查询变量log_error来查看。123456mysql&gt; show variables like 'log_error';+---------------+----------------------------------------+| Variable_name | Value |+---------------+----------------------------------------+| log_error | /var/log/mysqld.log+---------------+----------------------------------------+ 查询日志(general log)使用--general_log={0|1}来决定是否启用一般查询日志，使用--general_log_file=&lt;file_name&gt;来指定查询日志的路径。不给定路径时默认的文件名以 hostname.log 命名。 查询日志相关变量有：123general_log=off # 是否启用一般查询日志，为全局变量，必须在global上修改。sql_log_off=off # 在session级别控制是否启用一般查询日志，默认为off，即启用general_log_file=/mydata/data/hostname.log # 默认是库文件路径下主机名加上.log 查看和设置日志12mysql&gt; SELECT @@global.general_log;mysql&gt; set @@global.general_log=1; 慢查询日志慢查询日志对于我们线上调用耗时问题的排查十分重要。可以通过指定long_query_time指定时间阈值。注意：mysql记录慢查询日志是在查询执行完毕且已经完全释放锁之后才记录的因此慢查询日志记录的顺序和执行的SQL查询语句顺序可能不一致; 另外，指定的慢查询超时时长是指超出这个时间的才算慢查询，等于这个时间的不会记录。 慢查询相关变量：123456long_query_time=10 # 指定慢查询超时时长(默认10秒)，超出此时长的属于慢查询log_output=&#123;TABLE|FILE|NONE&#125; # 定义一般查询日志和慢查询日志的输出格式，默认为filelog_slow_queries=&#123;yes|no&#125; # 是否启用慢查询日志，默认不启用slow_query_log=&#123;1|ON|0|OFF&#125; # 也是是否启用慢查询日志，此变量和log_slow_queries修改一个另一个同时变化slow_query_log_file=/var/lib/mysql/hostname-slow_query.log #默认路径为库文件目录下主机名加上-slow.loglog_queries_not_using_indexes=OFF # 查询没有使用索引的时候是否也记入慢查询日志 测试 启用慢查询日志 123456789101112131415161718mysql&gt; select @@global.slow_query_log;+-------------------------+| @@global.slow_query_log |+-------------------------+| 0 |+-------------------------+1 row in set (0.00 sec)mysql&gt; set @@global.slow_query_log=1;Query OK, 0 rows affected (0.01 sec)mysql&gt; select @@global.slow_query_log;+-------------------------+| @@global.slow_query_log |+-------------------------+| 1 |+-------------------------+1 row in set (0.00 sec) 2.配置时间阈值1234567mysql&gt; select @@global.long_query_time;+--------------------------+| @@global.long_query_time |+--------------------------+| 10.000000 |+--------------------------+1 row in set (0.00 sec) 3.查看日志文件位置123456789101112131415mysql&gt; select @@global.log_output;+---------------------+| @@global.log_output |+---------------------+| FILE |+---------------------+1 row in set (0.00 sec)mysql&gt; select @@global.slow_query_log_file;+-----------------------------------+| @@global.slow_query_log_file |+-----------------------------------+| /var/lib/mysql/localhost-slow.log |+-----------------------------------+1 row in set (0.00 sec) 4.测试一个11s的查询1234567mysql&gt; select sleep(11);+-----------+| sleep(11) |+-----------+| 0 |+-----------+1 row in set (11.01 sec) 5.查看慢查询日志12345678910[root@localhost]# vi /var/lib/mysql/localhost-slow.log /usr/sbin/mysqld, Version: 5.7.17-log (MySQL Community Server (GPL)). started with:Tcp port: 3306 Unix socket: /var/lib/mysql/mysql.sockTime Id Command Argument# Time: 2019-04-09T08:07:03.990025Z# User@Host: root[root] @ localhost [] Id: 3# Query_time: 11.000576 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0SET timestamp=1554797223;select sleep(11); 拓展随着时间的推移，慢查询日志文件会变得越来越大，这对于分析查询来说是非常困难的，好在mysql已经为我们提供了一个专门用来归类慢查询日志的工具mysqldumpslow123456789101112131415161718192021222324[root@localhost]# mysqldumpslow --help --verbose verbose --debug debug --help write this text to standard output -v verbose -d debug -s ORDER what to sort by (al, at, ar, c, l, r, t), &apos;at&apos; is default al: average lock time ar: average rows sent at: average query time c: count l: lock time r: rows sent t: query time -r reverse the sort order (largest last instead of first) -t NUM just show the top n queries -a don&apos;t abstract all numbers to N and strings to &apos;S&apos; -n NUM abstract numbers with at least n digits within names -g PATTERN grep: only consider stmts that include this string -h HOSTNAME hostname of db server for *-slow.log filename (can be wildcard), default is &apos;*&apos;, i.e. match all -i NAME name of server instance (if using mysql.server startup script) -l don&apos;t subtract lock time from total time 该工具归类的时候，默认会将同文本但变量值不同的查询语句视为同一类，并使用N代替其中的数值变量，使用S代替其中的字符串变量。可以使用-a来禁用这种替换; 归类后的结果只是精确到0.01秒的，如果想要显示及其精确的秒数，则使用-d选项启用调试功能; 12345678910111213141516171819[root@localhost]# mysqldumpslow /var/lib/mysql/localhost-slow.log Reading mysql slow query log from /var/lib/mysql/localhost-slow.logCount: 1 Time=0.00s (0s) Lock=0.00s (0s) Rows=0.0 (0), 0users@0hosts # Time: N-N-09T08:N:N.990025Z # User@Host: root[root] @ localhost [] Id: N # Query_time: N.N Lock_time: N.N Rows_sent: N Rows_examined: N SET timestamp=N; select sleep(N)[root@localhost]# mysqldumpslow -a /var/lib/mysql/localhost-slow.log Reading mysql slow query log from /var/lib/mysql/localhost-slow.logCount: 1 Time=0.00s (0s) Lock=0.00s (0s) Rows=0.0 (0), 0users@0hosts # Time: 2019-04-09T08:07:03.990025Z # User@Host: root[root] @ localhost [] Id: 3 # Query_time: 11.000576 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0 SET timestamp=1554797223; select sleep(11) 二进制日志(bin log)二进制binlog日志在主从同步复制和定点恢复数据库功能中发挥着重要的作用，详情查阅：mysql binlog日志 中继日志(replay log)中继日志在主从同步复制时，在从机上发挥作用。","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"02_Mysql执行顺序","date":"2019-01-13T14:51:00.000Z","path":"2019/01/13/03-02_Mysql执行顺序/","text":"Mysql的执行顺序 Mysql的查询解析器，会对我们的sql进行解析生成一颗语法树, 进而判断语法错误，优化调整执行顺序，我们来看看Mysql是按照什么样的顺序来执行各个关键字的： (8) SELECT (9) DISTINCT &lt;select_list&gt; (1) FROM &lt;left_table&gt; (3) &lt;join_type&gt; JOIN &lt;right_table&gt; (2) ON &lt;join_condition&gt; (4) WHERE &lt;where_condition&gt; (5) GROUP BY &lt;group_by_list&gt; (6) WITH {CUBE|ROLLUP} (7) HAVING &lt;having_condition&gt; (10) ORDER BY &lt;order_by_list&gt; (11) LIMIT &lt;limit_number&gt; 可以看到执行的顺序如上面的编号，from，join, on, where, group by, having, select,distinct, order by, limit.每一个操作都会产生一张虚拟表，该虚拟表作为一个处理的输入。这些虚拟表对用户是透明的，只有最后一步生成的虚拟表才会返回给用户。","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"04_Innodb_undo日志","date":"2019-01-13T14:30:00.000Z","path":"2019/01/13/02-04_Innodb_undo日志/","text":"Innodb_undo日志 标签：undo log, mysql转载：undo log 介绍undo log的定义undo log主要记录的是数据的逻辑变化，为了在发生错误时回滚之前的操作，需要将之前的操作都记录下来，然后在发生错误的时候才可以回滚。 undo log的作用undo log 有两个作用： 用于事务的回滚 MVCC 在数据修改的时候，不仅记录了redo log，还记录了相对应的undo log,如果因为某些原因导致事务失败或者回滚了，可以借助undo log进行回滚。 undo log和redo log记录物理日志不一样，它记录的是逻辑日志。**可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然；当update一条记录时，它记录一条对应相反的update记录。","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"02_Innodb存储引擎事务的隔离级别","date":"2019-01-13T14:29:00.000Z","path":"2019/01/13/02-02_Innodb存储引擎事务的隔离级别/","text":"Innodb存储引擎事务的隔离级别","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"Mysql解决断电启动失败问题","date":"2019-01-04T17:59:00.000Z","path":"2019/01/05/03-Mysql解决断电启动失败问题/","text":"Mysql解决断电启动失败的问题现象还原 Windows上运行着Mysql, 而且是开机自启 有一天正在写代码，突然断电了…………… 电来了，开机，MySQL启动失败，mmp………123C:\\WINDOWS\\system32&gt;net start mysqlMySQL 服务正在启动 ........MySQL 服务无法启动。 问题排查1. 查看启动日志启动日志在数据存放目录下(配置文件中指定的datadir目录)，一个后缀为.err的文件, 查看发现了如下的错误: 发现原来是我之前手动删除过data目录下的数据(不要学我), 2. 解决方案 1.停止mysql12345C:\\WINDOWS\\system32&gt;tasklist|findstr &quot;mysql&quot;mysqld.exe 6744 Services 0 378,652 KC:\\WINDOWS\\system32&gt;taskkill /f -pid 6744成功: 已终止 PID 为 6744 的进程。 3.设置recoveryhttps://blog.csdn.net/lyhdream/article/details/787464392.删除文件 删除data目录下的ib_logfile0, ib_logfile1, ibtmp1三个文件，重启数据库123C:\\WINDOWS\\system32&gt;net start mysqlMySQL 服务正在启动 ...MySQL 服务已经启动成功。 3.刷新数据1mysqladmin -u root -p flush-tables","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"Mysql的介绍和安装","date":"2019-01-03T17:58:00.000Z","path":"2019/01/04/01-Mysql的介绍和安装/","text":"Mysql的介绍与安装 标签：MySql, Linux 介绍MySQL 是最流行的关系型数据库管理系统，在 WEB 应用方面 MySQL 是最好的 RDBMS(Relational Database Management System：关系数据库管理系统)应用软件之一。 安装安装环境 Centos7 获取源官网地址 选择DOWNLOADS =&gt; Archives =&gt; MySQL Community Server选择相应版本下载，这里我下载5.7.17 开始安装 1.建立mysql用户 1234567891011#后面mysql就使用这个用户来运行（注意这也是mysql启动脚本中默认的用户，因此最好不要改名）。$ groupadd mysql$ useradd -r -g mysql mysql（使用-r参数表示mysql用户是一个系统用户，不能登录） #建立目录/usr/local/mysql，后面mysql就安装在这个目录下面。$ mkdir /usr/local/mysql /usr/local/mysql/data#将mysql及其下所有的目录所有者和组均设为mysql:$ cd /usr/local/mysql$ chown mysql:mysql -R . 2.解压 12345#安装mysql的依赖库$yum install libaio #将前面得到的mysql-5.7.11-linux-glibc2.5-x86_64.tar.gz解压至/usr/local/mysql目录下$ tar zxvf mysql-5.7.11-linux-glibc2.5-x86_64.tar.gz -C /usr/local/mysql 3.初始化 1234567891011121314151617181920$ /usr/local/mysql/bin/mysqld \\ --initialize --user=mysql \\ --datadir=/usr/local/mysql/data \\ --basedir=/usr/local/mysql 注意：1. data目录解压后没有，需要手动建立（见上文）；2. mysql5.7和之前版本不同，很多资料上都是这个命令...../scripts/mysql_install_db --user=mysql而5.7版本根本没有这个。初始化成功后出现如下信息：201x-xx-xxT07:10:13.583130Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).201x-xx-xx T07:10:13.976219Z 0 [Warning] InnoDB: New log files created, LSN=45790201x-xx-xx T07:10:14.085666Z 0 [Warning] InnoDB: Creating foreign key constraint system tables.201x-xx-xx T07:10:14.161899Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 1fa941f9-effd-11e5-b67d-000c2958cdc8.201x-xx-xx T07:10:14.165534Z 0 [Warning] Gtid table is not ready to be used. Table &apos;mysql.gtid_executed&apos; cannot be opened.201x-xx-xx T07:10:14.168555Z 1 [Note] A temporary password is generated for root@localhost: q1SLew5T_6K, 注意最后一行，这也是和之有版本不同的地方，它给了root一个初始密码，后面要登录的时候要用到这个密码。 4.配置[可以跳过] 123456789101112131415161718192021$ cp /usr/local/mysql/support-files/my-default.cnf /etc/my.cnf$ vi /etc/my.cnf [client] socket=/var/lib/mysql/mysql.sock [mysqld] #用于找回密码 #skip-grant-tables #忽略表名大小写，linux区分大小写的，windows不区分 lower_case_table_names=1 sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES basedir=/usr/local/mysql datadir=/usr/local/mysql/data port=3306 socket=/var/lib/mysql/mysql.sock character-set-server=utf8如果不把my.cnf拷到/etc下，运行时会出现：mysqld: Can&apos;t change dir to &apos;/usr/local/mysql/data/&apos; (Errcode: 2 - No such file or directory)这样的出错提示，说明它没找到my.cnf中的配置；而去找了程序编译时的默认安装位置：/usr/local/mysql 5.启动 1234$ mysqld_safe&amp;#停止$ service mysqld stop 5.设置开机启动 123456789101112将&#123;mysql&#125;/ support-files/mysql.server 拷贝为/etc/init.d/mysql并设置运行权限 #cp mysql.server /etc/init.d/mysql#chmod +x /etc/init.d/mysql 把mysql注册为开机启动的服务#chkconfig --add mysql 【mysql开启和关闭】#/etc/init.d/mysql start#/etc/init.d/mysql stop#service mysql start 拓展 修改密码1234567$ mysqld_safe --skip-grant-tables &amp;root$ mysql -uroot -p&gt; use mysql&gt; update user set password=PASSWORD(&quot;123456&quot;) where user=&apos;root&apos;;发现报错：ERROR 1054 (42S22): Unknown column &apos;password&apos; in &apos;field list&apos;&gt; show create user //发现密码字段已经发生改变，变为`authentication_string` &gt; update user set authentication_string=password(&apos;123456&apos;) where user=&apos;root&apos;; 设置远程访问 123mysq&gt; use mysql;mysql&gt;grant all privileges on *.* to &apos;root&apos;@&apos;&apos; identified by &apos;123456&apos; with grant option;msyql&gt;flush privileges;","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"Mysql5.7-ONLY_FULL_GROUP_BY问题","date":"2019-01-03T16:25:00.000Z","path":"2019/01/04/02-Mysql5.7-ONLY_FULL_GROUP_BY问题/","text":"Mysql5.7-ONLY_FULL_GROUP_BY问题问题复现mysql 5.7之后，进行一些group by查询时，比如:1234567SELECT *, count(id) as count FROM `news` GROUP BY `group_id` ORDER BY `inputtime` DESC LIMIT 20;``` 就会报错： ```sql SELECT list is not in GROUP BY clause and contains nonaggregated column ‘news.id' which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by. 分析与解决分析原因是mysql 5.7模式中，默认启用了ONLY_FULL_GROUP_BY。ONLY_FULL_GROUP_BY是Mysql提供的一个sql_mode,通过这个sql_mode来提供group by合法性的检查。其要求查询的字段必须全部都应该在group by分组条件内。 解决方案123SET @@sql_mode ='STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION';SET @@global.sql_mode ='STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION';SELECT @@global.sql_mode;","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"Mysql主从同步","date":"2019-01-03T15:28:00.000Z","path":"2019/01/03/04-Mysql主从同步/","text":"Mysql主从同步 标签：Mysql, 主从同步 1. 介绍1.1 主从复制概念Mysql主从复制是指数据可以从一个Mysql数据库主节点复制到所有的从节点中，从而保证所有节点的数据一致性。 1.2 主从复制主要的用途 读写分离 业务中大部分的场景是读多写少，然而写操作需要锁表，导致读操作阻塞，从而降低了系统的吞吐量，假如可以读写分离，写操作在主节点，读操作在从节点，在利用同步机制保证数据的同步，这样便可以提高系统的处理能力。 高可用 2. 原理介绍当master服务器的数据发生改变时，会将其记录进二进制文件binlog日志中，salve服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/OThread请求master二进制事件，同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中，从节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后I/OThread和SQLThread将进入睡眠状态，等待下一次被唤醒。流程图如下： 2.1 复制方式mysql复制主要有三种方式： 基于SQL语句的复制(statement-based replication) 基于行的复制(row-based replication) 混合模式复制(mixed-based replication)。 对应的，binlog的格式也有三种：STATEMENT，ROW，MIXED。 STATEMENT模式 每一条会修改数据的sql语句会记录到binlog中。优点是并不需要记录每一条sql语句和每一行的数据变化，减少了binlog日志量，节约IO，提高性能。缺点是在某些情况下会导致master-slave中的数据不一致(如sleep()函数， last_insert_id()，以及user-defined functions(udf)等会出现问题) ROW模式（RBR） 不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了，修改成什么样了。而且不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题。缺点是会产生大量的日志，尤其是alter table的时候会让日志暴涨。 MIXED模式（MBR） 以上两种模式的混合使用，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog，MySQL会根据执行的SQL语句选择日志保存方式。 3. 环境搭建3.1 服务器配置 Ip 配置 172.16.22.135 Centos7 2CPU 2G内存 40G硬盘, Mysql5.7.17 172.16.22.136 Centos7 2CPU 2G内存 40G硬盘, Mysql5.7.17 本次模拟搭建一主一从结构 3.2 Master配置3.2.1 配置文件修改12345678910111213141516171819202122232425262728293031323334353637# vi /etc/my.cnf #修改配置文件[mysqld]#数据存储目录datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sock#忽略大小写lower_case_table_names=1port = 3306#error日志log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid#生成binlog日志log-bin=/var/lib/mysql/mysql-bin#服务ID，用于区分服务，范围1~2^32-1,需要与从服务器不同server_id=135#MySQL 磁盘写入策略以及数据安全性#每次事务提交时MySQL都会把log buffer的数据写入log file，并且flush(刷到磁盘)中去innodb_flush_log_at_trx_commit=1#当sync_binlog =N (N&gt;0) ，MySQL 在每写 N次 二进制日志binary log时，会使用fdatasync()函数将它的写二进制日志binary log同步到磁盘中去。#sync_binlog 的默认值是0，像操作系统刷其他文件的机制一样，MySQL不会同步到磁盘中去而是依赖操作系统来刷新binary log。sync_binlog=1#同步数据库，如果多库，就以此格式另写几行即可binlog-do-db=test_0001#无需同步的数据库binlog-ignore-db=mysqlbinlog-ignore-db=performance_schemabinlog-ignore-db=information_schema#mysql复制模式binlog_format=ROW#binlog过期清理时间expire_logs_days=7#binlog每个日志文件大小max_binlog_size=20M 3.2.2 重启服务1234567# systemctl restart mysqld# mysql -uroot -p123456 -e &apos;show master status&apos;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 | 573 | | | |+------------------+----------+--------------+------------------+-------------------+ 记录下上面查询出来的File和Position 3.2.3 创建并授权用户123456# mysql -uroot -ppassword:mysql&gt; GRANT REPLICATION SLAVE ON *.* TO &apos;root&apos;@&apos;172.16.22.%&apos; IDENTIFIED BY &apos;123456&apos; WITH GRANT OPTION;mysql&gt; FLUSH PRIVILEGES;mysql&gt; FLUSH tables with read lock; #锁定数据库为只读，确保备份数据一致性 3.2.4 备份数据库123# mysqldump -u root -p --master-data test_0001&gt; dbdump.sql #备份test_0001数据库# 备份所有数据库采用mysqldump -u root -p --all-databases --master-data &gt; dbdump.sql 将dbdump.sql在从服务器执行，然后在主服务器执行mysql -uroot -p123456 -e &#39;unlock tables&#39; 3.3 Slave配置3.3.1 配置文件修改12345678910111213141516171819202122232425262728293031#从库日志记录文件位置或名称前缀log-bin=/var/lib/mysql/mysql-binrelay_log=/var/lib/mysql/mysql-relay-bin#同步日志记录的频率，1为每条都记录，安全但效率低sync_binlog=1#server的id，不能与相同id的mysql主从连接server-id=136#从库日志忽略的数据库名称，不记录#这里记录从库的binlog是为了安全，如果觉得没必要，可以去掉从库binlog的配置binlog-ignore-db = mysqlbinlog-ignore-db = performance_schemabinlog-ignore-db = information_schema#此处添加需要同步的数据库名称，那么它会只接收这个数据库的信息，多个数据库需同步按照此格式另写几行即可#这里同步数据有两种思路，一种是主服务器只发从库需要的，在主库指定；一种是主服务器把所有数据同步过来，从库按需过滤接收#为了让配置更详细些，此处配置了从库过滤接收的配置replicate-do-db=test_0001#忽略接收的库名replicate-ignore-db=mysqlreplicate-ignore-db=performance_schemareplicate-ignore-db=information_schema#跳过所有错误继续slave-skip-errors=all#设置延时时间slave-net-timeout=60#mysql复制模式binlog_format=ROW#binlog过期清理时间expire_logs_days=7#binlog每个日志文件大小max_binlog_size=20M 3.3.2 重启1# systemctl restart mysqld 3.3.3 配置Master位置12345678910# mysql -uroot -ppassword:mysql&gt; CHANGE MASTER TO MASTER_HOST=&apos;172.16.22.135&apos;, MASTER_USER=&apos;repl&apos;, MASTER_PASSWORD=&apos;repl&apos;, MASTER_PORT=3306, MASTER_LOG_FILE=&apos;mysql-bin.000001&apos;, MASTER_LOG_POS= 573, MASTER_CONNECT_RETRY=30;# 注意上面的master二进制文件名和pos要和master信息一致 3.3.4 启动slave123#启动slave进程mysql&gt; slave start;mysql&gt; show slave statue\\G; 可以看到启动成功，如果此步失败，请排查网络问题，或者查看出错日志/var/log/mysqld.log, /var/log/message 3.4 测试在master上新建表，插入数据，观察slave数据库中是否同步了数据。123456#master上执行mysql&gt; show slave hosts;mysql&gt; show mater status;#slave上执行，对比master上的binlog信息mysql&gt; show slave status\\G; 4. 彩蛋4.1 Error-UUID重复发现原来是Mysql的一个配置文件auto.cnf里面记录了mysql服务器的uuid。 server_uuid:服务器身份ID。在第一次启动Mysql时，会自动生成一个server_uuid并写入到数据目录下auto.cnf文件里。原来是这个uuid和主服务器的uuid重复了。经过修改auto.cnf文件中的server-uuid，重启mysql服务器，再查看mysql从节点的状态，终于成功了。 4.2 命令拓展123mysql&gt; stop slave; #停止mysql&gt; reset slave; #重置mysql&gt; delete from user Where user=&apos;repl&apos; and host=&apos;172.16.22.%&apos;; #删除主服务器配置的连接slave用户","tags":[{"name":"mysql","slug":"mysql","permalink":"https://cnkeep.github.io/tags/mysql/"}]},{"title":"1","date":"2018-11-21T14:52:00.000Z","path":"2018/11/21/网络-01/","text":"数据链路层主要是为了子网内传输数据，使用MAC地址标识,ARP协议用来判断指定的MAC地址机器. 网络层为了子网间传输数据，IP协议。 通过子网掩码来判断两个ip是否属于同一个子网，方法是将两个IP地址与子网掩码分别进行AND运算（两个数位都为1，运算结果为1，否则为0），然后比较结果是否相同，如果是的话，就表明它们在同一个子网络中，否则就不是 传输层，匹配端口来完成进程通讯，TCP/UDP协议 123集线器，工作在物理层；交换机，工作在数据链路层；路由器，工作在网络层。","tags":[{"name":"Network","slug":"Network","permalink":"https://cnkeep.github.io/tags/Network/"}]},{"title":"02_TCP拆包，粘包问题","date":"2018-11-20T13:54:00.000Z","path":"2018/11/20/网络-02_TCP拆包，粘包问题/","text":"TCP粘包、拆包问题1. 背景在网络传输工程中，数据事进行分组，分包传输的，考虑一下几种情况： 1). client发送数据包到server, 完成后中断连接。第二次新建连接传送数据，完成后中断连接，退出。 第一次数据传送 第二次数据传送 2).client发送数据包到server，保持连接状态，不中断连接，继续发送第二个数据包，分三种情形。 数据包粘连：两个数据包无法判断个各自的终止位置。 数据包粘连 + 数据包拆分 数据包粘连 + 数据包拆分 2. 分析 1.这两种情形会导致什么问题吗？ 第一种情况：在数据发送上不会出现问题，但是需要频繁的建立和释放socket连接，我们都知道socket连接的释放是十分耗费资源的，所以会存在性能问题。 第二种情况：因为数据包之间无法区分终止的位置，导致server端解析出错，无法正常分割解析，无法进行有效的数据传送。 2.为什么会出现粘包和拆包问题？ 1). 要发送的数据大于TCP发送缓冲区大空间大小，发生拆包。 2).待发送的数据大于MSS(MSS=TCP报文段长度-TCP首部长度)，发生拆包。 3).要发送的数据小于TCP发送缓冲区的大小，TCP将粘包。 4).接收端应用层没有及时的读取缓冲区的数据，将发生粘包。 3.TCP会出现这种问题，那么UDP会出现吗？为什么？ &emsp;&emsp;UDP是基于报文发送的，从UDP的帧结构可以看出，在UDP首部采用了16bit来指示UDP数据报文的长度，因此在应用层能很好的将不同的数据报文区分开。 4.有哪些解决方案可以解决这些问题？ &emsp;&emsp;既然UDP不会出现这种问题，那么我们可不可以参照UDP的方式去实现呢，添加报文的长度信息。 1).发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。 2).发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。 3).可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。 3. 引申 1). JDK中的socket.write(int arg)是如何实现的?&emsp;&emsp;我们知道socket.write(byte[] args),是通过byte写入的，虽然支持int类型的写入，但是，只会写入低八位。12345678Int: +---------------+---------------+---------------+---------------+ |1 1 1 1 1 1 1 1|1 1 1 1 1 1 1 1|1 1 1 1 1 1 1 1|1 1 1 1 1 1 1 1| +---------------+---------------+---------------+---------------+Byte:+---------------+|1 1 1 1 1 1 1 1|+---------------+ 那如何将一个int类型写入呢？使用移位操作A).获取第一个八位：(num &gt;&gt;&gt; 24) &amp; 0xFFB).获取第二个八位：(num &gt;&gt;&gt; 16) &amp; 0xFFC).获取第三个八位：(num &gt;&gt;&gt; 8) &amp; 0xFFD).获取第四个八位：(num &gt;&gt;&gt; 0) &amp; 0xFF依次写入就实现了int的写入","tags":[{"name":"Network","slug":"Network","permalink":"https://cnkeep.github.io/tags/Network/"}]},{"title":"01_入门netty4.x","date":"2018-11-05T16:25:00.000Z","path":"2018/11/06/02-01_入门netty4.x/","text":"入门netty4.xNetty是什么&emsp;&emsp;Netty是业界流行的NIO框架之一，它基于事件驱动，API使用简单，定制能力强，内置了很多的协议，而且解决了JDK NIO的一些bug,是目前业内最流行的网络编程框架。 一些概念的介绍NIO传统的各种I/O流，socket都属于BIO(同步阻塞式IO)，这部分内容在上一篇中已经介绍过。Netty实际上就是NIO的封装工具(但不仅仅只是封装)。 事件驱动通常，我们写服务器处理模型的程序时，有以下几种模型：（1）每收到一个请求，创建一个新的进程，来处理该请求；（2）每收到一个请求，创建一个新的线程，来处理该请求；（3）每收到一个请求，放入一个事件列表，让主进程通过非阻塞I/O方式来处理请求上面的几种方式，各有千秋，第（1）种方法，由于创建新的进程的开销比较大，所以，会导致服务器性能比较差,但实现比较简单。第（2）种方式，由于要涉及到线程的同步，有可能会面临死锁等问题。第（3）种方式，在写应用程序代码时，逻辑比前面两种都复杂。综合考虑各方面因素，一般普遍认为第（3）种方式是大多数网络服务器采用的方式，这就是事件驱动。常见的JavaScript，AWT就是事件驱动模型。 为什么抛弃JDK的NIO选用Netty我们不选择使用JDK原生的NIO API而是使用Netty主要是因为以下原因： NIO的类库和API繁杂，使用麻烦，你需要熟练掌握Selector、 ServerSocketChannel、SocketChannel、ByteBuffer等。 需要具备其他的额外技能做铺垫，例如熟悉Java多线程编程。这是因为NIO编程涉及到Reactor模式，你必须对多线程和网路编程非常熟悉，才能编写出高质量的NIO程序。 自己编写可靠性弱，工作量和难度都非常大。例如客户端面临断连重连、网 络闪断、半包读写、失败缓存、网络拥塞和异常码流的处理等问题，而这些Netty都已经实现了。 JDK NIO存在许多BUG，例如臭名昭著的epoll bug，它会导致Selector空轮询， 最终导致CPU 100%。而Netty作为业界优秀的NIO框架都为这些问题提供了解决方案。 此外Netty具有很多优点：API简单，扩展性强，预置了多种编解码功能可直接使用。 示例使用本文基于Netty 4.19示例一个群发消息的应用，其中客户端发送消息，同时接收服务端转发的来自其他客户端的消息。服务端接收客户端的消息并将消息转发给所有的客户端。 服务端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/*** 服务端启动入口*/public final class Server &#123; static final int PORT = Integer.parseInt(System.getProperty(\"port\", \"8009\")); public static void main(String[] args) throws Exception &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;()&#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(\"decode\",new StringDecoder()); pipeline.addLast(\"encode\",new StringEncoder()); pipeline.addLast(new EchoHandler()); &#125; &#125;); // Bind and start to accept incoming connections. ChannelFuture f = b.bind(PORT).sync(); // Wait until the server socket is closed. // In this example, this does not happen, but you can do that to gracefully // shut down your server. f.channel().closeFuture().sync(); &#125; finally &#123; workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125;&#125;/** * 服务端处理器: 打印请求消息，返回响应 */public class EchoHandler extends SimpleChannelInboundHandler&lt;String&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception &#123; System.out.println(\"server get:\"+msg); Channel channel = ctx.channel(); ChannelFuture future = channel.writeAndFlush(\"I get you message\"); /** * 关闭连接 */ future.addListener(ChannelFutureListener.CLOSE); &#125;&#125; 客户端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class Client implements Runnable &#123; public static final String HOST = \"127.0.0.1\"; public static final int PORT = 8009; @Override public void run() &#123; EventLoopGroup eventLoopGroup = new NioEventLoopGroup(); Bootstrap client = new Bootstrap(); client.group(eventLoopGroup).channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;SocketChannel&gt;()&#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(\"decode\",new StringDecoder()); pipeline.addLast(\"encode\",new StringEncoder()); pipeline.addLast(new ClientHandler()); &#125; &#125;); try &#123; ChannelFuture f = client.connect(HOST, PORT).sync(); Channel channel = f.channel(); while (true &amp;&amp; channel.isActive()) &#123; Scanner input = new Scanner(System.in); System.out.print(\"input:\"); String str = input.nextLine(); if (null != str &amp;&amp; \"exit\".equals(str)) &#123; f.channel().closeFuture().sync(); &#125; else &#123; channel.writeAndFlush(str); &#125; &#125; f.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; eventLoopGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; new Thread(new Client()).start(); &#125;&#125;/*** 客户端消息处理：简单打印*/public class ClientHandler extends SimpleChannelInboundHandler&lt;String&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception &#123; System.out.println(\"client get:\"+msg); &#125;&#125;","tags":[{"name":"Netty","slug":"Netty","permalink":"https://cnkeep.github.io/tags/Netty/"}]},{"title":"01_杂谈IO类型&线程模型","date":"2018-11-05T14:10:00.000Z","path":"2018/11/05/01-01_杂谈IO类型&线程模型/","text":"I/O类型 &amp; 线程模型I/O类型提到I/O我们先得了解一下阻塞，同步都是什么。一次I/O操作, 以read方法举例，需要经历两个阶段: 等待数据准备阶段，内核态等待套接口数据准备好，是否阻塞值得就是这个阶段 数据复制阶段，将数据从内核拷贝到用户进程中，是否同步指的就是这个阶段 那按照这两个阶段的不同类型组合在一起就将I/O处理分成同步阻塞IO(BIO), 同步非阻塞IO(NIO), 异步非阻塞IO(AIO)三种类型，接下来我们来具体看看区别。 BIOBIO: 同步阻塞I/O，我们常见的I/O流，最原始的Socket都属于同步阻塞I/O，来看看BIO的流程图： 第一个阶段，用户进程通知内核，阻塞等待数据准备；第二阶段，内核拷贝数据到用户进程，在这个过程中用户进程依旧阻塞着。 NIONIO: 同步非阻塞式I/O，jdk1.4之后提供了一系列的方法来操作流，定义在java.nio包下面。相比于传统的BIO,NIO 提供了高速的面向快的I/O,它加入了Buffer、Channel、Selector等概念。它是基于事件驱动的，采用了Reactor模式，它使用一个线程管理所有的socket通道，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。它的特点是要不断主动地去询问数据有没有处理完，一般只适用于连接数目较大但连接时间短的应用，如聊天应用等。 AIOAIO: 异步非阻塞式I/O, jdk1.7开始支持，编码复杂，不做介绍了。 线程模型传统的单线程模型 以较低版本的tomcat为例，每次新建一个连接就创建一个新的线程为其处理请求，问题显而易见，最终线程创建太多，线程切换频繁，处理性能急剧下降。 Reactor模型 一个线程处理监听，连接成功后，交由后面的线程池处理","tags":[{"name":"Netty","slug":"Netty","permalink":"https://cnkeep.github.io/tags/Netty/"}]},{"title":"02_netty处理模型","date":"2018-11-04T17:14:00.000Z","path":"2018/11/05/02-02_netty处理模型/","text":"Netty处理模型前言&emsp;&emsp;上节我们通过一个实例学习了如何简单的使用Netty快速构建自己的服务，这节我们来学习Netty的整体处理流程。了解如何更高效的使用Netty的处理模型，以及如何自定义协议。 Netty的处理流程整体模型 &emsp;&emsp;上节我们已经知道Netty采用的是Reactor模型，其内部包含boss和worker两个线程组分别负责不同的职责，如图所示： &emsp;&emsp;&emsp;&emsp; boss线程：负责监听请求，即处理Accept请求 worker线程：负责具体的请求处理和响应, 即处理具体的I/O处理 I/O的处理机制 &emsp;&emsp;Netty的I/O处理是最主要的部分，包含了一个请求从解码，处理，编码响应的完整处理流程，具体流程如下图： &emsp;&emsp;&emsp;&emsp; 整个处理流程为责任链方式，非常容易进行扩展，例如半包问题解决，常用的编解码方式。 推荐的处理模型 &emsp;&emsp;上面我们已经里了解到，Netty接收到请求后会交由I/O处理线程完成，包含请求的解码，业务处理，响应编码，这些流程因为是链式处理，也就意味着如果我们在业务处理中需要处理耗时的操作时，就会阻塞后面的请求处理，所以不应该将业务处理放在I/O处理中处理，所以我们应该改进模型。 所以我们的处理模型应当是这样的：&emsp;&emsp; boss线程负责监听请求，即值处理Accept请求，接收请求后交由worker线程池处理 worker线程，负责具体的请求的基础处理，包含：请求的解码，基础校验，响应的编码等非耗时的处理，这些处理结束后将请求交由业务线程池处理，I/O线程尽快返回，避免阻塞后面请求的处理。 业务线程处理具体的耗时业务逻辑，处理完成后异步返回。","tags":[{"name":"Netty","slug":"Netty","permalink":"https://cnkeep.github.io/tags/Netty/"}]},{"title":"02_JDK的NIO操作","date":"2018-11-03T17:42:00.000Z","path":"2018/11/04/01-02_JDK的NIO操作/","text":"NIO转载:李林峰-Netty系列之Netty 服务端创建 前言&emsp;&emsp;因为BIO的性能等问题，NIO的呼声越来越大，终于在jdk1.4的时候java为我们带来了同步非阻塞I/O(NIO)的网络编程API。它弥补了原来同步阻塞I/O的不足，但是同时也增加了复杂性，本次我们就NIO的API进行简单学习，以便为Netty的原理理解做铺垫。 NIO API&emsp;&emsp;NIO为我们提供了一套不同于之前BIO的API, 主要包含：Selector,事件, Channel, Buffer。下面我们逐个看看这些接口的作用。 多路复用器Selector&emsp;&emsp;Selector, 多路复用器，它是NIO编程的基础。Selector会不断的轮训注册在其上的Channel, 如果某个Channel上发生读写事件，此时这个Channel就处于就绪状态，会被Selector轮询出来，我们再通过判断事件的类型进行不同的处理操作。一个Selector可以同时轮询多个Channel, 这一点相对于BIO同一时刻只能处理一个的效果就好太多了。 事件&emsp;&emsp;事件类型有四种:OP_CONNECT, OP_READ, OP_WRITE, OP_ACCEPT, 来看事件触发的时机： OP_CONNECT 只有客户端SocketChannel可以监听该事件，当客户端调用SocketChannel.connect()时，该事件触发，触发该事件并不代表已经连接成功，连接成功需要调用Channel.finishConnect()判断。 OP_READ 该操作对客户端和服务端的SocketChannel都有效，当OS的读缓冲区中有数据可读时，该事件触发。 OP_WRITE 该操作对客户端和服务端的SocketChannel都有效，当OS的写缓冲区中有空闲的空间时(大部分时候都有)，该事件触发。 该事件在操作系统内核缓冲区有空闲时触发，而写缓冲区绝大部分事件都是有空闲空间的，所以当你注册写事件后，写操作一直就是就绪的，这样会导致Selector处理线程会占用整个CPU的资源，所以一般不注册该事件,如果注册也应该是临时注册，写完数据后立即取消注册。注意这个事件很特别，并不是调用write时就触发该事件，该事件一般是内核触发。 OP_ACCEPT 当服务端收到一客户端的连接请求时会触发该事件，只有ServerSocketChannel可以监听该事件。 通道Channel&emsp;&emsp;不同于BIO的是，在NIO中连接被抽象成一条通道，而这个通道是双向的，可以同时写和读，而传统的BIO流式操作只支持单向。我们可以将Channel注册到Selector中以实现Selector对其的管理。一个Channel可以注册到多个不同的Selector中。 &emsp;&emsp;当Channel注册到Selector后会返回一个SelectionKey对象，该SelectionKey对象则代表这这个Channel和它注册的Selector间的关系。并且SelectionKey中维护着两个很重要的属性：interestOps、readyOps。interestOps是我们希望Selector监听Channel的哪些事件。我们将我们感兴趣的事件设置到该字段，这样在selection操作时，当发现该Channel有我们所感兴趣的事件发生时，就会将我们感兴趣的事件再设置到readyOps中，这样我们就能得知是哪些事件发生了以做相应处理。 &emsp;&emsp;NIO中存在两种通道SocketChannel和ServerSocketChannel,不同的通道支持监听的事件类型不同，具体范围如下所示：&emsp;&emsp; 客户端的SocketChannel支持 OP_CONNECT, OP_READ, OP_WRITE三个操作 服务端ServerSocketChannel只支持OP_ACCEPT操作 服务端由ServerSocketChannel的accept()方法产生的SocketChannel只支持OP_READ, OP_WRITE操作 缓冲区Buffer&emsp;&emsp;Buffer是一个对象，它包含一些写入或者要读出的数据，实质上它是一个字节数组，它提供了对数据的结构化访问以及维护读写位置等信息。在NIO中所有的数据都是用缓冲区处理的，在读取数据时，直接从缓冲区中读，写数据时，直接写入到缓冲区中。这一点不同于BIO, BIO是通过不同的Stream对象来完成的，我们可以简单的理解成下图这样： &emsp;&emsp; NIO编程实例&emsp;&emsp;为了更真切的了解NIO的编程方式，接下来我们编写一个简单的聊天程序。 服务端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147public class NioServer implements Runnable &#123; private Selector selector; private ServerSocketChannel serverSocketChannel; private ExecutorService executor; public NioServer() &#123; bind(); init(); &#125; private void init() &#123; final int cpuCount = Runtime.getRuntime().availableProcessors(); ThreadFactory threadFactory = new ThreadFactory() &#123; private AtomicLong threadCount = new AtomicLong(0); private static final String threadNameFormat = \"workerPool-Thread:%d\"; @Override public Thread newThread(Runnable r) &#123; return new Thread(r, String.format(threadNameFormat, threadCount.getAndIncrement())); &#125; &#125;; executor = new ThreadPoolExecutor(cpuCount, 2 * cpuCount, 1, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), threadFactory, new ThreadPoolExecutor.CallerRunsPolicy()); &#125; /** * 服务端端口绑定 */ private void bind() &#123; try &#123; selector = Selector.open(); serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false); serverSocketChannel.socket().bind(new InetSocketAddress(\"127.0.0.1\", 8080), 1024); /** *注册关注服务端接收客户端连接事件 */ serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println(\"Server is start in port : 8080\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; while (true) &#123; try &#123; selector.select(1000L); Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); SelectionKey key; while (iterator.hasNext()) &#123; key = iterator.next(); iterator.remove(); executor.submit(() -&gt; handleEvent(key)); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); if (selector != null) &#123; try &#123; selector.close(); &#125; catch (IOException e1) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125; private void handleEvent(SelectionKey key) &#123; try &#123; if (key.isValid()) &#123; if (key.isAcceptable()) &#123; ServerSocketChannel serverSocketChannel = (ServerSocketChannel) key.channel(); SocketChannel channel = serverSocketChannel.accept(); channel.configureBlocking(false); channel.register(selector, SelectionKey.OP_READ); &#125; if (key.isReadable()) &#123; doRead(key); &#125; &#125; &#125; catch (Exception e) &#123; if(key!=null|| null!=key.channel())&#123; try &#123; key.channel().close(); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; &#125; e.printStackTrace(); &#125; &#125; private void doRead(SelectionKey key) throws IOException &#123; SocketChannel channel = (SocketChannel) key.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); int readBytes = channel.read(byteBuffer); if (readBytes &gt; 0) &#123; /** * 有读到字节 */ byteBuffer.flip(); byte[] bytes = new byte[byteBuffer.remaining()]; byteBuffer.get(bytes); String receiverMsg = new String(bytes, \"UTF-8\"); System.out.println(\"NioServer receiver msg: \" + receiverMsg); doWrite(channel); &#125; else if (readBytes &lt; 0) &#123; /* 链路已关闭*/ key.cancel(); channel.close(); &#125; &#125; private void doWrite(SocketChannel channel) throws IOException &#123; String respMsg = \"Server has received the msg !!!\"; ByteBuffer outBuffer = ByteBuffer.wrap(respMsg.getBytes()); channel.write(outBuffer); &#125; public void close()&#123; try &#123; this.serverSocketChannel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; this.executor.shutdown(); try &#123; this.executor.awaitTermination(10,TimeUnit.MINUTES); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) &#123; NioServer server = new NioServer(); Thread thread = new Thread(server); thread.start(); &#125; server接收到事件后交由worker线程池处理，服务端接收到客户端消息后打印并返回响应。 客户端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.SocketChannel;import java.util.Iterator;/** * @author &lt;a mailto:zhangleili924@gmail.com&gt;LeiLi.Zhang&lt;/a&gt; * @version 0.0.1 * @apiNote nio客户端 * @date 2018-09-14 */public class NioClient implements Runnable &#123; private Selector selector; private SocketChannel clientChannel; private NioClient() &#123; try &#123; doConnect(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; private void doConnect() throws Exception &#123; selector = Selector.open(); clientChannel = SocketChannel.open(); clientChannel.configureBlocking(false); if (clientChannel.connect(new InetSocketAddress(&quot;127.0.0.1&quot;, 8009))) &#123; clientChannel.register(selector, SelectionKey.OP_READ); doWrite(clientChannel); &#125; else &#123; clientChannel.register(selector, SelectionKey.OP_CONNECT); &#125; System.out.println(&quot;Client will start connect.&quot;); &#125; @Override public void run() &#123; while (true) &#123; try &#123; selector.select(1000L); Iterator&lt;SelectionKey&gt; iterator = this.selector.selectedKeys().iterator(); SelectionKey key; while (iterator.hasNext()) &#123; key = iterator.next(); iterator.remove(); doHandleInput(key); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; private void doHandleInput(SelectionKey key) throws IOException &#123; if (key.isValid()) &#123; if (key.isConnectable()) &#123; SocketChannel channel = (SocketChannel) key.channel(); if (channel.finishConnect()) &#123; channel.configureBlocking(false); channel.register(selector, SelectionKey.OP_READ); doWrite(channel); &#125; else &#123; System.exit(1); &#125; &#125; if (key.isReadable()) &#123; doRead(key); &#125; &#125; &#125; private void doRead(SelectionKey key) throws IOException &#123; SocketChannel channel = (SocketChannel) key.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); int readBytes = channel.read(byteBuffer); if (readBytes &gt; 0) &#123; /*有读到字节*/ byteBuffer.flip(); byte[] bytes = new byte[byteBuffer.remaining()]; byteBuffer.get(bytes); String receiverMsg = new String(bytes, &quot;UTF-8&quot;); System.out.println(&quot;NioClient receiver reponse from server which is : &quot; + receiverMsg); &#125; else if (readBytes &lt; 0) &#123; /* 链路已关闭*/ key.cancel(); channel.close(); &#125; &#125; private void doWrite(SocketChannel channel) throws IOException &#123; String sendMsg = &quot;This msg is client send to server !!!&quot;; ByteBuffer outBuffer = ByteBuffer.wrap(sendMsg.getBytes()); channel.write(outBuffer); &#125; public static void main(String[] args) &#123; NioClient nioClient = new NioClient(); Thread thread = new Thread(nioClient); thread.start(); &#125;&#125; 流程分析服务端步骤1：打开ServerSocketChannel, 用于监听客户端的连接，它是所有客户端连接的父通道1ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); 步骤2： 绑定端口，设置客户端连接方式为非阻塞方式：12serverSocketChannel.configureBlocking(false);serverSocketChannel.socket().bind(new InetSocketAddress(&quot;127.0.0.1&quot;, 8080), 1024); 步骤3：打开多路复用器，注册ServerSocketChannel通道的accept事件：1234567891011121314151617Selector selector = Selector.open();serverSocketChannel.register(selector,SelectionKey.OP_ACCEPT);``` 步骤4：多路复用器在线程中无限循环轮询准备就绪的通道： ```text/**此方法会阻塞**/while(true)&#123; selector.select(); Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); Iterator it = selectedKeys.iterator(); while(it.hasNext())&#123; SelectionKey key = (SelectionKey)it.next(); iterator.remove(); handlerEvent(key); &#125;&#125; 步骤5: 多路复用器监听到有新的客户端接入时，处理新的连接请求，完成TCP握手，建立物理连接：12345678910111213141516171819/**有可能被cancel，需要检测有效性**/if(key.isValid())&#123; if(key.isAcceptable())&#123; /**accept事件**/ ServerSocketChannel serverSocketChannel = (ServerSocketChannel) key.channel(); SocketChannel channel = serverSocketChannel.accept(); if (null == channel) return; /**设置客户端连接的配置**/ channel.configureBlocking(false); /**监听客户端通道的可读事件**/ channel.register(selector, SelectionKey.OP_READ); &#125; if (key.isReadable()) &#123; /**客户端写事件**/ doRead(key); &#125;&#125; 步骤6：在步骤5建立连接后，监听客户单该连接的可读事件，当有数据时，读取数据doRead(key)：1234567891011121314151617181920private void doRead(SelectionKey key) throws IOException &#123; SocketChannel channel = (SocketChannel) key.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); int readBytes = channel.read(byteBuffer); if (readBytes &gt; 0) &#123; /** * 有读到字节 */ byteBuffer.flip(); byte[] bytes = new byte[byteBuffer.remaining()]; byteBuffer.get(bytes); String receiverMsg = new String(bytes, &quot;UTF-8&quot;); System.out.println(&quot;NioServer receiver msg: &quot; + receiverMsg); doWrite(channel); &#125; else if (readBytes &lt; 0) &#123; /* 链路已关闭*/ key.cancel(); channel.close(); &#125;&#125; 步骤6：返回响应：1234567 private void doWrite(SocketChannel channel,ByteBuffer response) throws IOException &#123; response.flip(); while (response.hasRemaining())&#123; channel.write(response); &#125; response.clear();&#125;","tags":[{"name":"Netty","slug":"Netty","permalink":"https://cnkeep.github.io/tags/Netty/"}]},{"title":"netty_catalog","date":"2018-11-03T17:19:00.000Z","path":"2018/11/04/00-netty_catalog/","text":"高效的事件模型 零拷贝 内存池 JDK NIO bug 的修复 协议的封装 拆包，粘包的处理 时间轮定制任务 ChannelPipeline, EventLoopGroup, ChannelHandlerAdapter, Decoder, Encoder, Unsafe FastThreadLocal 对象池Recycle 环形数组ByteBuffer 系列笔记来自于《Netty权威指南》 01-01_初识Netty EventLoopGroup = n * EventLoop DefaultChanelHandlerContext.fireChannelXXX方法完成链式处理 1.采用异步非阻塞的I/O类库，基于Reactor模式实现，解决了传统同步阻塞I/O模式下一个服务端无法平滑处理线性增长的客户端的问题 2.TCP接收和发送缓冲区使用直接内存代替堆内存，避免了内存复制，提升了I/O读取和写入的性能 3.支持通过内存池的方式循环利用ByteBuf，避免了频繁创建和销毁ByteBuf带来的性能损耗。 4.可配置的I/O线程数、TCP参数等，为不同的用户场景提供定制化的调优参数，满足不同的性能场景 5.采用环形数组缓冲区实现无锁化并发编程，代替传统的线程安全容器或者锁 6.合理使用线程安全容器、原子类等，提升系统的并发处理能力 7.关键资源的处理使用单线程串行化的方式，避免多线程并发访问带来的锁竞争和额外的CPU资源消耗问题 8.通过引用计数器及时的申请释放不再被引用的对象，细粒度的内存管理降低了GC的频率，减少了频繁GC带来的时延增大和CPU损耗","tags":[{"name":"Netty","slug":"Netty","permalink":"https://cnkeep.github.io/tags/Netty/"}]},{"title":"01_执行流程解读","date":"2018-09-03T15:50:00.000Z","path":"2018/09/03/04-01_执行流程解读/","text":"执行流程分析 既然mybatis是针对JDBC操作的封装，那我们接下来就拨看云雾见阳光的看看mybatis是如何一步一步的做这些事情的，我们以查询为例。 引言 先看一下基础的jdbc操作有那几个步骤： Step1. 获取连接Step2. 获取执行动态sqlStep3. 构建预编译对象PrepareStatementStep4. 设置动态参数Step5. 通过连接发送执行请求到数据库Step6. 数据库返回结果集，编辑解析返回结果Step7. 关闭连接 我们如何用mybatis做数据库查询呢？1234567891011121314151617181920212223 public class MybatisDemo&#123; public static void main(String[] args)&#123; String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); try( SqlSession openSession = sqlSessionFactory.openSession() )&#123; User user = openSession.&lt;User&gt;selectOne(\"com.study.mybatis.mapper.UserMapper.select\", 1); System.out.println(user); &#125; &#125; &#125;``` &gt; 我们一步一步来解读mybatis具体的查询流程（以id方式为例，Mapper接口方式后面分析） ### 正文#### 1.获取SqlSession &gt; 在mybatis中连接被抽象为SqlSession,但是并不是真正意义上的connection，其通过SqlSessionFactoy.openSession()获取SqlSession。 #### 2.获取执行sql &gt; 在mybatis中我们是通过mapper.xml来配置sql语句的，而mybatis会通过解析将这些sql语句映射为MappedStatement,一个MappedStatement维护了一条&lt;select|update|delete|insert&gt;节点的封装 &gt; 我们通过namespace+id去获取一个MappedStatement //Configuration.class public MappedStatement getMappedStatement(String id, boolean validateIncompleteStatements) { if (validateIncompleteStatements) { buildAllStatements(); } return mappedStatements.get(id); }12#### 3. 调用查询方法 //DefaultSqlSession.class@Override public List selectList(String statement, Object parameter, RowBounds rowBounds) { try { MappedStatement ms = configuration.getMappedStatement(statement); return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); } catch (Exception e) { throw ExceptionFactory.wrapException(“Error querying database. Cause: “ + e, e); } finally { ErrorContext.instance().reset(); } } 1&gt; SqlSession的查询其实质是委托给Executor去执行了，接着来看*Executor*的query方法 @Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException { BoundSql boundSql = ms.getBoundSql(parameter); CacheKey key = createCacheKey(ms, parameter, rowBounds, boundSql); return query(ms, parameter, rowBounds, resultHandler, key, boundSql); } @SuppressWarnings(&quot;unchecked&quot;) @Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException { ErrorContext.instance().resource(ms.getResource()).activity(&quot;executing a query&quot;).object(ms.getId()); if (closed) { throw new ExecutorException(&quot;Executor was closed.&quot;); } if (queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) { clearLocalCache(); } List&lt;E&gt; list; try { queryStack++; //查询缓存 list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null; if (list != null) { handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); } else { //缓存不存在，查库 list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); } } finally { queryStack--; } if (queryStack == 0) { for (DeferredLoad deferredLoad : deferredLoads) { deferredLoad.load(); } // issue #601 deferredLoads.clear(); //清除二级缓存 if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) { // issue #482 clearLocalCache(); } } return list; } @Override public &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException { PreparedStatement ps = (PreparedStatement) statement; ps.execute(); return resultSetHandler.&lt;E&gt; handleResultSets(ps); } private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException { List&lt;E&gt; list; localCache.putObject(key, EXECUTION_PLACEHOLDER); try { list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql); } finally { localCache.removeObject(key); } localCache.putObject(key, list); if (ms.getStatementType() == StatementType.CALLABLE) { localOutputParameterCache.putObject(key, parameter); } return list; } 1&gt; BaseExecutor提供模板方法，不同的子类实现不同的doQuery回调接口，我们就看SimpleExecutor类 @Override public &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException { Statement stmt = null; try { Configuration configuration = ms.getConfiguration(); //生成StatementHandler代理对象 StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); //利用ParameterHandler完成参数的注入，返回Statement对象 stmt = prepareStatement(handler, ms.getStatementLog()); return handler.&lt;E&gt;query(stmt, resultHandler); } finally { closeStatement(stmt); } } 123456789101112&gt; sql交由相应的StatementHandler代理对象执行``` @Override public &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException &#123; String sql = boundSql.getSql(); //执行sql statement.execute(sql); //交由ResultSetHandler完成结果集的映射，最后返回 return resultSetHandler.&lt;E&gt;handleResultSets(statement); &#125; 总结 自此一个简单的执行流程就分析结束了 ，我们来梳理一下流程（如图）: 1.加载配置文件 2.通过SqlSessionFactroy获取SqlSession 3.通过SqlSession调用方法，传入mapper.xml配置的namespace+id, 动态参数列表 4.SqlSession委托给Executor代理对象去执行 5.调用相应的ParameterHandler代理对象完成参数的注入 6.委托StatementHandler代理对象完成数据库执行 7.委托ResultSetHandler代理对象完成结果集的映射操作","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://cnkeep.github.io/tags/Mybatis/"}]},{"title":"从实例入门","date":"2018-09-02T17:40:00.000Z","path":"2018/09/03/02-从实例入门/","text":"从Mybatis实例看原理[目录] 前言mybatis结构写一个Hello Mybatis与Spring集成 前言 上一节针对Mybatis中主要的几个类进行了列举，我们再来回顾一下 Configuration: Mybatis的配置信息都在该类中 SqlSession: 作为MyBatis工作的主要顶层API，表示和数据库交互的会话，完成必要数据库增删改查功能，类似于connection Executor: 执行器，是Mybatis 调度的核心，负责SQL语句的生成和查询缓存的维护 StatementHandler: 封装了JDBC Statement操作，负责对JDBC statement 的操作，如设置参数、将Statement结果集转换成List集合。 ParameterHandler: 负责将用户传递的参数转换成JDBC statement锁需要的参数。 ResultHandler: 负责将JDBC返回的ResultSet结果集装换为List集合 TypeHandler: 负责java数据类型和JDBC数据类型之间的映射和转化 MappedStatement: MappedStatement维护了一条&lt;select|update|delete|insert&gt;节点的封装 SqlSource: 负责根据用户传递的parameterObject，动态地生成SQL语句，将信息封装到BoundSql对象中，并返回 BoundSql: 表示动态生成的SQL语句以及相应的参数信息 mybatis结构介绍mybatis的架构图: Mybatis的功能架构分为三层： API接口层：提供给外部使用的接口API，开发人员通过这些本地API来操纵数据库。接口层一接收到调用请求就会调用数据处理层来完成具体的数据处理。 数据处理层：负责具体的SQL查找、SQL解析、SQL执行和执行结果映射处理等。它主要的目的是根据调用的请求完成一次数据库操作。 基础支撑层：负责最基础的功能支撑，包括连接管理、事务管理、配置加载和缓存处理，这些都是共用的东西，将他们抽取出来作为最基础的组件。为上层的数据处理层提供最基础的支撑。 MyBatis整个项目的包结构如下： 1.annotation 本包定义了Mybatis框架中的24个注解: Cache,Mapper,Select等。 2.binding 映射绑定Mapper接口与mapper.xml。 3.builder 解析Mybatis的配置文件和映射文件，包括Xml格式和Annotation格式2种配置。 4.cache 本包包含了Mybatis框架的缓存接口定义和实现。 缓存实现为PerpetualCache类，它直接实现了Cache接口，其它缓存类实现采用装饰模式实现。一个个包装起来，形成一个链，典型的就是SynchronizedCache-&gt;LoggingCache-&gt;SerializedCache-&gt;LruCache-&gt;PerpetualCache，通过链起来达到功能增加。 缓存框架按照 Key-Value方式存储，Key的生成采取规则为：[hashcode:checksum:mappedStementId:offset:limit:executeSql:queryParams]。 5.datasource 数据源相关接口和类。 6.exceptions 本包定义了Mybatis框架中的异常。 7.executor Mybatis最后中的四个接口(Executor,StatementHandler,ParameterHandler,ResultSetHandler)以及实现。 8.io 本包主要包含了资源加载和访问相关的类。 9.jdbc JDBC和SQL相关的类。 10.logging 把日志抽象成Log接口，该接口有7种实现。 1.Apache Commons Logging 2.JDBC Logging 3.Java Util Logging 4.Log4j 5.No Logging 6.Slf4J 7.Stdout 11.mapping Mybatis配置文件, 映射文件相关的类。 12.ognl ongl表达式处理 13.parsing 解析配置文件的核心类和接口。 14.plugin 插件相关接口和类。 15.reflection 反射处理相关类。 16.scripting 脚本解析相关类。 17.session 会话相关类，提供对外核心接口. 18.transaction Transaction接口是对事务的抽象，有2种实现方式： 1.JdbcTransaction,jdbc:手动管理 2.ManagedTransaction,managed:container manage the full lifecycle of the transaction TransactionFactory接口定义了生成Transaction接口(实现类)的若干方法。 该接口有2种实现方式： 1.JdbcTransactionFactory,Creates {@link JdbcTransaction} instances。 2.ManagedTransactionFactory，Creates {@link ManagedTransaction} instances。 本包主要依赖了Mybatis session包的TransactionIsolationLevel和exceptions包的PersistenceException。 Mybatis的其它包大量引用了本包中的类和接口，即严重依赖于本包。 19.type 类型转换处理，包含了类型处理器接口TypeHandler，父类BaseTypeHandler,以及若干个子类。 Hello Mybatis 还是老套路，先来玩一玩Mybatis，看一个Demo参照官网,需要以下几个步骤：1.引入依赖12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;x.x.x&lt;/version&gt;&lt;/dependency&gt; 2.配置mybatis-config.xml123456789101112131415161718&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"$&#123;driver&#125;\"/&gt; &lt;property name=\"url\" value=\"$&#123;url&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;password&#125;\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource=\"org/mybatis/example/BlogMapper.xml\"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 3.编写Mapper接口注：该接口不用提供实现类，只是提供一个映射关系，mybatis会自动解析该映射关系来调用相关的sql语句12345package org.mybatis.example;public interface BlogMapper&#123; Blog selectBlog(@org.apache.ibatis.annotations.Param(\"id\")Integer id);&#125; 4.编写mapper.xml注意：该xml文件需要在配置文件中的mappers节点下注册1234567&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"org.mybatis.example.BlogMapper\"&gt; &lt;select id=\"selectBlog\" resultType=\"Blog\"&gt; select * from Blog where id = #&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; 5.加载配置文件,构建SqlSessionFactory123String resource = \"org/mybatis/example/mybatis-config.xml\";InputStream inputStream = Resources.getResourceAsStream(resource);SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); 6.从SqlSessionFactory中获取会话SqlSession12345678910111213141516// 采用直接指定sqlid的方式SqlSession session = sqlSessionFactory.openSession();try &#123; Blog blog = (Blog) session.selectOne(\"org.mybatis.example.BlogMapper.selectBlog\", 101);&#125; finally &#123; session.close();&#125;//采用接口的方式SqlSession session = sqlSessionFactory.openSession();try &#123; BlogMapper mapper = session.getMapper(BlogMapper.class); Blog blog = mapper.selectBlog(101);&#125; finally &#123; session.close();&#125; 自此一个简单的Demo就完成了 与Spring集成 在开发中我们一般不会单独使用Mybatis,都是利用Spring强大的IOC和AOP来帮助我们快速的构建项目，我们来看看如何与Spring集成先看看版本之间的对应关系1.添加依赖12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061 &lt;!-- 导入database依赖,使用druid作连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.44&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;4.3.10.RELEASE&lt;/version&gt; &lt;/dependency&gt;``` &gt; 2.配置SqlSessionFactory &gt; 在spring的配置文件application-context.xml中配置如下内容 ```xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!-- 引入配置文件 --&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!-- 引入配置文件 --&gt; &lt;bean id=\"propertyConfigurer\" class=\"org.springframework.beans.factory.config.PropertyPlaceholderConfigurer\"&gt; &lt;property name=\"location\" value=\"classpath:/mybatis/db.properties\"/&gt; &lt;/bean&gt; &lt;!-- dataSource配置 --&gt; &lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\" init-method=\"init\" destroy-method=\"close\"&gt; &lt;property name=\"driverClassName\" value=\"$&#123;jdbc.driverClassName&#125;\"/&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\"/&gt; &lt;property name=\"filters\" value=\"log4j\"/&gt; &lt;property name=\"maxActive\" value=\"5\"/&gt; &lt;property name=\"initialSize\" value=\"1\"/&gt; &lt;property name=\"maxWait\" value=\"6000\"/&gt; &lt;/bean&gt; &lt;!-- mybatis配置,mapper.xml文件扫描 --&gt; &lt;bean id=\"sessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"configLocation\" value=\"classpath:/mybatis/mybatis-config.xml\"/&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;/beans&gt; 3.使用`java package com.company.repo; import org.apache.ibatis.session.; import org.springframework.beans.factory.annotation.; /** * 抽象 */ public abstract class AbstractRepository{ protected SqlSessionFactory sqlSessionFactory; @Autowired @Qualifier(&quot;sqlSessionFactory&quot;) public void setSqlSessionFacto(SqlSessionFactory sqlSessionFactory){ this.sqlSessionFactory = sqlSessionFactory; } } ```java @org.springframework.stereotype.Repository public class BlogRepository extends AbstactRepository{ public Blog findById(Integer id){ try(org.apache.ibatis.session.SqlSession sqlSession = sqlSessionFactory.openSession()){ BlogMapper mapper = sqlSession.getMapper(BlogMapper.class); return mapper.findById(id); } } } 这样一个与Spring集成，简单的使用实例就完成了，复杂的就看各位的了。下一节将针对配置文件mybatis-config.xml进行说明","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://cnkeep.github.io/tags/Mybatis/"}]},{"title":"mybatis-config.xml的配置介绍","date":"2018-09-02T17:29:00.000Z","path":"2018/09/03/03-mybatis-config.xml的配置介绍/","text":"mybatis-config.xml配置介绍介绍 mybatis-config.xml作为Mybatis的配置文件，提供了很多配置，而且这些配置存在加载顺序，需要特别注意，这里说明一下: properties(属性配置节点) settings (全局配置参数) typeAiases(类型别名) typeHandlers(类型转换器) objectFactory (对象工厂) plugins (插件) environments (环境集合属性对象) mappers(xml映射器)) properties属性 将外部配置文件的属性导入，这样就可以在文件内部使用外部配置文件中的属性值了. 例如配置jdbc.properties12345678910111213141516171819202122232425 jdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/jdbc jdbc.username=root jdbc.password=123456``` &gt; * 在mybatis-Config.xml中加载db.properties ```xml &lt;properties resource=\"db.properties\"&gt; &lt;!-- properties中还可以配置一些属性名和属性值,此处的优先加载 --&gt; &lt;!-- &lt;property name=\"driver\" value=\"\"/&gt; --&gt; &lt;/properties&gt; &lt;!-- 和spring整合后 environments配置将废除--&gt; &lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;!-- 使用jdbc事务管理,事务控制由mybatis管理--&gt; &lt;transactionManager type=\"JDBC\" /&gt; &lt;!-- 数据库连接池,由mybatis管理--&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"$&#123;jdbc.driver&#125;\" /&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\" /&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\" /&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; 注意： 在 properties元素内定义的属性优先读取。 然后读取properties元素中resource或url加载的属性，它会覆盖已读取的同名属性。 最后读取parameterType传递的属性，它会覆盖已读取的同名属性。 settings全局属性 mybatis 运行时可以调整一些参数，比如开启二级缓存 设置参数 描述 有效值 默认值 cacheEnabled 全局地开启或关闭配置文件中的所有映射器已经配置的任何缓存。即二级缓存 true | false true lazyLoadingEnabled 延迟加载的全局开关。当开启时，所有关联对象都会延迟加载。 特定关联关系中可通过设置fetchType属性来覆盖该项的开关状态。 true | false false aggressiveLazyLoading 当开启时，任何方法的调用都会加载该对象的所有属性。否则，每个属性会按需加载（参考lazyLoadTriggerMethods). true | false false (true in ≤3.4.1) multipleResultSetsEnabled 是否允许单一语句返回多结果集（需要兼容驱动）。 true | false true useColumnLabel 使用列标签代替列名。不同的驱动在这方面会有不同的表现， 具体可参考相关驱动文档或通过测试这两种不同的模式来观察所用驱动的结果。 true | false true useGeneratedKeys 允许 JDBC 支持自动生成主键，需要驱动兼容。 如果设置为 true 则这个设置强制使用自动生成主键，尽管一些驱动不能兼容但仍可正常工作（比如 Derby）。 true | false False autoMappingBehavior 指定 MyBatis 应如何自动映射列到字段或属性。 NONE 表示取消自动映射；PARTIAL 只会自动映射没有定义嵌套结果集映射的结果集。 FULL 会自动映射任意复杂的结果集（无论是否嵌套）。 NONE, PARTIAL, FULL PARTIAL autoMappingUnknownColumnBehavior 指定发现自动映射目标未知列（或者未知属性类型）的行为。 NONE: 不做任何反应 WARNING: 输出提醒日志 (‘org.apache.ibatis.session.AutoMappingUnknownColumnBehavior’ 的日志等级必须设置为 WARN) FAILING: 映射失败 (抛出 SqlSessionException) NONE, WARNING, FAILING NONE defaultExecutorType 配置默认的执行器。SIMPLE 就是普通的执行器；REUSE 执行器会重用预处理语句（prepared statements）； BATCH 执行器将重用语句并执行批量更新。 SIMPLE REUSE BATCH SIMPLE defaultStatementTimeout 设置超时时间，它决定驱动等待数据库响应的秒数。 任意正整数 Not Set (null) defaultFetchSize 为驱动的结果集获取数量（fetchSize）设置一个提示值。此参数只可以在查询设置中被覆盖。 任意正整数 Not Set (null) safeRowBoundsEnabled 允许在嵌套语句中使用分页（RowBounds）。如果允许使用则设置为false。 true | false False safeResultHandlerEnabled 允许在嵌套语句中使用分页（ResultHandler）。如果允许使用则设置为false。 true | false True mapUnderscoreToCamelCase 是否开启自动驼峰命名规则（camel case）映射，即从经典数据库列名 A_COLUMN 到经典 Java 属性名 aColumn 的类似映射。 true | false False localCacheScope MyBatis 利用本地缓存机制（Local Cache）防止循环引用（circular references）和加速重复嵌套查询。 默认值为 SESSION，这种情况下会缓存一个会话中执行的所有查询。 若设置值为 STATEMENT，本地会话仅用在语句执行上，对相同 SqlSession 的不同调用将不会共享数据。 SESSION | STATEMENT SESSION jdbcTypeForNull 当没有为参数提供特定的 JDBC 类型时，为空值指定 JDBC 类型。 某些驱动需要指定列的 JDBC 类型，多数情况直接用一般类型即可，比如 NULL、VARCHAR 或 OTHER。 JdbcType 常量. 大多都为: NULL, VARCHAR and OTHER OTHER lazyLoadTriggerMethods 指定哪个对象的方法触发一次延迟加载。 用逗号分隔的方法列表。 equals,clone,hashCode,toString defaultScriptingLanguage 指定动态 SQL 生成的默认语言。 一个类型别名或完全限定类名。 org.apache.ibatis.scripting.xmltags.XMLLanguageDriver defaultEnumTypeHandler 指定 Enum 使用的默认 TypeHandler 。 (从3.4.5开始) 一个类型别名或完全限定类名。 org.apache.ibatis.type.EnumTypeHandler callSettersOnNulls 指定当结果集中值为 null 的时候是否调用映射对象的 setter（map 对象时为 put）方法，这对于有 Map.keySet() 依赖或 null 值初始化的时候是有用的。注意基本类型（int、boolean等）是不能设置成 null 的。 true | false false returnInstanceForEmptyRow 当返回行的所有列都是空时，MyBatis默认返回null。 当开启这个设置时，MyBatis会返回一个空实例。 请注意，它也适用于嵌套的结果集 (i.e. collectioin and association)。（从3.4.2开始） true | false false logPrefix 指定 MyBatis 增加到日志名称的前缀。 任何字符串 Not set logImpl 指定 MyBatis 所用日志的具体实现，未指定时将自动查找。 查找顺序：SLF4J | LOG4J | LOG4J2 | JDK_LOGGING | COMMONS_LOGGING | STDOUT_LOGGING | NO_LOGGING Not set proxyFactory 指定 Mybatis 创建具有延迟加载能力的对象所用到的代理工具。 CGLIB | JAVASSIST JAVASSIST (MyBatis 3.3 or above) vfsImpl 指定VFS的实现 自定义VFS的实现的类全限定名，以逗号分隔。 Not set useActualParamName 允许使用方法签名中的名称作为语句参数名称。 为了使用该特性，你的工程必须采用Java 8编译，并且加上-parameters选项。（从3.4.1开始） true | false true configurationFactory 指定一个提供Configuration实例的类。 这个被返回的Configuration实例用来加载被反序列化对象的懒加载属性值。 这个类必须包含一个签名方法static Configuration getConfiguration(). (从 3.2.3 版本开始) 类型别名或者全类名. Not set typeAliases类型别名 记得我们在***Mapper.xml配置resultMap节点时需要配置type即需要映射的实体类类型，但是项目中一般实体类都在相同的目录下，这样写太过繁杂于是就有了简化的配置就别名配置，例如：123456789 &lt;typeAliases&gt; &lt;typeAlias alias=\"Blog\" type=\"domain.blog.Blog\"/&gt; &lt;/typeAliases&gt;``` &gt; 也可以配置包名,Mybatis会自动在包名下搜索需要的java bean 对象 ```xml &lt;typeAliases&gt; &lt;package name=\"domain.blog\"/&gt; &lt;/typeAliases&gt; typeHandlers类型转换器 mybatis在预处理语句中设置参数和从结果集中取出参数时都会使用类型转换器将获取的值以合适的方式转换为java类型。mybatis内置了大部分的类型转换器。这些类型转换器实现了TypeHandler接口，如果我们需要自己实现自定义的类型转换器，可以实现该接口，但是这个接口方法太多，我们一般继承BaseTypeHandler抽象类即可。例如我们实现一个枚举类型的转换器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 public interface HasIndexEnum &#123; int getIndex(); &#125; public class EnumTypeHandler&lt;T extends HasIndexEnum&gt; extends BaseTypeHandler&lt;T&gt; &#123; private Map&lt;Integer, T&gt; enumCache = new HashMap&lt;&gt;(); public EnumTypeHandler(Class&lt;T&gt; clazz) &#123; if (!Enum.class.isAssignableFrom(clazz) &amp;&amp; HasIndexEnum.class.isAssignableFrom(clazz)) &#123; throw new UnsupportedOperationException(\"Class shound be enum and implements HasIndexEnum.class!\"); &#125; T[] constants = clazz.getEnumConstants(); for (T e : constants) &#123; enumCache.put(e.getIndex(), e); &#125; &#125; @Override public void setNonNullParameter(PreparedStatement ps, int i, T parameter, JdbcType jdbcType) throws SQLException &#123; ps.setInt(i, parameter.getIndex()); &#125; @Override public T getNullableResult(ResultSet rs, String columnName) throws SQLException &#123; Object value = rs.getObject(columnName); if (rs.wasNull()) &#123; return null; &#125; return convertOrException(value); &#125; @Override public T getNullableResult(ResultSet rs, int columnIndex) throws SQLException &#123; Object value = rs.getObject(columnIndex); if (rs.wasNull()) &#123; return null; &#125; return convertOrException(value); &#125; @Override public T getNullableResult(CallableStatement cs, int columnIndex) throws SQLException &#123; Object value = cs.getObject(columnIndex); if (cs.wasNull()) &#123; return null; &#125; return convertOrException(value); &#125; private T convertOrException(Object value) &#123; T e = this.enumCache.get((Integer) value); if (null == e) &#123; throw new IllegalArgumentException(\"Cannot convert \" + value); &#125; else &#123; return e; &#125; &#125; &#125;``` &gt; 然后在mybatis-config.xml中配置该转换器 1234567891011121314151617181920212223242526### objectFactory对象工厂 &gt; 不怎么常用，略 ### plugins插件 &gt; MyBatis 允许你在已映射语句执行过程中的某一点进行拦截调用。默认情况下，MyBatis 允许使用插件来拦截的方法调用包括： &gt; * Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed) &gt; * ParameterHandler (getParameterObject, setParameters) &gt; * ResultSetHandler (handleResultSets, handleOutputParameters) &gt; * StatementHandler (prepare, parameterize, batch, update, query)&gt; 通过 MyBatis 提供的强大机制，使用插件是非常简单的，只需实现 &lt;code&gt;Interceptor&lt;/code&gt; 接口，并指定想要拦截的方法签名即可 ```java // ExamplePlugin.java @Intercepts(&#123;@Signature( type= Executor.class, method = \"update\", args = &#123;MappedStatement.class,Object.class&#125;)&#125;) public class ExamplePlugin implements Interceptor &#123; public Object intercept(Invocation invocation) throws Throwable &#123; return invocation.proceed(); &#125; public Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; public void setProperties(Properties properties) &#123; &#125; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041 &lt;!-- mybatis-config.xml --&gt; &lt;plugins&gt; &lt;plugin interceptor=\"org.mybatis.example.ExamplePlugin\"&gt; &lt;property name=\"someProperty\" value=\"100\"/&gt; &lt;/plugin&gt; &lt;/plugins&gt;``` &gt; 像一些分页插件，日志插件，分表插件都是基于插件实现的，后面我们会做详细的原理介绍，在此不作过多赘述。 ### environments 配置环境 &gt; mybatis与spring整合后，该配置就变得十分简单，在此不做介绍了。 ### mappers(映射器)&gt; 所谓的映射器就是指明我们编写的mapper.xml sql文件的位置的，便于mybatis去做关联。 &gt; 我们可以配置具体的文件，也可以配置整个包路径，同时还支持表达式符号，例如： ```xml &lt;!-- 使用相对于类路径的资源引用 --&gt; &lt;mappers&gt; &lt;mapper resource=\"org/mybatis/builder/AuthorMapper.xml\"/&gt; &lt;mapper resource=\"org/mybatis/builder/BlogMapper.xml\"/&gt; &lt;mapper resource=\"org/mybatis/builder/PostMapper.xml\"/&gt; &lt;/mappers&gt; &lt;!-- 使用完全限定资源定位符（URL） --&gt; &lt;mappers&gt; &lt;mapper url=\"file:///var/mappers/AuthorMapper.xml\"/&gt; &lt;mapper url=\"file:///var/mappers/BlogMapper.xml\"/&gt; &lt;mapper url=\"file:///var/mappers/PostMapper.xml\"/&gt; &lt;/mappers&gt; &lt;!-- 使用映射器接口实现类的完全限定类名 --&gt; &lt;mappers&gt; &lt;mapper class=\"org.mybatis.builder.AuthorMapper\"/&gt; &lt;mapper class=\"org.mybatis.builder.BlogMapper\"/&gt; &lt;mapper class=\"org.mybatis.builder.PostMapper\"/&gt; &lt;/mappers&gt; &lt;!-- 将包内的映射器接口实现全部注册为映射器,要求包名与xml文件的目录名一致 --&gt; &lt;mappers&gt; &lt;package name=\"org.mybatis.builder\"/&gt; &lt;/mappers&gt; 到此Mybatis的配置文件就介绍完了，下一节我们开始讨论学习Mybatis 的执行流程和原理","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://cnkeep.github.io/tags/Mybatis/"}]},{"title":"01_拓展-缓存(一级缓存)","date":"2018-09-02T17:25:00.000Z","path":"2018/09/03/06-01_拓展-缓存(一级缓存)/","text":"拓展-缓存(一级缓存) 目录 前言 正文 使用一级缓存 一级缓存原理分析 一级缓存的声明周期 总结 前言 前面几节，我们针对mybatis的执行流程，sql配置做了介绍。我们知道，mybatis是一个高效的orm框架，除了前几届了解到的功能，为了提高查询性能，mybatis也提供了缓存的功能，本节我们就一起来探究一下。 正文 我们在系统的运行过程中，总是会出现这样的情况：多次执行完全相同的查询语句，尤其是那种数据变化不大，读多写少的场景，重复的查库会增加系统的开销，自然我们就想到了使用缓存。mybatis就为我们提供了一级缓存和二级缓存的功能（实际生产中建议关闭缓存功能，让更专业的工具去做缓存的功能），本节我们来了解一下一级缓存。 使用一级缓存 在mybatis配置文件分析中介绍过缓存的配置 配置开启一级缓存12345678910111213&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;!-- 打印查询语句--&gt; &lt;setting name=\"logImpl\" value=\"STDOUT_LOGGING\" /&gt; &lt;!-- 共有2个选项，SESSION和STATEMENT,默认SESSION --&gt; &lt;setting name=\"localCacheScope\" value=\"SESSION\"/&gt; &lt;/settings&gt; &lt;mappers&gt; &lt;mapper resource=\"mapper/UserMapper.xml\" /&gt; &lt;/mappers&gt;&lt;/configuration&gt; 我们在同一个sqlSession中执行相同的sql 12345678910111213141516@Testpublic void mapperTest() &#123; SqlSessionFactory sqlSessionFactory = application.getBean(SqlSessionFactory.class); SqlSession sqlSession = sqlSessionFactory.openSession(); try &#123; UserMapper userMapper = sqlSession.getMapper(UserMapper.class); User user = userMapper.getById(\"4f98966b-f7a9-401c-b327-aa0e401d47b4\"); userMapper.getById(\"4f98966b-f7a9-401c-b327-aa0e401d47b4\"); System.out.println(user); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; sqlSession.close(); &#125;&#125; 查看数据库执行，发现只执行了一次： 之后改变localCacheScope为STATEMENT,发现执行了多次: 接下来我们来分析一级缓存是如何实现的。 一级缓存原理分析 在Mybati执行流程分析我们分析过，通过SqlSession去执行查询，最终会委托给Executor,我们发现一级缓存就属于Session级别，在同一个Sessino会话中有效，并且缓存信息存储在Executor中，来看一下查询流程：12345678910111213141516171819202122232425262728293031323334353637383940414243//BaseExecutor.classpublic &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; //去除多余代码，保留主要代码段 //判断是否需要清除缓存，可以在配置sql语句是执行flushCahe=true,默认为false if (queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) &#123; clearLocalCache(); &#125; List&lt;E&gt; list; //查询缓存 list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null; if (list != null) &#123; //缓存存在 handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); &#125; else &#123; //缓存不存在，查库 list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; //判断是否缓存结果，理论上都会缓存，只是设置了localCacheScope=STATEMENT会清除缓存 if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123; clearLocalCache(); &#125; return list;&#125; private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; List&lt;E&gt; list; localCache.putObject(key, EXECUTION_PLACEHOLDER); try &#123; list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql); &#125; finally &#123; localCache.removeObject(key); &#125; //一级缓存，缓存查询结果 localCache.putObject(key, list); if (ms.getStatementType() == StatementType.CALLABLE) &#123; localOutputParameterCache.putObject(key, parameter); &#125; return list; &#125; 我们来看看这个缓存的Key和实现原理，首先看Key的生成：12345678910111213141516171819202122232425262728293031323334353637383940//BaseExecutor.class/*** 使用id+offset+limit+sql+params来标示一次查询*/ public CacheKey createCacheKey(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql) &#123; if (closed) &#123; throw new ExecutorException(\"Executor was closed.\"); &#125; CacheKey cacheKey = new CacheKey(); cacheKey.update(ms.getId()); cacheKey.update(Integer.valueOf(rowBounds.getOffset())); cacheKey.update(Integer.valueOf(rowBounds.getLimit())); cacheKey.update(boundSql.getSql()); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); TypeHandlerRegistry typeHandlerRegistry = ms.getConfiguration().getTypeHandlerRegistry(); // mimic DefaultParameterHandler logic for (int i = 0; i &lt; parameterMappings.size(); i++) &#123; ParameterMapping parameterMapping = parameterMappings.get(i); if (parameterMapping.getMode() != ParameterMode.OUT) &#123; Object value; String propertyName = parameterMapping.getProperty(); if (boundSql.hasAdditionalParameter(propertyName)) &#123; value = boundSql.getAdditionalParameter(propertyName); &#125; else if (parameterObject == null) &#123; value = null; &#125; else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123; value = parameterObject; &#125; else &#123; MetaObject metaObject = configuration.newMetaObject(parameterObject); value = metaObject.getValue(propertyName); &#125; cacheKey.update(value); &#125; &#125; if (configuration.getEnvironment() != null) &#123; // issue #176 cacheKey.update(configuration.getEnvironment().getId()); &#125; return cacheKey; &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class CacheKey implements Cloneable, Serializable &#123; private List&lt;Object&gt; updateList;//用于存储参数列表 /** * 只关注重要的方法，其余的在此忽略.... */ //只是简单的将参数依次加入到List中 public void update(Object object) &#123; // 参数是Array，依次顺序追加之 if (object != null &amp;&amp; object.getClass().isArray()) &#123; int length = Array.getLength(object); for (int i = 0; i &lt; length; i++) &#123; Object element = Array.get(object, i); doUpdate(element); &#125; &#125; else &#123; doUpdate(object); &#125; &#125; private void doUpdate(Object object) &#123; int baseHashCode = object == null ? 1 : object.hashCode(); count++; checksum += baseHashCode; baseHashCode *= count; hashcode = multiplier * hashcode + baseHashCode; updateList.add(object); &#125; /** * 重要的方法：简单依次对比List中元素是否相等即可判断出sql是否相同 */ @Override public boolean equals(Object object) &#123; if (this == object) &#123; return true; &#125; if (!(object instanceof CacheKey)) &#123; return false; &#125; final CacheKey cacheKey = (CacheKey) object; if (hashcode != cacheKey.hashcode) &#123; return false; &#125; if (checksum != cacheKey.checksum) &#123; return false; &#125; if (count != cacheKey.count) &#123; return false; &#125; for (int i = 0; i &lt; updateList.size(); i++) &#123; Object thisObject = updateList.get(i); Object thatObject = cacheKey.updateList.get(i); if (thisObject == null) &#123; if (thatObject != null) &#123; return false; &#125; &#125; else &#123; if (!thisObject.equals(thatObject)) &#123; return false; &#125; &#125; &#125; return true; &#125;&#125; 可以看到，key是通过statementId+offset+limit+sql+params这几个条件决定，通过List将他们存储起来，对比相同只需要依次对比List中的元素是否相等即可判断是否为同一执行sql. 深入看缓存存储实现localCache,发现是PerpetualCache类，来一探究竟1234567891011121314151617181920212223public class PerpetualCache implements Cache &#123; private Map&lt;Object, Object&gt; cache = new HashMap&lt;Object, Object&gt;(); // 忽略一些方法，只关注重要的方法 @Override public void putObject(Object key, Object value) &#123; cache.put(key, value); &#125; @Override public Object getObject(Object key) &#123; return cache.get(key); &#125; @Override public Object removeObject(Object key) &#123; return cache.remove(key); &#125; @Override public void clear() &#123; cache.clear(); &#125;&#125; 恍然大悟，原来就是通过HashMap来存储sqlKey=result键值对。 一级缓存的声明周期 那么问题来了，既然有缓存，那缓存什么时候被清理呢？缓存的生命周期又是什么呢？看来我们还需要继续探索。我们继续在BaseExecutor中找线索,发现commit,rollback,close这三个方法中清除了缓存既然清理缓存是在这三个方法中，那这三个方法什么时候被调用呢？很容易通过SqlSession接口就知道如下调用规则： sql类型 调用方法 select close update commit,rollback,close delete commit,rollback,close 所以我们得出结论： 一级缓存声明周期是在session级别(因为session调用最终都会调用close方法清除缓存)。 一级缓存在执行update,delete操作时会被清除。 总结 一级缓存的流程： 对于某个Select Statement，根据该Statement生成key。 判断在Local Cache中,该key是否用对应的数据存在。 如果命中，则跳过查询数据库，继续往下走。 如果没命中： 去数据库中查询数据，得到查询结果 将key和查询到的结果作为key和value，放入Local Cache中 将查询结果返回 判断缓存级别是否为STATEMENT级别，如果是的话，清空本地缓存 一级缓存的特点： Mybatis一级缓存的生命周期和SqlSession一致，即只能在同一个sqlSession中共享缓存数据，存储在BaseExecutor中。 Mybatis的一级缓存是一个粗粒度的缓存，没有更新缓存和缓存过期的概念，同时只是使用了默认的hashmap，也没有做容量上的限定。 Mybatis的一级缓存最大范围是SqlSession内部，有多个SqlSession或者分布式的环境下，有操作数据库写的话，会引起脏数据，建议是把一级缓存的默认级别设定为Statement，即不使用一级缓存。 Mybatis的一级缓存不能人为干预，即无论设置了flushCache=true还是cacheScope=STATEMENT都不能阻止mybatis缓存查询结果，只能是控制在下一次查询时提前清空缓存，达到最终结果上的无缓存。","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://cnkeep.github.io/tags/Mybatis/"}]},{"title":"mbatis_catalog","date":"2018-09-02T15:31:00.000Z","path":"2018/09/02/00-mbatis_catalog/","text":"路线： 入门介绍 重要的几个接口： Configuration: Mybatis的配置信息都在该类中 SqlSession: 作为MyBatis工作的主要顶层API，表示和数据库交互的会话，完成必要数据库增删改查功能，类似于connection Executor: 执行器，是MyBatis 调度的核心，负责SQL语句的生成和查询缓存的维护 StatementHandler: 封装了JDBC Statement操作，负责对JDBC statement 的操作，如设置参数、将Statement结果集转换成List集合。 ParameterHandler: 负责将用户传递的参数转换成JDBC statement锁需要的参数。 ResultHandler: 负责将JDBC返回的ResultSet结果集装换为List集合 TypeHandler: 负责java数据类型和JDBC数据类型之间的映射和转化 MappedStatement: MappedStatement维护了一条&lt;select|update|delete|insert&gt;节点的封装 SqlSource: 负责根据用户传递的parameterObject，动态地生成SQL语句，将信息封装到BoundSql对象中，并返回 BoundSql: 表示动态生成的SQL语句以及相应的参数信息 实例操作，多库连接，动态创建SqlSessionFactory,与spring整合 提供Demo 配置文件mybatis-config.xml,内部结点的作用，顺序 执行流程，各个相关类 MapperProxy.invoke(…) Mapper接口的代理类, MapperMethod.execute(…) 按照sql类型分类执行 DefaultSqlSession.selectList(…) Executor.query(…) parameterHandler.parameterize()//设置参数 查询缓存是否存在 Executor.doQuery(…) statementHandler.query(…) prepareStatement.execute();//jdbc执行 resultSetHandler.handleResultSets() 处理结果 mapper.xml节点学习，动态sql 拓展：缓存 插件，分库分表，日志 个人实践：分页，分表，日志，TypeHandler抽象 总结，设计模式 大量的jdk静态代理使用，Plugin类似于洋葱模型生成代理模式 Builder模式，例如SqlSessionFactoryBuilder、XMLConfigBuilder、XMLMapperBuilder、XMLStatementBuilder、CacheBuilder； 工厂模式，例如SqlSessionFactory、ObjectFactory、MapperProxyFactory； 单例模式，例如ErrorContext和LogFactory； 代理模式，Mybatis实现的核心，比如MapperProxy、ConnectionLogger，用的jdk的动态代理；还有executor.loader包使用了cglib或者javassist达到延迟加载的效果； 组合模式，例如SqlNode和各个子类ChooseSqlNode等； 模板方法模式，例如BaseExecutor和SimpleExecutor，还有BaseTypeHandler和所有的子类例如IntegerTypeHandler； 适配器模式，例如Log的Mybatis接口和它对jdbc、log4j等各种日志框架的适配实现； 装饰者模式，例如Cache包中的cache.decorators子包中等各个装饰者的实现； 迭代器模式，例如迭代器模式PropertyTokenizer；","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://cnkeep.github.io/tags/Mybatis/"}]},{"title":"02_接口方式执行流程解读","date":"2018-09-02T15:29:00.000Z","path":"2018/09/02/04-02_接口方式执行流程解读/","text":"接口方式执行分析###前言 上节我们针对id方式mybatis的执行流程进行了分析，但是有的小伙伴就问了，我们都是用Mapper接口，那原理是啥，这节我们就分析一下。 正文mapper接口方式的调用示例 先生成mapper.xml文件配置我们的sql12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"test.mybatis.mapper.UserMapper\"&gt; &lt;resultMap type=\"test.entity.User\" id=\"user\"&gt; &lt;id column=\"id\" property=\"id\" javaType=\"String\"/&gt; &lt;result column=\"name\" property=\"name\"/&gt; &lt;/resultMap&gt; &lt;select id=\"findById\" resultMap=\"user\"&gt; select * from user where id = #&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt;``` &gt;* 提供xml对应的接口 ```java package test.entity; public class User&#123; private String id; private String name; public void setId(String id)&#123; this.id = id; &#125; public String getId()&#123; return id; &#125; public void setName(String name)&#123; this.name = name; &#125; public String getName()&#123; return name; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; if (!super.equals(o)) return false; User user = (User) o; if (!id.equals(user.id)) return false; return name.equals(user.name); &#125; @Override public int hashCode() &#123; int result = super.hashCode(); result = 31 * result + id.hashCode(); result = 31 * result + name.hashCode(); return result; &#125; &#125; 1234package test.mybatis.mapper;public interface User&#123; User findById(Integer id);&#125; 注意：这里接口的包名要和xml的namespace一致，方法名要和select结点的id一致 调用 1234567891011public class MybatisMapperDemo&#123; public static void main(String[] args)&#123; String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession openSession = sqlSessionFactory.openSession(); UserMapper mapper = openSession.getMapper(UserMapper.class); User user = mapper.findById(\"001\"); System.out.println(user); &#125;&#125; 源码分析 我们发现接口的包名和什么的都有限制，那先猜想一下是否就是通过接口的类名+方法名去生成id，从而转化到上一节的执行流程中，我们从源码中去分析一下是否是我们想的那样。 获取Mapper接口123456//DefaultSqlSession @Override public &lt;T&gt; T getMapper(Class&lt;T&gt; type) &#123; //调用Configuration获取 return configuration.&lt;T&gt;getMapper(type, this); &#125; mapper接口的获取最终委托给MapperProxyFactory去生成代理对象12345678910111213 // MapperRegistry.classpublic &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type); if (mapperProxyFactory == null) &#123; throw new BindingException(\"Type \" + type + \" is not known to the MapperRegistry.\"); &#125; try &#123; //委托给指定的MapperProxyFactory去生成 return mapperProxyFactory.newInstance(sqlSession); &#125; catch (Exception e) &#123; throw new BindingException(\"Error getting mapper instance. Cause: \" + e, e); &#125;&#125; 12345678910 //MapperProxyFactory.classpublic T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;T&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); &#125; protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; //JDK动态代理实现 return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy);&#125; 最终使用JDK的动态代理技术生成Mappe接口的代理对象，我们知道jdk动态代理的方法入口是InvocationHandler接口，即MapperProxy类，来分析一下该类。123456789101112131415161718192021222324252627282930313233343536373839public class MapperProxy&lt;T&gt; implements InvocationHandler, Serializable &#123; private static final long serialVersionUID = -6424540398559729838L; private final SqlSession sqlSession; private final Class&lt;T&gt; mapperInterface; private final Map&lt;Method, MapperMethod&gt; methodCache; public MapperProxy(SqlSession sqlSession, Class&lt;T&gt; mapperInterface, Map&lt;Method, MapperMethod&gt; methodCache) &#123; this.sqlSession = sqlSession; this.mapperInterface = mapperInterface; this.methodCache = methodCache; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //如果是从Object基类中声明的方法则直接执行，即过滤hashCode,equals，getClass等方法 if (Object.class.equals(method.getDeclaringClass())) &#123; try &#123; return method.invoke(this, args); &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; &#125; //通过MapperMethod去执行方法 final MapperMethod mapperMethod = cachedMapperMethod(method); return mapperMethod.execute(sqlSession, args); &#125; private MapperMethod cachedMapperMethod(Method method) &#123; MapperMethod mapperMethod = methodCache.get(method); if (mapperMethod == null) &#123; mapperMethod = new MapperMethod(mapperInterface, method, sqlSession.getConfiguration()); methodCache.put(method, mapperMethod); &#125; return mapperMethod; &#125;&#125; 接着看MapperMethod类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class MapperMethod &#123; private final SqlCommand command; private final MethodSignature method; public MapperMethod(Class&lt;?&gt; mapperInterface, Method method, Configuration config) &#123; this.command = new SqlCommand(config, mapperInterface, method); this.method = new MethodSignature(config, mapperInterface, method); &#125; public Object execute(SqlSession sqlSession, Object[] args) &#123; Object result; if (SqlCommandType.INSERT == command.getType()) &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.insert(command.getName(), param)); &#125; else if (SqlCommandType.UPDATE == command.getType()) &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); &#125; else if (SqlCommandType.DELETE == command.getType()) &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.delete(command.getName(), param)); &#125; else if (SqlCommandType.SELECT == command.getType()) &#123; if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) &#123; executeWithResultHandler(sqlSession, args); result = null; &#125; else if (method.returnsMany()) &#123; result = executeForMany(sqlSession, args); &#125; else if (method.returnsMap()) &#123; result = executeForMap(sqlSession, args); &#125; else if (method.returnsCursor()) &#123; result = executeForCursor(sqlSession, args); &#125; else &#123; Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); &#125; &#125; else if (SqlCommandType.FLUSH == command.getType()) &#123; result = sqlSession.flushStatements(); &#125; else &#123; throw new BindingException(\"Unknown execution method for: \" + command.getName()); &#125; if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) &#123; throw new BindingException(\"Mapper method '\" + command.getName() + \" attempted to return null from a method with a primitive return type (\" + method.getReturnType() + \").\"); &#125; return result; &#125; private &lt;E&gt; Object executeForMany(SqlSession sqlSession, Object[] args) &#123; List&lt;E&gt; result; Object param = method.convertArgsToSqlCommandParam(args); if (method.hasRowBounds()) &#123; RowBounds rowBounds = method.extractRowBounds(args); result = sqlSession.&lt;E&gt;selectList(command.getName(), param, rowBounds); &#125; else &#123; result = sqlSession.&lt;E&gt;selectList(command.getName(), param); &#125; // issue #510 Collections &amp; arrays support if (!method.getReturnType().isAssignableFrom(result.getClass())) &#123; if (method.getReturnType().isArray()) &#123; return convertToArray(result); &#125; else &#123; return convertToDeclaredCollection(sqlSession.getConfiguration(), result); &#125; &#125; return result; &#125; //其他的方法暂时省略+&#125; MapperMethod的execute()方法，根据sql的不同类型(insert,update,delete,select),执行相应的操作，最终还是通过SqlSession执行，又回到上一节的流程中。我们梳理一下流程: 通过MapperProxyFactory生成代理对象 通过接口调用的方式最终都进入到MapperProxy的invoke方法中 调用MapperMethod的execute方法 execute方法中通过sql的不同类型分类执行，最终还是通过SqlSession+id的方式执行","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://cnkeep.github.io/tags/Mybatis/"}]},{"title":"01_拓展-缓存(二级缓存)","date":"2018-09-02T14:47:00.000Z","path":"2018/09/02/06-01_拓展-缓存(二级缓存)/","text":"拓展-缓存(二级缓存) 目录 前言 正文 使用二级缓存 二级缓存原理分析 二级缓存的生命周期 总结 前言 上节我们针对一级缓存的原理做了探究，本节我们就一起来探究一下二级缓存。 二级缓存使用二级缓存 在mybatis配置文件分析中介绍过缓存的配置1.mapper-config.xml配置开启二级缓存1234567891011121314151617 &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt; &lt;configuration&gt; &lt;settings&gt; &lt;!-- 打印查询语句--&gt; &lt;setting name=\"logImpl\" value=\"STDOUT_LOGGING\" /&gt; &lt;!-- 二级缓存,默认true --&gt; &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; &lt;/settings&gt; &lt;mappers&gt; &lt;mapper resource=\"mapper/UserMapper.xml\" /&gt; &lt;/mappers&gt; &lt;/configuration&gt; ``` &gt; 2.在Mybatis的映射XML中配置cache或者 cache-ref 。 &lt;cache/&gt; 或 &lt;cache-ref namespace=&quot;mapper.UserMapper&quot;/&gt; 12345678910cache标签用于声明这个namespace使用二级缓存，并且可以自定义配置。 * type: cache使用的类型，默认是PerpetualCache，这在一级缓存中提到过。 * eviction: 定义回收的策略，常见的有FIFO，LRU。 * flushInterval: 配置一定时间自动刷新缓存，单位是毫秒 * size: 最多缓存对象的个数 * readOnly: 是否只读，若配置可读写，则需要对应的实体类能够序列化。 * blocking: 若缓存中找不到对应的key，是否会一直blocking，直到有对应的数据进入缓存。 &gt; 3.测试使用 @Test public void mapperTest() { SqlSessionFactory sqlSessionFactory = application.getBean(SqlSessionFactory.class); SqlSession sqlSession = sqlSessionFactory.openSession(); SqlSession sqlSession1 = sqlSessionFactory.openSession(); try { UserMapper userMapper = sqlSession.getMapper(UserMapper.class); UserMapper userMapper1 = sqlSession1.getMapper(UserMapper.class); User user = userMapper.getById(&quot;4f98966b-f7a9-401c-b327-aa0e401d47b4&quot;); //sqlSession.commit(); User user1 = userMapper1.getById(&quot;4f98966b-f7a9-401c-b327-aa0e401d47b4&quot;); } catch (Exception e) { e.printStackTrace(); } finally { sqlSession.close(); } } 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244执行发现报错： ![二级缓存需要实体序列化](images/two_level_cache_exception.png) 发现是因为二级缓存实体需要实现序列化，实现序列化后发现缓存没有生效，神奇了 ![二级缓存失效的错误](images/two_level_cache_invalid.png) 最后发现是因为第一个事务没有``commit``导致的，修改代码先提交事务1，再查询事务2，发现二级缓存生效，至于为什么要commit，先留个悬念，后面分析原理再说明 ### 二级缓存原理分析 Mybatis二级缓存的工作流程和前文提到的一级缓存类似，只是在一级缓存处理前，用CachingExecutor装饰了BaseExecutor的子类，实现了缓存的查询和写入功能。 ![CachingExecutor装饰Executor](images/create_cachingExecutor.png) &gt; 来看``CachingExecutor``类，这是一个装饰者模式的应用 ```java public class CachingExecutor implements Executor &#123; private Executor delegate;//装饰的对象 //管理缓存 private TransactionalCacheManager tcm = new TransactionalCacheManager(); /*** * 部分方法代码已经省略，这里只关注重要的方法.... */ public CachingExecutor(Executor delegate) &#123; this.delegate = delegate; delegate.setExecutorWrapper(this); &#125; @Override public void close(boolean forceRollback) &#123; try &#123; //是否回滚缓存 if (forceRollback) &#123; tcm.rollback(); &#125; else &#123; tcm.commit(); &#125; &#125; finally &#123; delegate.close(forceRollback); &#125; &#125; @Override public int update(MappedStatement ms, Object parameterObject) throws SQLException &#123; // 清除二级缓存 flushCacheIfRequired(ms); return delegate.update(ms, parameterObject); &#125; @Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; BoundSql boundSql = ms.getBoundSql(parameterObject); CacheKey key = createCacheKey(ms, parameterObject, rowBounds, boundSql); return query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); &#125; @Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; Cache cache = ms.getCache(); if (cache != null) &#123; /*根据Mapper.xml中sql节点配置的flushCache属性(select默认为false)判断是否需要清空缓存*/ flushCacheIfRequired(ms); /*根据Mapper.xml中sql节点配置的useCache属性(select默认为true)判断是否需要缓存查询结果*/ if (ms.isUseCache() &amp;&amp; resultHandler == null) &#123; ensureNoOutParams(ms, parameterObject, boundSql); //查询缓存 List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key); if (list == null) &#123; list = delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); tcm.putObject(cache, key, list); // issue #578 and #116 &#125; return list; &#125; &#125; return delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); &#125; @Override public void commit(boolean required) throws SQLException &#123; /*提交事务*/ delegate.commit(required); /*保存缓存，这就是为什么多个session必须提交之后缓存才生效的原因*/ tcm.commit(); &#125; @Override public void rollback(boolean required) throws SQLException &#123; /*事务和缓存同时回滚*/ try &#123; delegate.rollback(required); &#125; finally &#123; if (required) &#123; tcm.rollback(); &#125; &#125; &#125; @Override public CacheKey createCacheKey(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql) &#123; return delegate.createCacheKey(ms, parameterObject, rowBounds, boundSql); &#125; @Override public void clearLocalCache() &#123; /*清除一级缓存 */ delegate.clearLocalCache(); &#125; private void flushCacheIfRequired(MappedStatement ms) &#123; Cache cache = ms.getCache(); /*select默认为flushCache=false; update,delete为false. 即修改操作会清除缓存*/ if (cache != null &amp;&amp; ms.isFlushCacheRequired()) &#123; tcm.clear(cache); &#125; &#125; &#125;``` 通过对原有的Executor执行器做装饰来实现缓存的功能 &gt; 我们重点来看``TransactionalCacheManager``类 ```java public class TransactionalCacheManager &#123; //利用map来临时存储缓存 private Map&lt;Cache, TransactionalCache&gt; transactionalCaches = new HashMap&lt;Cache, TransactionalCache&gt;(); /*** * 这里只给出部分源代码.... */ public void putObject(Cache cache, CacheKey key, Object value) &#123; getTransactionalCache(cache).putObject(key, value); &#125; public void commit() &#123; for (TransactionalCache txCache : transactionalCaches.values()) &#123; txCache.commit(); &#125; &#125; public void rollback() &#123; for (TransactionalCache txCache : transactionalCaches.values()) &#123; txCache.rollback(); &#125; &#125; private TransactionalCache getTransactionalCache(Cache cache) &#123; TransactionalCache txCache = transactionalCaches.get(cache); if (txCache == null) &#123; //对Cache重新包装为TransactionalCache,可以像事务一样的操作缓存 txCache = new TransactionalCache(cache); transactionalCaches.put(cache, txCache); &#125; return txCache; &#125; &#125;``` &gt; ``TransactionlCache``类，它提供了类似于事务操作的方式来操作缓存 ```java public class TransactionalCache implements Cache &#123; //装饰源对象 private Cache delegate; //用于标示是否提交时先清除缓存 private boolean clearOnCommit; //临时缓存区，存储待提交的缓存信息 private Map&lt;Object, Object&gt; entriesToAddOnCommit; private Set&lt;Object&gt; entriesMissedInCache; public TransactionalCache(Cache delegate) &#123; this.delegate = delegate; this.clearOnCommit = false; this.entriesToAddOnCommit = new HashMap&lt;Object, Object&gt;(); this.entriesMissedInCache = new HashSet&lt;Object&gt;(); &#125; @Override public Object getObject(Object key) &#123; // issue #116 Object object = delegate.getObject(key); if (object == null) &#123; entriesMissedInCache.add(key); &#125; // issue #146 if (clearOnCommit) &#123; return null; &#125; else &#123; return object; &#125; &#125; @Override public void putObject(Object key, Object object) &#123; entriesToAddOnCommit.put(key, object); &#125; //提交缓存，即确认缓存信息需要保存 public void commit() &#123; if (clearOnCommit) &#123; delegate.clear(); &#125; flushPendingEntries(); reset(); &#125; public void rollback() &#123; unlockMissedEntries(); reset(); &#125; private void reset() &#123; clearOnCommit = false; entriesToAddOnCommit.clear(); entriesMissedInCache.clear(); &#125; //将缓存信息放入最终缓存区 private void flushPendingEntries() &#123; for (Map.Entry&lt;Object, Object&gt; entry : entriesToAddOnCommit.entrySet()) &#123; delegate.putObject(entry.getKey(), entry.getValue()); &#125; for (Object entry : entriesMissedInCache) &#123; if (!entriesToAddOnCommit.containsKey(entry)) &#123; delegate.putObject(entry, null); &#125; &#125; &#125; private void unlockMissedEntries() &#123; for (Object entry : entriesMissedInCache) &#123; try &#123; delegate.removeObject(entry); &#125; catch (Exception e) &#123; log.warn(\"Unexpected exception while notifiying a rollback to the cache adapter.\" + \"Consider upgrading your cache adapter to the latest version. Cause: \" + e); &#125; &#125; &#125; &#125; 我们看到TransactionalCacheManager和TransactionalCache组合提供了类似事务操作的方式来控制缓存的功能,当然mybatis不可能止步于此，它做的更深入：二级缓存使用了装饰器模式优雅的做了很多事情，如图： 装饰类的执行链：SynchroinzedCache -&gt; LoggingCache -&gt; SerializedCache -&gt; LruCache -&gt; PerpetualCache，来看看每个装饰器都是什么功能： SynchronizedCache: 同步的方式操作Cache，实现比较简单，直接使用synchronized修饰方法。 LoggingCache: 日志功能，装饰类，用于记录缓存的命中率，如果开启了DEBUG模式，则会输出命中率日志。 SerializedCache: 序列化功能，将值序列化后存到缓存中。该功能用于缓存返回一份实例的Copy，用于保存线程安全。 LruCache: 采用了Lru算法实现（内部使用LinkedHashMap实现），移除最近最少使用的缓存。 PerpetualCache: 作为最基础的缓存类，底层实现比较简单，直接使用了HashMap来存储数据。 二级缓存的生命周期 上面我们说到二级缓存采用了装饰器模式，其中存在LruCache装饰器，该装饰器就管理着我们的缓存有效性，所以从理论上讲二级缓存属于应用级别的。此外，二级缓存虽然可以在不同SqlSession之间共享缓存，但是还是有限制的，因为cache的作用域为同一个namespace，即在同一个namespace下才使用相同的缓存，不同的namespace使用的是不同的缓存。这样在多表级联且在多个namespace下时存在脏数据，实际上达到不能共享缓存的目的，我们可以使用cache-ref指定相同的namespace（不建议这么做）。同样的insert,update,delete操作时会清除原有缓存 总结 二级缓存的执行时流程： 根据配置生成包装的CachingExecutor来增强executor的功能 当sqlSession委托executor执行器执行查询时，判断是否存在缓存 存在时，判断是否开启了二级缓存，开启的话，获取具体的缓存信息，如果存在就直接返回; 不存在就查库并放入临时缓存区 不存在，直接查库(理论上配置开启了二级缓存是不会出现这种情况的) 提交事务，临时缓存真正存储到二级缓存区 二级缓存的特点： Mybatis二级缓存是基于namespace的，同一个namespace下的属于同一个缓存，不同的namespace使用不同的缓存，但是可以通过cache-ref解决。 Mybatis二级缓存的生命周期与应用一致，存储在Configuration中(实际在MappedStatement中两者是一样的)，失效清理策略可自行配置失效策略，默认是LRU。 Mybatis二级缓存的实体对象需要序列化。 Mybatis二级缓存是一个粗粒度的缓存，可以实现在不同sqlsession之间共享缓存。 Mybatis的二级缓存在多表查询时，极大可能会出现脏数据，有设计上的缺陷，且在分布式环境下因为默认缓存是在本地，必然会读到脏数据，还不容使用其他类似redis,memcache来的好些。 一二级缓存的处理流程：","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://cnkeep.github.io/tags/Mybatis/"}]},{"title":"01_应用实践-补充","date":"2018-09-02T13:29:00.000Z","path":"2018/09/02/07-01_应用实践-补充/","text":"应用实践-补充 目录 主键生成 批量插入时的主键获取","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://cnkeep.github.io/tags/Mybatis/"}]},{"title":"01_事务","date":"2018-09-01T17:16:00.000Z","path":"2018/09/02/08-01_事务/","text":"Mybatis事务管理[目录] 事务的特性事务的隔离级别介绍 事务带来的问题通过事务隔离来解决问题事务原理JDBC事务实现Mybatis事务实现啰嗦一下 事务的特性 事务的四个特性（ACID）已经是老生常谈的话题，想必各位已经都熟记于心，这里就帮大家快速的回忆一下: 原子性(Atomicity): 体现在同一个事务的操作要么一起成功，要么集体失败。 一致性(Consistent): 表现在事务执行前后系统是整体稳定的，比如对于出入账操作不会存在总资金的变化。 隔离性(Isolation): 变现在各个事务之间是相互隔离的，不会相互影响。 持久性(Durability): 事务一旦执行成功了，对于数据库的修改是永久性的。 事务的隔离级别 在讲事务的隔离级别之前，先分析一下事务的引入在并发的情况下会遇到什么样的问题。 事务带来的问题脏读 考虑转账的情况： 账号A, 开启事务1，自己账户减500，通知B,我已经转账你了，你看我的账号都减了; 账号B, 开启事务2，进行了查询操作，发现账户A确实减了(此时事务1还未提交，已经发生了脏读), 自己账户增加500，提交事务; 账号A, 因为一些问题，回滚事务; 最终发现账号A钱数没减，账号B钱数增加了500，但是这500事实上不存在; 像上面这样的情况，事务2读取到事务1未提交的数据，就发生了脏读。 不可重复读 同样是上面转账的情景，此外银行还有一个策略（当银行账户钱数少于500时即冻结账户）： 账号A, 开启事务1，自己账户减500，通知B,我已经转账你了，你看我的账号都减了; 账号B, 开启事务2，进行了查询操作，发现账户A确实减了，同时A的账户到达了最低值，异步锁定了账户A并通知A解锁; 账号A, 因为一些问题，回滚事务1，账号B一看A不转了，那我也不加了，回滚事务2; 最终发现账号A钱数没有小于500，但是A很奇怪，我的账户咋不能用了,投诉就来了; 像上面的情况，在一个事务里,因为另一个事务修改操作，导致同一个事务前后读取的数据不一致，就造成了不可重复读的问题。 幻读 这次不是转账了，是银行搞活动，存款大于1000的送100(想得美)： 事务1，查看当前存款大于1000的用户，给这些账号送钱; 事务2，存款1500，提交事务; 事务1，看看送钱的结果，我擦，咋有个用户没有送钱; 像上面的情况，在一个事务里，因为另一个事务删除或者插入的操作，导致同一个事务里的数据前后不一致，就造成了幻读的问题。 丢失更新 除了上面提到的这些问题，还有一种问题会出现，那就是丢失更新的问题： 皮一下 当你明白舍生取义，就会回来和我一起唱这首歌了,” 当当当。。。”（跑题了） 通过事务隔离来解决问题 既然事务带来这么多的问题，但是我们还要用事务，有没有什么好的办法去解决呢？ 答案是有的，这就要引入我们事务隔离机制了。根据处理的不同，事务的隔离级别分为四种： 隔离级别 特点 none read_uncommitted 读未提交：脏读、不可重复读、幻读均不能避免 read_committed 读已提交：避免脏读；不可重复读，幻读不能避免 repeatable_read 可重复读：避免脏读、不可重复读；幻读不能避免 serializable 序列化：避免脏读、不可重复读、幻读；不能解决丢失更新的问题 mysql默认的事务隔离级别是repeatable_read 事务原理JDBC事务实现 我们先来看看jdbc方式如何实现事务操作 1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.sql.*;/*** jdk&gt;=1.7 */public class JdbcTransactionTest&#123; private static String driverClass = \"com.mysql.jdbc.Driver\"; private static String url = \"jdbc:mysql://localhost:3306/zhiyun_os?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=true\"; private static String userName = \"root\"; private static String password = \"123456\"; static &#123; Class.forName(driverClass); &#125; public static Connection getConnection() throws SQLException&#123; return DriverManager.getConnection(url,userName.password); &#125; public static void transactionTest()&#123; Connection connection = getConnection(); //需要关闭自动提交，否则数据库会为每一条sql建立一个新的事务 connection.setAutoCommit(false); try&#123; //update operation //insert operation //select operation //事务提交 connection.commit(); &#125;catch (Exception e)&#123; //异常，事务回滚 if(null!=connection)&#123; connection.rollback(); &#125; &#125;finally&#123; close(connection); &#125; &#125; public static void close(AutoCloseable closeable)&#123; if(null!=closeable)&#123; closeable.close(); &#125; &#125;&#125; 我们看到，事务是依托Connection操作完成的，那我们大胆的猜想一下，Mybatis肯定也是通过某种手段来按照标准jdbc的方式来操作事务，只是隐藏起来了，这里我们似乎闻到了一丝原理的气息，嘿嘿嘿~ Mybatis事务实现 先看下mybatis是如何操作事务的： mybati-config.xml123456789101112131415161718&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;transactionManager type=\"JDBC\" /&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"com.mysql.jdbc.Driver\" /&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/test\" /&gt; &lt;property name=\"username\" value=\"root\" /&gt; &lt;property name=\"password\" value=\"123456\" /&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource=\"mapper/UserMapper.xml\" /&gt; &lt;/mappers&gt;&lt;/configuration&gt; 1234567891011121314151617181920public class MybatisTransactionTest&#123; public static void main(String[] args) throws IOException &#123; String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); try(SqlSession openSession = sqlSessionFactory.openSession())&#123; /** * openSession.insert(...); * openSession.update(...); * openSession.select(...); */ openSession.commit(); &#125;catch (Exception e)&#123; openSession.rollBack(); &#125; &#125;&#125; 回顾一下我们之前讲的，SqlSession是mybatis暴露给我们的外部接口，代表着一个数据库连接，一次回话，那我们可以简单的理解为对Connection的抽象(实际不是),我们看看mybatis是如何完成事务的，从openSession()开始：12345678910111213141516171819//DefalutSqlSessionFactoryprivate SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; final Environment environment = configuration.getEnvironment(); //获取事务工厂类 final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); //创建事务 tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); //事务注入到Executor,我们知道Executor是真正的执行者 final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); &#125; catch (Exception e) &#123; closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(\"Error opening session. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; 我们发现在创建一个SqlSession会话时，就已经开启了一个事务，我们来看看openSession.commit()和rollBack()方法，直接去BaseExecutor中查看：1234567891011121314151617181920212223242526272829 @Overridepublic void commit(boolean required) throws SQLException &#123; if (closed) &#123; throw new ExecutorException(\"Cannot commit, transaction is already closed\"); &#125; //清理缓存 clearLocalCache(); flushStatements(); if (required) &#123; //事务提交 transaction.commit(); &#125;&#125;@Overridepublic void rollback(boolean required) throws SQLException &#123; if (!closed) &#123; try &#123; clearLocalCache(); flushStatements(true); &#125; finally &#123; if (required) &#123; //事务提交 transaction.rollback(); &#125; &#125; &#125;&#125; 于是我们想，事务又是如何提交和回滚的，我们想到了jdbc是通过Connection来操作的，其实Mybatis也是如此，我们来看实现类JdbcTransaction123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108public class JdbcTransaction implements Transaction &#123; protected Connection connection; protected DataSource dataSource; protected TransactionIsolationLevel level; protected boolean autoCommmit; public JdbcTransaction(DataSource ds, TransactionIsolationLevel desiredLevel, boolean desiredAutoCommit) &#123; dataSource = ds; level = desiredLevel; autoCommmit = desiredAutoCommit; &#125; @Override public Connection getConnection() throws SQLException &#123; if (connection == null) &#123; openConnection(); &#125; return connection; &#125; @Override public void commit() throws SQLException &#123; if (connection != null &amp;&amp; !connection.getAutoCommit()) &#123; if (log.isDebugEnabled()) &#123; log.debug(\"Committing JDBC Connection [\" + connection + \"]\"); &#125; connection.commit(); &#125; &#125; @Override public void rollback() throws SQLException &#123; if (connection != null &amp;&amp; !connection.getAutoCommit()) &#123; if (log.isDebugEnabled()) &#123; log.debug(\"Rolling back JDBC Connection [\" + connection + \"]\"); &#125; connection.rollback(); &#125; &#125; @Override public void close() throws SQLException &#123; if (connection != null) &#123; resetAutoCommit(); if (log.isDebugEnabled()) &#123; log.debug(\"Closing JDBC Connection [\" + connection + \"]\"); &#125; connection.close(); &#125; &#125; protected void setDesiredAutoCommit(boolean desiredAutoCommit) &#123; try &#123; if (connection.getAutoCommit() != desiredAutoCommit) &#123; if (log.isDebugEnabled()) &#123; log.debug(\"Setting autocommit to \" + desiredAutoCommit + \" on JDBC Connection [\" + connection + \"]\"); &#125; connection.setAutoCommit(desiredAutoCommit); &#125; &#125; catch (SQLException e) &#123; // Only a very poorly implemented driver would fail here, // and there's not much we can do about that. throw new TransactionException(\"Error configuring AutoCommit. \" + \"Your driver may not support getAutoCommit() or setAutoCommit(). \" + \"Requested setting: \" + desiredAutoCommit + \". Cause: \" + e, e); &#125; &#125; protected void resetAutoCommit() &#123; try &#123; if (!connection.getAutoCommit()) &#123; // MyBatis does not call commit/rollback on a connection if just selects were performed. // Some databases start transactions with select statements // and they mandate a commit/rollback before closing the connection. // A workaround is setting the autocommit to true before closing the connection. // Sybase throws an exception here. if (log.isDebugEnabled()) &#123; log.debug(\"Resetting autocommit to true on JDBC Connection [\" + connection + \"]\"); &#125; connection.setAutoCommit(true); &#125; &#125; catch (SQLException e) &#123; if (log.isDebugEnabled()) &#123; log.debug(\"Error resetting autocommit to true \" + \"before closing the connection. Cause: \" + e); &#125; &#125; &#125; protected void openConnection() throws SQLException &#123; if (log.isDebugEnabled()) &#123; log.debug(\"Opening JDBC Connection\"); &#125; connection = dataSource.getConnection(); if (level != null) &#123; connection.setTransactionIsolation(level.getLevel()); &#125; setDesiredAutoCommit(autoCommmit); &#125; @Override public Integer getTimeout() throws SQLException &#123; return null; &#125; &#125; 可以看到事务的操作最终还是回归到最原始的JDBC操作了，看到这里我想大家应该可以总结出来一些内容了吧：我们开启一次回话默认会开启一个新的事务，回话的提交和回滚最后还是通过事务的回滚和提交来操作的。那问题就归结到事务Transaction对象怎么通过TransactionFactory创建的。 我们来看看TransactionFactory的类图： 其中：ManagedTransactionFactory表示将事务委托给第三发服务去处理，比如JBoss，其生成的ManagedTransacton内部也是什么都不做。JdbcTransactionFactory表示通过jdbc的事务机制来实现事务，这也是我们常用的实现方式，当然与spring集成时使用的是SpringTransactionFactory其实也是通过jdbc实现的变种，这里不做介绍。至于使用JDBC还是Manager我们可以在mybatis-config.xml中配置： 总结一下 自此我们对Mybatis的事务就了解的差不多了，总结一下： Mybatis自身不处理事务，而是将提供事务接口TransactionFactory，由外界注入处理处理事务，只是其默认提供了JDBC和Managed两种模式。 新建一个回话就会开启一个事务，回话的提交和回滚最终都是由事务的提交和回滚完成的。 啰嗦一下 说道Mybatis事务不得不说Spring事务管理，简单说Spring集成Mybatis管理事务时，内部使用的还是标准JDBC去完成事务的操作，只是spring通过AOP在我们执行方法前后自动的完成了事务的操作。","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://cnkeep.github.io/tags/Mybatis/"}]},{"title":"02_拓展-插件(Plugin)","date":"2018-09-01T16:48:00.000Z","path":"2018/09/02/06-02_拓展-插件(Plugin)/","text":"Mybatis插件(Plugin)目录 前言 前言 Mybatis利用接口将各个层进行分离的同时也提供了手段给予编程者去修改mybatis的默认行为，最经典的要属其插件的使用，本节我们就来研究一下。 介绍 Mybatis允许用户使用自定义拦截器对sql语句执行过程中的某一点进行拦截，我们可以拦截四大接口(Executor,StatementHandler,ParameterHandler,ResultSetHandler)的方法来实现某些功能。1.使用拦截器需要实现Interceptor接口,Interceptor是实现Plugin的核心，其定义如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546 public interface Interceptor &#123; //执行拦截逻辑的方法 Object intercept(Invocation var1) throws Throwable; //决定是否触发interceptor()方法 Object plugin(Object var1); //根据配置初始化Interceptor对象 void setProperties(Properties var1); &#125;``` 除了实现Interceptor接口外，还需要在注解中指明拦截的类和方法： ```java @Intercepts(&#123;@Signature(type = Executor.class, method = \"query\", args = &#123; MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class &#125;)&#125;) public class TableExecutorInterceptor implements Interceptor &#123; private Logger logger = LoggerFactory.getLogger(TableExecutorInterceptor.class); /*** * 拦截后的操作处理 */ @Override public Object intercept(Invocation invocation) throws Throwable &#123; Object result = invocation.proceed(); logger.info(\"result:&#123;&#125;\",result); return result; &#125; @Override public Object plugin(Object target) &#123; if (target instanceof Executor) &#123; //返回代理对象 return Plugin.wrap(target, this); &#125; else &#123; return target; &#125; &#125; @Override public void setProperties(Properties properties) &#123; //初始化配置的参数 &#125; &#125; 针对注解格式做一下说明:123456789@Interceptor( &#123; @Signature( type=,//指明拦截的类的名称 method=,//拦截的方法名 args=&#123;&#125;//拦截的方法的参数列表，通过方法名+参数列表可以匹配指定的方法 ) &#125;) 2.配置文件中声明拦截器1234567891011121314151617181920212223242526&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!-- &lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;transactionManager type=\"JDBC\" /&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"com.mysql.jdbc.Driver\" /&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/test\" /&gt; &lt;property name=\"username\" value=\"root\" /&gt; &lt;property name=\"password\" value=\"123456\" /&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; --&gt; &lt;settings&gt; &lt;!-- 打印查询语句--&gt; &lt;setting name=\"logImpl\" value=\"STDOUT_LOGGING\" /&gt; &lt;/settings&gt; &lt;plugins&gt; &lt;plugin interceptor=\"test.mybatis.plugins.TablePrepareInterceptor\"&gt;&lt;/plugin&gt; &lt;/plugins&gt; &lt;mappers&gt; ...... &lt;/mappers&gt;&lt;/configuration&gt; 到此自定义的拦截器就配置好了，在Mybatis初始化时，会通过XMLConfigBuilder.pluginElement()方法解析mybatis-config.xml配置文件中定义的节点，得到相应的Interceptor对象以及配置的相应属性，之后会调用Interceptor.setProperties(properties)方法完成对Interceptor对象初始化配置，最后将Interceptor对象添加到Configuration.interceptorChain字段中保存。 拦截原理 Mybatis中有一个很重要的类-Configuration，该配置类为我们提供各种接口实例的获取，其中就包括四大接口，这四种接口对象都是通过newXXXX()方法获得的，如果配置了拦截器，就会在生成这些对象后，通过interceptorChain.pluginAll(…)来生成代理对象，最终返回的都是代理对象。例如创建Executor对象:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051 public Executor newExecutor(Transaction transaction, ExecutorType executorType) &#123; executorType = executorType == null ? defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; // 根据参数，选择合适的Executor if (ExecutorType.BATCH == executorType) &#123; executor = new BatchExecutor(this, transaction); &#125; else if (ExecutorType.REUSE == executorType) &#123; executor = new ReuseExecutor(this, transaction); &#125; else &#123; executor = new SimpleExecutor(this, transaction); &#125; // 根据配置决定是否开启二级缓存 if (cacheEnabled) &#123; executor = new CachingExecutor(executor); &#125; //通过InterceptorChain.pluginAll()方法创建Executor的代理对象 executor = (Executor) interceptorChain.pluginAll(executor); return executor; &#125;``` InterceptorChain中使用interceptors字段(ArrayList&lt;Interceptor&gt;类型)记录了mybatis-config.xml文件中配置的拦截器。在InterceptorChain.pluginAll()方法中会遍历该interceptors集合，并调用其中的每个元素的plugin()方法创建代理对象，创建代理对象的 代理对象，类似于洋葱一样，![](images/plugins.png) 具体的实现如下所示。```java public class InterceptorChain &#123; //保存配置的拦截器 private final List&lt;Interceptor&gt; interceptors = new ArrayList&lt;Interceptor&gt;(); //依次调用plugin生成代理对象 public Object pluginAll(Object target) &#123; for (Interceptor interceptor : interceptors) &#123; target = interceptor.plugin(target); &#125; return target; &#125; public void addInterceptor(Interceptor interceptor) &#123; interceptors.add(interceptor); &#125; public List&lt;Interceptor&gt; getInterceptors() &#123; return Collections.unmodifiableList(interceptors); &#125; &#125; 不当的使用Interceptor的plugin方法生成代理对象是危险的，因为这会改变Mybatis原有的执行流程，很有可能会导致程序无法运行，为此mybatis为我们提供了Plugin类的wrap方法来实现代理的生成，减少出错的可能，因此我们在重写plugin方法时推荐使用Plugin类。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public class Plugin implements InvocationHandler &#123; private Object target;//目标对象 private Interceptor interceptor;//拦截器 private Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap; private Plugin(Object target, Interceptor interceptor, Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap) &#123; this.target = target; this.interceptor = interceptor; this.signatureMap = signatureMap; &#125; public static Object wrap(Object target, Interceptor interceptor) &#123; //获取用户自定义Interceptor中@Signature注解的信息，getSignatureMap()方法负责处理@Signture注解 Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = getSignatureMap(interceptor); Class&lt;?&gt; type = target.getClass(); ////获取目标类型实现的接口，正如前文所述，拦截器可以拦截4类对象都实现了相应的接口，这也是能使用JDK动态代理的方式创建对象的基础 Class&lt;?&gt;[] interfaces = getAllInterfaces(type, signatureMap); if (interfaces.length &gt; 0) &#123; //使用JDK动态代理的方式创建代理对象 return Proxy.newProxyInstance( type.getClassLoader(), interfaces, new Plugin(target, interceptor, signatureMap)); &#125; return target; &#125; //拦截方法入口 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; //获取方法签名 Set&lt;Method&gt; methods = signatureMap.get(method.getDeclaringClass()); //判断是否需要拦截 if (methods != null &amp;&amp; methods.contains(method)) &#123; //需要拦截，则执行相应的拦截方法 return interceptor.intercept(new Invocation(target, method, args)); &#125; //不需要拦截，则执行原有的方法 return method.invoke(target, args); &#125; catch (Exception e) &#123; throw ExceptionUtil.unwrapThrowable(e); &#125; &#125; private static Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; getSignatureMap(Interceptor interceptor) &#123; Intercepts interceptsAnnotation = interceptor.getClass().getAnnotation(Intercepts.class); // issue #251 if (interceptsAnnotation == null) &#123; throw new PluginException(\"No @Intercepts annotation was found in interceptor \" + interceptor.getClass().getName()); &#125; Signature[] sigs = interceptsAnnotation.value(); Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = new HashMap&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt;(); for (Signature sig : sigs) &#123; Set&lt;Method&gt; methods = signatureMap.get(sig.type()); if (methods == null) &#123; methods = new HashSet&lt;Method&gt;(); signatureMap.put(sig.type(), methods); &#125; try &#123; Method method = sig.type().getMethod(sig.method(), sig.args()); methods.add(method); &#125; catch (NoSuchMethodException e) &#123; throw new PluginException(\"Could not find method on \" + sig.type() + \" named \" + sig.method() + \". Cause: \" + e, e); &#125; &#125; return signatureMap; &#125; private static Class&lt;?&gt;[] getAllInterfaces(Class&lt;?&gt; type, Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap) &#123; Set&lt;Class&lt;?&gt;&gt; interfaces = new HashSet&lt;Class&lt;?&gt;&gt;(); while (type != null) &#123; for (Class&lt;?&gt; c : type.getInterfaces()) &#123; if (signatureMap.containsKey(c)) &#123; interfaces.add(c); &#125; &#125; type = type.getSuperclass(); &#125; return interfaces.toArray(new Class&lt;?&gt;[interfaces.size()]); &#125;&#125; 最终方法会进入我们自定义的拦截器interceptor方法中，在该方法中实现自定义的内容，从而达到拦截的目的。 总结 总结一下拦截器的处理流程： SqlSession执行相应方法时，通过Configuration类获取对象的四大接口对象 Configuration根据config.xml中配置的plugin生成代理对象返回 当调用代理对象的方法时，进入Plugin对象的invoke方法，根据方法签名判断是否需要拦截该方法，不需要拦截则继续执行原方法；需要拦截的则进入自定义拦截器的intercept方法 继续执行","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://cnkeep.github.io/tags/Mybatis/"}]},{"title":"03_拓展-自定义类型转换器","date":"2018-09-01T15:43:00.000Z","path":"2018/09/01/06-03_拓展-自定义类型转换器/","text":"类型转换器-TypeHandler[目录] 前言自定义一个类型转化器 前言 我们知道Java有Java的数据类型，数据库也有数据库相应的数据类型，两者虽然不同，但是存在着某种对应关系。那Mybatis在插入插入数据时又是如何把Java数据类型转化为数据库对应的数据类型，查询时又是如何把数据库数据类型转化为Java数据类型返回给我们的呢? 这中间必然需要经过一个类型转化，Mybatis中提供了TypeHandler来完成类型的转化工作。 自定义一个类型转化器 在应用中我们经常会使用枚举类型来标示不同的状态，但在数据库存储时存储的是int数值，如果不采用自定义类型转化器，我们就需要在插入数据和查询数据时自己编写转化关系，这种方式虽然可以实现功能，但是太过低效，而且而不便于维护，接下来我们就利用Mybatis的自定义类型转换器来实现一个通用的枚举类型转化器。 实现TypeHandler接口 在Mybatis中要实现自己的TypeHandler就需要实现TypeHandler接口中定义的四个方法：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115 public interface TypeHandler&lt;T&gt; &#123; /** * 用于定义在Mybatis设置参数时该如何把Java类型的参数转换为对应的数据库类型 * @param ps 当前的PreparedStatement对象 * @param i 当前参数的位置 * @param parameter 当前参数的Java对象 * @param jdbcType 当前参数的数据库类型 * @throws SQLException */ void setParameter(PreparedStatement ps, int i, T parameter, JdbcType jdbcType) throws SQLException; /** * 用于在Mybatis获取数据结果集时如何把数据库类型转换为对应的Java类型 * @param rs 当前的结果集 * @param columnName 当前的字段名称 * @return 转换后的Java对象 * @throws SQLException */ T getResult(ResultSet rs, String columnName) throws SQLException; /** * 用于在Mybatis通过字段位置获取字段数据时把数据库类型转换为对应的Java类型 * @param rs 当前的结果集 * @param columnIndex 当前字段的位置 * @return 转换后的Java对象 * @throws SQLException */ T getResult(ResultSet rs, int columnIndex) throws SQLException; /** * 用于Mybatis在调用存储过程后把数据库类型的数据转换为对应的Java类型 * @param cs 当前的CallableStatement执行后的CallableStatement * @param columnIndex 当前输出参数的位置 * @return * @throws SQLException */ T getResult(CallableStatement cs, int columnIndex) throws SQLException; &#125;``` 我们可以选择实现该接口，但是直接实现该接口需要处理一些为空的情况，为了减少实现的复杂度，mybatis建议我们继承``BaseTypeHandler``类，实现其中的抽象方法即可： ```java /*** * 自定义枚举接口，用于返回枚举类型对应的数值类型，所有枚举类型需实现该接口 */ public interface HasIndexEnum &#123; int getIndex(); &#125; public class EnumTypeHandler&lt;T extends HasIndexEnum&gt; extends BaseTypeHandler&lt;T&gt; &#123; //存储枚举类型与数值类型的对应关系 private Map&lt;Integer, T&gt; enumCache = new HashMap&lt;&gt;(); /** * mybatis会传入Class生成TypeHandler */ public EnumTypeHandler(Class&lt;T&gt; clazz) &#123; if (!Enum.class.isAssignableFrom(clazz) &amp;&amp; HasIndexEnum.class.isAssignableFrom(clazz)) &#123; throw new UnsupportedOperationException(\"Class shound be enum and implements HasIndexEnum.class!\"); &#125; T[] constants = clazz.getEnumConstants(); for (T e : constants) &#123; enumCache.put(e.getIndex(), e); &#125; &#125; @Override public void setNonNullParameter(PreparedStatement ps, int i, T parameter, JdbcType jdbcType) throws SQLException &#123; ps.setInt(i, parameter.getIndex()); &#125; @Override public T getNullableResult(ResultSet rs, String columnName) throws SQLException &#123; Object value = rs.getObject(columnName); if (rs.wasNull()) &#123; return null; &#125; return convertOrException(value); &#125; @Override public T getNullableResult(ResultSet rs, int columnIndex) throws SQLException &#123; Object value = rs.getObject(columnIndex); if (rs.wasNull()) &#123; return null; &#125; return convertOrException(value); &#125; @Override public T getNullableResult(CallableStatement cs, int columnIndex) throws SQLException &#123; Object value = cs.getObject(columnIndex); if (cs.wasNull()) &#123; return null; &#125; return convertOrException(value); &#125; private T convertOrException(Object value) &#123; T e = this.enumCache.get((Integer) value); if (null == e) &#123; throw new IllegalArgumentException(\"Cannot convert \" + value); &#125; else &#123; return e; &#125; &#125; &#125;``` 这样一个通用的枚举类型的类型转换器就完成了，只要枚举类型实现了HasIndexEnum接口就可以使用该转换器处理。 ### 注册TypeHandler&gt; 在mapper-config中，注册你实现的转换器类，其中jdbcType可以指定的类型在Mybatis的枚举类org.apache.ibatis.type.JdbcType中有明确的定义，不能为该枚举以外的值，不然会出错。这里因为枚举中没有我们需要的XMLType类型，所以指定为UNDEFINED。（也可以不指定具体的类型，在使用时用typeHandler指定具体的类即可）： &lt;typeHandlers&gt; &lt;typeHandler handler=&quot;com.xxxx.handler.EnumTypeHandler&quot; jdbcType=&quot;INTEGER&quot; javaType=&quot;com.xxx.enums.XXXType&quot; /&gt; &lt;/typeHandlers&gt; ` 这样一个通用的枚举类型转化器就完成了，就可以帮助我们自动的完成类型转化工作了。","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://cnkeep.github.io/tags/Mybatis/"}]},{"title":"入门介绍","date":"2018-09-01T15:31:00.000Z","path":"2018/09/01/01-入门介绍/","text":"Mybatis入门介绍应用场景 最开始学习jdbc知识的时候，考虑一下我们是如何编写程序的？大概分为几个步骤: 配置基本参数 获取连接资源 编译sql 设置参数 执行sql 获取查询结果集 遍历结果集 释放连接资源 我们写个最简单的例子看一下：`javaimport java.sql.;import java.util.; public class JDBCUtil{ private static String url; private static String username; private static String pwd; private static String driverClass; //step 1: static { url = &quot;jdbc:mysql://127.0.0.1:3306/jdbc?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;failOverReadOnly=false&quot;; username = &quot;root&quot;; pwd = &quot;123456&quot;; driverClass = &quot;com.mysql.jdbc.Driver&quot;; } public static Connection getConnection() throws ClassNotFoundException, SQLException { Class.forName(driverClass); return java.sql.DriverManager.getConnection(url, username, pwd); } /** * 查询接口 * * @param sql 执行的查询sql,参数使用?占位 * @param params 占位符对应的参数列表 * @return List&lt;Map&lt;String,Object&gt;&gt; 查询结果，每行数据采用map存储，key=columnName,value = columnValue */ public static List&lt;Map&lt;String,Object&gt;&gt; query(String sql, java.util.List&lt;Object&gt; params) throws SQLException, ClassNotFoundException { //step 2: java.sql.Connection connection = getConnection(); //step 3: // 这里使用预编译的statement，防止sql注入 java.sql.PreparedStatement preparedStatement = connection.prepareStatement(sql); //step 4: // 设置参数 invokeParams(preparedStatement, params); //step 5 and 6: java.sql.ResultSet resultSet = preparedStatement.executeQuery(); //step 7: // 解析查询结果 List&lt;Map&lt;String,Object&gt;&gt; result = parseResult(resultSet); //step 8: // 关闭资源 close(resultSet, preparedStatement, connection); return result; } /** * 参数设置 * * @param preparedStatement * @param params * @throws SQLException */ public static void invokeParams(java.sql.PreparedStatement preparedStatement, java.util.List params) throws SQLException { if (null == preparedStatement || null == params) throw new IllegalArgumentException(&quot;[NullPointerException],params can not be null&quot;); ParameterMetaData parameterMetaData = preparedStatement.getParameterMetaData(); int parameterCount = parameterMetaData.getParameterCount(); if (parameterCount &lt; params.size()) { throw new IllegalArgumentException(&quot;params&apos;s size is worn, the size should be &quot; + parameterCount); } for (int index = 1; index &lt;= parameterCount; index++) { preparedStatement.setObject(index, params.get(index-1)); } } /** * 结果解析 * * @param resultSet */ private static List&lt;Map&lt;String, Object&gt;&gt; parseResult(ResultSet resultSet) throws SQLException { List&lt;Map&lt;String, Object&gt;&gt; resultList = new LinkedList&lt;Map&lt;String, Object&gt;&gt;(); ResultSetMetaData metaData = resultSet.getMetaData(); int columnCount = metaData.getColumnCount(); while (resultSet.next()) { Map&lt;String, Object&gt; rowData = new HashMap&lt;String, Object&gt;(); for (int index = 1; index &lt;= columnCount; index++) { String key = metaData.getColumnLabel(index); Object value = resultSet.getObject(index); rowData.put(key, value); } resultList.add(Collections.unmodifiableMap(rowData)); } return resultList; } private static void close(ResultSet resultSet, PreparedStatement preparedStatement, Connection connection) { try { if (null != resultSet) resultSet.close(); if (null != preparedStatement) preparedStatement.close(); if (null != connection) connection.close(); } catch (SQLException e) { e.printStackTrace(); } } public static void main(String[] args) throws SQLException, ClassNotFoundException { String sql = &quot;select * from customer where id=?&quot;; List&lt;Object&gt; params = new LinkedList&lt;Object&gt;(); params.add(1); List&lt;Map&lt;String, Object&gt;&gt; query = query(sql, params); System.out.println(query); } } ` 我们可以看到就简单的查询就这么多复杂的代码，既要连接数据库，又要设置参数，遍历结果集，而且其中很大一部分都是通用的，每次都写太麻烦了。有人就想到写一些工具类,来处理这些事情，类似于模板模式，同时在利用反射机制，就可以直接注入对象，结果集也可以直接反射成对象。完美！这种工具有一个高大上的名称叫ORM(对象关系映射)，Mybatis就是这么一个工具，节省开发工作量。 利弊 比较常用的ORM框架就是Hibernate和Mybatis,那么各自有什么优缺点呢？ Hibernate Hibernate的DAO层开发比MyBatis简单，Mybatis需要维护SQL和结果映射。 Hibernate对对象的维护和缓存要比MyBatis好，对增删改查的对象的维护要方便。 Hibernate数据库移植性很好，MyBatis的数据库移植性不好，不同的数据库需要写不同SQL。 Hibernate有更好的二级缓存机制，可以使用第三方缓存。MyBatis本身提供的缓存机制不佳。 强大、方便、高效、复杂、间接、全自动化 Mybatis Mybatis可以进行更为细致的SQL优化，可以减少查询字段。 Mybatis容易掌握，而Hibernate门槛较高。 小巧、方便、高效、简单、直接、半自动化 主要的几个类 Configuration: Mybatis的配置信息都在该类中 SqlSession: 作为MyBatis工作的主要顶层API，表示和数据库交互的会话，完成必要数据库增删改查功能，类似于connection Executor: 执行器，是MyBatis 调度的核心，负责SQL语句的生成和查询缓存的维护 StatementHandler: 封装了JDBC Statement操作，负责对JDBC statement 的操作，如设置参数、将Statement结果集转换成List集合。 ParameterHandler: 负责将用户传递的参数转换成JDBC statement锁需要的参数。 ResultHandler: 负责将JDBC返回的ResultSet结果集装换为List集合 TypeHandler: 负责java数据类型和JDBC数据类型之间的映射和转化 MappedStatement: MappedStatement维护了一条&lt;select|update|delete|insert&gt;节点的封装 SqlSource: 负责根据用户传递的parameterObject，动态地生成SQL语句，将信息封装到BoundSql对象中，并返回 BoundSql: 表示动态生成的SQL语句以及相应的参数信息","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://cnkeep.github.io/tags/Mybatis/"}]},{"title":"01_设计模式","date":"2018-09-01T14:46:00.000Z","path":"2018/09/01/09-01_设计模式/","text":"Mybatis中的设计模式 目录 前言 正文 Builder模式 动态代理模式 静态代理模式 适配器模式 装饰器模式","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://cnkeep.github.io/tags/Mybatis/"}]},{"title":"01_Mapper.xml学习","date":"2018-09-01T14:21:00.000Z","path":"2018/09/01/05-01_Mapper.xml学习/","text":"Mapper.xml学习前言 本节我们针对sql的配置映射文件Mapper.xml进行学习目录 基本元素（按照它们应该被定义的顺序）: select – 映射查询语句 sql – 可被其他语句引用的可重用语句块 insert – 映射插入语句 update – 映射更新语句 delete – 映射删除语句 parameterMap – 已废弃！老式风格的参数映射。内联参数是首选,这个元素可能在将来被移除，这里不会记录。 resultMap – 是最复杂也是最强大的元素，用来描述如何从数据库结果集中来加载对象。 cache-ref – 其他命名空间缓存配置的引用。 cache – 给定命名空间的缓存配置。 动态sql #{}和${}区别 动态表达式 正文基本元素select 查询语句是 MyBatis 中最常用的元素之一，光能把数据存到数据库中价值并不大，如果还能重新取出来才有用，多数应用也都是查询比修改要频繁。对每个插入、更新或删除操作，通常对应多个查询操作。这是 MyBatis 的基本原则之一，也是将焦点和努力放到查询和结果映射的原因。简单查询的 select 元素是非常简单的。比如：123&lt;select id=\"selectPerson\" parameterType=\"int\" resultType=\"hashmap\"&gt; SELECT * FROM PERSON WHERE ID = #&#123;id&#125;&lt;/select&gt; 这个语句被称作 selectPerson，接受一个 int（或 Integer）类型的参数，并返回一个 HashMap 类型的对象，其中的键是列名，值便是结果行中的对应值。 注意参数符号：#{id} 这就告诉 MyBatis 创建一个预处理语句参数，通过 JDBC，这样的一个参数在 SQL 中会由一个“?”来标识，并被传递到一个新的预处理语句中，就像这样：1234// Similar JDBC code, NOT MyBatis…String selectPerson = \"SELECT * FROM PERSON WHERE ID=?\";PreparedStatement ps = conn.prepareStatement(selectPerson);ps.setInt(1,id); select 元素有很多属性允许你配置，来决定每条语句的作用细节。123456789101112&lt;select id=\"selectPerson\" parameterType=\"int\" parameterMap=\"deprecated\" resultType=\"hashmap\" resultMap=\"personResultMap\" flushCache=\"false\" useCache=\"true\" timeout=\"10000\" fetchSize=\"256\" statementType=\"PREPARED\" resultSetType=\"FORWARD_ONLY\"&gt; 属性 描述 id 在命名空间中唯一的标识符，可以被用来引用这条语句。 parameterType 将会传入这条语句的参数类的完全限定名或别名。这个属性是可选的，因为 MyBatis 可以通过 TypeHandler 推断出具体传入语句的参数，默认值为 unset。 parameterMap 这是引用外部 parameterMap 的已经被废弃的方法。使用内联参数映射和 parameterType 属性。 resultType 从这条语句中返回的期望类型的类的完全限定名或别名。注意如果是集合情形，那应该是集合可以包含的类型，而不能是集合本身。使用 resultType 或 resultMap，但不能同时使用。 resultMap 外部 resultMap 的命名引用。结果集的映射是 MyBatis 最强大的特性，对其有一个很好的理解的话，许多复杂映射的情形都能迎刃而解。使用 resultMap 或 resultType，但不能同时使用。 flushCache 将其设置为 true，任何时候只要语句被调用，都会导致一级缓存和二级缓存都会被清空，默认值：false。 useCache 将其设置为 true，将会导致本条语句的结果被二级缓存，默认值：对 select 元素为 true。 timeout 这个设置是在抛出异常之前，驱动程序等待数据库返回请求结果的秒数。默认值为 unset（依赖驱动）。 fetchSize 这是尝试影响驱动程序每次批量返回的结果行数和这个设置值相等。默认值为 unset（依赖驱动）。 statementType STATEMENT，PREPARED 或 CALLABLE 的一个。这会让 MyBatis 分别使用 Statement，PreparedStatement 或 CallableStatement，默认值：PREPARED。 resultSetType FORWARD_ONLY，SCROLL_SENSITIVE 或 SCROLL_INSENSITIVE 中的一个，默认值为 unset （依赖驱动）。 databaseId 如果配置了 databaseIdProvider，MyBatis 会加载所有的不带 databaseId 或匹配当前 databaseId 的语句；如果带或者不带的语句都有，则不带的会被忽略。 resultOrdered 这个设置仅针对嵌套结果 select 语句适用：如果为 true，就是假设包含了嵌套结果集或是分组了，这样的话当返回一个主结果行的时候，就不会发生有对前面结果集的引用的情况。这就使得在获取嵌套的结果集的时候不至于导致内存不够用。默认值：false。 resultSets 这个设置仅对多结果集的情况适用，它将列出语句执行后返回的结果集并每个结果集给一个名称，名称是逗号分隔的。 insert, update 和 delete 数据变更语句 insert，update 和 delete 的实现非常接近：123456789101112131415161718192021222324&lt;insert id=\"insertAuthor\" parameterType=\"domain.blog.Author\" flushCache=\"true\" statementType=\"PREPARED\" keyProperty=\"\" keyColumn=\"\" useGeneratedKeys=\"\" timeout=\"20\"&gt;&lt;update id=\"updateAuthor\" parameterType=\"domain.blog.Author\" flushCache=\"true\" statementType=\"PREPARED\" timeout=\"20\"&gt;&lt;delete id=\"deleteAuthor\" parameterType=\"domain.blog.Author\" flushCache=\"true\" statementType=\"PREPARED\" timeout=\"20\"&gt; 属性 描述 id 命名空间中的唯一标识符，可被用来代表这条语句。 parameterType 将要传入语句的参数的完全限定类名或别名。这个属性是可选的，因为 MyBatis 可以通过 TypeHandler 推断出具体传入语句的参数，默认值为 unset。 parameterMap 这是引用外部 parameterMap 的已经被废弃的方法。使用内联参数映射和 parameterType 属性。 flushCache 将其设置为 true，任何时候只要语句被调用，都会导致本地缓存和二级缓存都会被清空，默认值：true（对应插入、更新和删除语句）。 timeout 这个设置是在抛出异常之前，驱动程序等待数据库返回请求结果的秒数。默认值为 unset（依赖驱动）。 statementType STATEMENT，PREPARED 或 CALLABLE 的一个。这会让 MyBatis 分别使用 Statement，PreparedStatement 或 CallableStatement，默认值：PREPARED。 useGeneratedKeys （仅对 insert 和 update 有用）这会令 MyBatis 使用 JDBC 的 getGeneratedKeys 方法来取出由数据库内部生成的主键（比如：像 MySQL 和 SQL Server 这样的关系数据库管理系统的自动递增字段），默认值：false。 keyProperty （仅对 insert 和 update 有用）唯一标记一个属性，MyBatis 会通过 getGeneratedKeys 的返回值或者通过 insert 语句的 selectKey 子元素设置它的键值，默认：unset。如果希望得到多个生成的列，也可以是逗号分隔的属性名称列表。 keyColumn （仅对 insert 和 update 有用）通过生成的键值设置表中的列名，这个设置仅在某些数据库（像 PostgreSQL）是必须的，当主键列不是表中的第一列的时候需要设置。如果希望得到多个生成的列，也可以是逗号分隔的属性名称列表。 databaseId 如果配置了 databaseIdProvider，MyBatis 会加载所有的不带 databaseId 或匹配当前 databaseId 的语句；如果带或者不带的语句都有，则不带的会被忽略。 sql 这个元素可以被用来定义可重用的 SQL 代码段，可以包含在其他语句中。它可以被静态地(在加载参数) 参数化. 不同的属性值通过包含的实例变化. 比如：1&lt;sql id=\"userColumns\"&gt; $&#123;alias&#125;.id,$&#123;alias&#125;.username,$&#123;alias&#125;.password &lt;/sql&gt; 这个 SQL 片段可以被包含在其他语句中，例如：1234567&lt;select id=\"selectUsers\" resultType=\"map\"&gt; select &lt;include refid=\"userColumns\"&gt;&lt;property name=\"alias\" value=\"t1\"/&gt;&lt;/include&gt;, &lt;include refid=\"userColumns\"&gt;&lt;property name=\"alias\" value=\"t2\"/&gt;&lt;/include&gt; from some_table t1 cross join some_table t2&lt;/select&gt; 属性值也可以被用在 include 元素的 refid 属性里（）或 include 内部语句中（${prefix}Table），例如：1234567891011121314151617&lt;sql id=\"sometable\"&gt; $&#123;prefix&#125;Table&lt;/sql&gt;&lt;sql id=\"someinclude\"&gt; from &lt;include refid=\"$&#123;include_target&#125;\"/&gt;&lt;/sql&gt;&lt;select id=\"select\" resultType=\"map\"&gt; select field1, field2, field3 &lt;include refid=\"someinclude\"&gt; &lt;property name=\"prefix\" value=\"Some\"/&gt; &lt;property name=\"include_target\" value=\"sometable\"/&gt; &lt;/include&gt;&lt;/select&gt; resultMap 结果集映射是mybatis最复杂的部分，mybatis为我们做了很多的工作,给出一个复杂的例子:123456789101112131415161718192021222324252627282930313233343536373839 public class Author&#123; private Integer id; private String name; //getter and setter &#125; public class Comment&#123; private Integer id; private String content; //getter and setter &#125; public class Blog&#123; private Integer id; private Author author; private List&lt;Comment&gt; commentList; private String title; //getter and setter &#125;``` ```xml &lt;resultMap id=\"detailedBlogResultMap\" type=\"Blog\"&gt; &lt;id property=\"id\" column=\"id\"/&gt; &lt;constructor&gt; &lt;idArg column=\"blog_id\" javaType=\"int\"/&gt; &lt;/constructor&gt; &lt;result property=\"title\" column=\"blog_title\"/&gt; &lt;association property=\"author\" javaType=\"Author\"&gt; &lt;id property=\"id\" column=\"author_id\"/&gt;&gt; &lt;result property=\"name\" column=\"author_name\"/&gt; &lt;/association&gt; &lt;collection property=\"commentList\" ofType=\"Comment\"&gt; &lt;id property=\"id\" column=\"comment_id\"/&gt; &lt;result property=\"content\" column=\"content\"/&gt; &lt;/collection&gt; &lt;discriminator javaype=\"int\" column=\"type\" &gt; &lt;case value=\"\" resultType=\"\"/&gt; &lt;/discriminator&gt; &lt;/resultMap&gt; resultMap constructor - 用于在实例化类时，注入结果到构造方法中 idArg - ID 参数;标记出作为 ID 的结果可以帮助提高整体性能 arg - 将被注入到构造方法的一个普通结果 id – 一个 ID 结果;标记出作为 ID 的结果可以帮助提高整体性能 result – 注入到字段或 JavaBean 属性的普通结果 association – 一个复杂类型的关联;许多结果将包装成这种类型嵌套结果映射 – 关联可以指定为一个 resultMap 元素，或者引用一个 collection – 一个复杂类型的集合嵌套结果映射 – 集合可以指定为一个 resultMap 元素，或者引用一个 discriminator – 使用结果值来决定使用哪个 resultMap case – 基于某些值的结果映射嵌套结果映射,一个 case 也是一个映射它本身的结果,因此可以包含很多相 同的元素，或者它可以参照一个外部的 resultMap。 动态sql#{}和${}区别 有时候我们会在xml的sql中使用到这两者但是这两者有什么区别呢？#{}: 属于动态参数，会进行预编译，而且进行类型匹配，用于变量替换 ${}: 不会进行类型匹配，用于字符串拼接举个例子：123456&lt;select id=\"findByName1\"&gt; select * from user where name=#&#123;params.name&#125;&lt;/select&gt;&lt;select id=\"findByName2\"&gt; select * from user where id=$&#123;parms.name&#125;&lt;/select&gt; 上面2个sql最终的结果都为：select * from user where name = &#39;zhangsan&#39; &#39;,但是findByName1中的参数会进行预编译参数替换为?,防止sql注入；而findByName2只是简单的字符串替换，使用时应当注意sql注入的问题,但是使用order by或者将表名作为参数传递进来是只能使用${}. 动态表达式 MyBatis 采用功能强大的基于 OGNL 的表达式来提供了动态sql的功能，主要包含: if choose(when, otherwise) trim (where, set) foreach if1234567&lt;select id=\"findUserList\"&gt; select * from user where state=0 &lt;if test=\"path != null\"&gt; and path=#&#123;param.path&#125; &lt;/if&gt; &lt;/select&gt; 这句话意味着，当传入的参数中path存在则筛选条件追加path字段，反之则忽略。 choose 有时我们不想应用到所有的条件语句，而只想从中择其一项。针对这种情况，MyBatis 提供了 choose 元素，它有点像 Java 中的 switch 语句。123456789101112&lt;select id=\"findUserList\"&gt; select * from user where name=#&#123;name&#125; &lt;choose&gt; &lt;when test=\"state != null and state != 0\"&gt; state = #&#123;state&#125; &lt;/when&gt; &lt;otherwise&gt; state = 0 &lt;/otherwise&gt; &lt;/choose&gt;&lt;/select&gt; 上面的sql意味着，假如存在state字段，则查询参数拼接该字段，否则拼接为默认的参数值。 trim(where)123456789101112131415&lt;select id=\"findActiveBlogLike\" resultType=\"Blog\"&gt; SELECT * FROM BLOG &lt;where&gt; &lt;if test=\"state != null\"&gt; state = #&#123;state&#125; &lt;/if&gt; &lt;if test=\"title != null\"&gt; AND title like #&#123;title&#125; &lt;/if&gt; &lt;if test=\"author != null and author.name != null\"&gt; AND author_name like #&#123;author.name&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; where 元素只会在至少有一个子元素的条件返回 SQL 子句的情况下才去插入“WHERE”子句。而且，若语句的开头为“AND”或“OR”，where 元素也会将它们去除。如果 where 元素没有按正常套路出牌，我们可以通过自定义 trim 元素来定制 where 元素的功能。比如，和 where 元素等价的自定义 trim 元素为：12345678 &lt;trim prefix=\"WHERE\" prefixOverrides=\"AND |OR \"&gt; ... &lt;/trim&gt;``` &gt; prefixOverrides 属性会忽略通过管道分隔的文本序列（注意此例中的空格也是必要的）。它的作用是移除所有指定在 prefixOverrides 属性中的内容，并且插入 prefix 属性中指定的内容。 ##### foreach &gt; 动态 SQL 的另外一个常用的操作需求是对一个集合进行遍历，通常是在构建 IN 条件语句的时候。比如： SELECT * FROM POST P WHERE ID in #{item} &lt;/foreach&gt; ` foreach 中的collection取值可以为(list,array,map)","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://cnkeep.github.io/tags/Mybatis/"}]},{"title":"Keepalived安装配置","date":"2018-07-03T12:51:00.000Z","path":"2018/07/03/01-Keepalived安装配置/","text":"Keepalived安装与配置 标签：Centos, Keepalived 1. 介绍Keepalived是一个免费的开源的交换机制软件，主要提供Load Balancing(负载均衡)和HA(高可用)我们一般采用Keepalived+Nginx分别来实现前端的高可用和负载均衡。它提供虚拟IP对外服务，可以自动完成主备的切换，服务可以在客户端无感知的情况下完成主备的切换，从而持续的为我们客户提供服务。 本次就来看看如何配置Keepalived 2. 安装与配置从官网下载最先版本，这里以keepalived-2.0.13为例。 2.1 安装123456# cd /usr/local# wget http://www.keepalived.org/software/keepalived-2.0.13.tar.gz# tar -zxvf keepalived-2.0.13.tar.gz# cd keepalived-2.0.13/# ./configure --prefix=/usr/local/keepalived# make &amp;&amp; make install 2.2 配置 将配置文件拷贝到系统对应的目录下1234# mkdir /etc/keepalived# cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf# cp /usr/local/keepalived-2.0.13/keepalived/etc/init.d/keepalived /etc/rc.d/init.d/keepalived# cp /usr/local/keepalived-2.0.13/keepalived/etc/sysconfig/keepalived /etc/sysconfig/keepalived 使用service keepalived start命令启动服务时，默认会将/etc/sysconfig/keepalived文件中KEEPALIVED_OPTIONS参数作为keepalived服务启动时的参数，并从/etc/keepalived/目录下加载keepalived.conf配置文件，或用-f参数指定配置文件的位置。 123456789101112131415[root@localhost local]# vi /etc/sysconfig/keepalived # Options for keepalived. See `keepalived --help&apos; output and keepalived(8) and# keepalived.conf(5) man pages for a list of all options. Here are the most# common ones :## --vrrp -P Only run with VRRP subsystem.# --check -C Only run with Health-checker subsystem.# --dont-release-vrrp -V Dont remove VRRP VIPs &amp; VROUTEs on daemon stop.# --dont-release-ipvs -I Dont remove IPVS topology on daemon stop.# --dump-conf -d Dump the configuration data.# --log-detail -D Detailed log messages.# --log-facility -S 0-7 Set local syslog facility (default=LOG_DAEMON)KEEPALIVED_OPTIONS=&quot;-D&quot; 设置keepalived开机启动123456# chkconfig keepalived on #设置开机自启# chkconfig keepalived off #取消开机自启# service keepalived start #启动服务# service keepalived stop #停止服务# ln -s /usr/local/keepalived/sbin/keepalived /usr/local/sbin/ #建立软连接方便操作 keepalived正常运行后，会启动3个进程，其中一个是父进程，负责监控其子进程。一个是vrrp子进程，另外一个是checkers子进程。12345[root@localhost local]# ps -ef|grep keepalivedroot 24726 1 0 21:54 ? 00:00:00 /usr/local/keepalived/sbin/keepalived -Droot 24727 24726 0 21:54 ? 00:00:00 /usr/local/keepalived/sbin/keepalived -Droot 24728 24726 0 21:54 ? 00:00:00 /usr/local/keepalived/sbin/keepalived -Droot 24873 6495 0 22:36 pts/1 00:00:00 grep --color=auto keepalived 到此keepalived就安装完成了。 3. keepalived.conf配置文件说明keepalived服务安装完成之后，后面的主要工作就是在keepalived.conf文件中配置HA和负载均衡。一个功能比较完整的常用的keepalived配置文件，主要包含三块：全局定义块，VRRP实例定义块和虚拟服务器定义块。全局定义块是必须的，如果keepalived只用来做ha，虚拟服务器是可选的。下面是一个功能比较完整的配置文件模板：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#全局定义块 global_defs &#123; # 邮件通知配置 notification_email &#123; email1 email2 &#125; notification_email_from email smtp_server host smtp_connect_timeout num #vrrp_strict #记得注释掉此行 lvs_id string router_id string ## 标识本节点的字条串,通常为hostname &#125; #VRRP 实例定义块 vrrp_sync_group string &#123; group &#123; string string &#125; &#125; vrrp_instance string &#123; state MASTER|BACKUP #只能存在一个MASTER, 其余的都是设置WieBACKUP virtual_router_id num #备机和主机需保持一致 interface string #绑定网卡名称 mcast_src_ip @IP #广播地址 priority num #保证master此值最大即可 advert_int num nopreempt smtp_alert lvs_sync_daemon_interface string authentication &#123; auth_type PASS|AH auth_pass string &#125; virtual_ipaddress &#123; # Block limited to 20 IP addresses @IP #虚拟ip @IP @IP &#125; &#125; #虚拟服务器定义块 virtual_server (@IP PORT)|(fwmark num) &#123; delay_loop num lb_algo rr|wrr|lc|wlc|sh|dh|lblc lb_kind NAT|DR|TUN persistence_timeout num protocol TCP|UDP real_server @IP PORT &#123; weight num notify_down /path/script.sh TCP_CHECK &#123; connect_port num connect_timeout num &#125; &#125; real_server @IP PORT &#123; weight num MISC_CHECK &#123; misc_path /path_to_script/script.sh(or misc_path “/path_to_script/script.sh &lt;arg_list&gt;”) &#125; &#125; real_server @IP PORT &#123; weight num HTTP_GET|SSL_GET &#123; url &#123; # You can add multiple url block path alphanum digest alphanum &#125; connect_port num connect_timeout num nb_get_retry num delay_before_retry num &#125; &#125; &#125; 3.1 全局定义块1、email通知（notification_email、smtp_server、smtp_connect_timeout）：用于服务有故障时发送邮件报警，可选项，不建议用。需要系统开启sendmail服务，建议用第三独立监控服务，如用nagios全面监控代替。 2、lvs_id：lvs负载均衡器标识，在一个网络内，它的值应该是唯一的。 3、router_id：用户标识本节点的名称，通常为hostname 4、花括号｛｝：用来分隔定义块，必须成对出现。如果写漏了，keepalived运行时不会得到预期的结果。由于定义块存在嵌套关系，因此很容易遗漏结尾处的花括号，这点需要特别注意 3.2 VRRP实例定义块（HA）1.vrrp_sync_group：同步vrrp级，用于确定失败切换（FailOver）包含的路由实例个数。即在有2个负载均衡器的场景，一旦某个负载均衡器失效，需要自动切换到另外一个负载均衡器的实例是哪 2.group：至少要包含一个vrrp实例，vrrp实例名称必须和vrrp_instance定义的一致 state：实例状态，只有MASTER 和 BACKUP两种状态，并且需要全部大写。抢占模式下，其中MASTER为工作状态，BACKUP为备用状态。当MASTER所在的服务器失效时，BACKUP所在的服务会自动把它的状态由BACKUP切换到MASTER状态。当失效的MASTER所在的服务恢复时，BACKUP从MASTER恢复到BACKUP状态. interface：对外提供服务的网卡接口，即VIP绑定的网卡接口。如：eth0，eth1。当前主流的服务器都有2个或2个以上的接口（分别对应外网和内网），在选择网卡接口时，一定要核实清楚。 mcast_src_ip: 本机广播IP地址 virtual_router_id：虚拟路由的ID号，每个节点设置必须一样，可选择IP最后一段使用，相同的 VRID 为一个组，他将决定多播的 MAC 地址。 priority: 节点优先级，取值范围0～254，MASTER要比BACKUP高 advert_int: MASTER与BACKUP节点间同步检查的时间间隔，单位为秒 lvs_sync_daemon_inteface: 负载均衡器之间的监控接口,类似于 HA HeartBeat 的心跳线。但它的机制优于 Heartbeat，因为它没有“裂脑”这个问题,它是以优先级这个机制来规避这个麻烦的。在 DR 模式中，lvs_sync_daemon_inteface与服务接口interface使用同一个网络接口. authentication: 验证类型和验证密码。类型主要有 PASS、AH 两种，通常使用PASS类型，据说AH使用时有问题。验证密码为明文，同一vrrp 实例MASTER与BACKUP使用相同的密码才能正常通信。 smtp_alert: 有故障时是否激活邮件通知 virtual_ipaddress: 虚拟IP地址池，可以有多个IP，每个IP占一行，不需要指定子网掩码。注意：这个IP必须与我们的设定的vip保持一致。配置之后我们只需要对外提供改地址即可，保证主机宕机后可以无感知的由从机提供服务。 3.3 虚拟服务器virtual_server定义块此模块主要用于负载均衡，这里不做过多介绍，因为一般都由nginx去做负载均衡了. virtual_server：定义一个虚拟服务器，这个ip是virtual_ipaddress中定义的其中一个，后面一个空格，然后加上虚拟服务的端口号。 delay_loop：健康检查时间间隔，单位：秒 lb_algo：负载均衡调度算法，互联网应用常用方式为wlc或rr lb_kind：负载均衡转发规则。包括DR、NAT、TUN 3种，一般使用路由（DR）转发规则。 persistence_timeout：http服务会话保持时间，单位：秒 protocol：转发协议，分为TCP和UDP两种 real_server：真实服务器IP和端口，可以定义多个 weight：负载权重，值越大，转发的优先级越高 notify_down：服务停止后执行的脚本 TCP_CHECK：服务有效性检测 1234* connect_port：服务连接端口* connect_timeout：服务连接超时时长，单位：秒* nb_get_retry：服务连接失败重试次数* delay_before_retry：重试连接间隔，单位：秒 4. 实战Keepalived+Nginx高可用接下来我们就上手搭建一套简单的高可用负载均衡服务 4.1 部署结构介绍先看看我们的部署结构：简单起见，我们采用4台虚拟机部署这套服务，省却web服务集群和数据库先关的部署，各个服务器服务部署情况如下： 服务器 说明 服务部署 172.16.22.135 作为主机实现后台Web服务的负载均衡 keepalive1, nginx1 172.16.22.136 作为备机实现后台Web服务的负载均衡 keepalive2, nginx2 172.16.22.137 Web服务集群(数据库单点，Session共享在Redis中) WebApplication01, WebApplication02 172.16.22.138 提供数据支撑服务(单点) Mysql, Redis 4.2 Nginx配置这套架构中，nginx主要提供一下三个服务能力: 静态Web服务器：提供静态资源的访问支持 反向代理：反向代理后台Web服务器，实现动态数据请求的转发 负载均衡：为后台Web集群提供负载均衡 nginx配置 2台机器配置相同内容 1234567891011121314151617181920212223242526272829303132333435363738394041424344# wwwroot.conf, 需要在nginx的主配置文件nginx.config中通过include引入# 负载均衡配置，配置web服务的地址upstream backend &#123; server 172.16.22.137:9001 weight=5; server 172.16.22.137:9002 weight=5;&#125;server &#123; listen 8080; server_name localhost; # 静态资源目录 set $root_path &quot;/home/zll/wwwroot&quot;; charset utf-8; access_log /home/zll/wwwlogs/host.access.log main; error_log /home/zll/wwwlogs/error.log; error_page 404 /404.html; # 静态资源服务配置 location / &#123; root $root_path; index index.html index.htm; &#125; # 配置后台转发规则，路径为service/*的将转发至web服务 location ~ ^/service/ &#123; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Cookie $http_cookie; proxy_cookie_path /service/ /; proxy_buffering off; proxy_connect_timeout 300s; proxy_send_timeout 300s; proxy_read_timeout 300s; # 反向代理 proxy_pass http://backend; &#125;&#125; 4.3 Keepalived配置 主机配置 12345678910111213141516171819202122232425262728293031[root@localhost sbin]# vi /etc/keepalived/keepalived.conf ! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr# vrrp_strict 注释掉这里 vrrp_garp_interval 0 vrrp_gna_interval 0&#125;vrrp_instance WWW-ROOT &#123; state MASTER interface eth1 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 172.16.22.140 #虚拟IP, 此地址为提供对外的地址，不真实存在 &#125;&#125; 从机配置12345678910111213141516171819202122232425262728293031[root@localhost sbin]# vi /etc/keepalived/keepalived.conf ! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr# vrrp_strict 注释掉这里 vrrp_garp_interval 0 vrrp_gna_interval 0&#125;vrrp_instance WWW-ROOT &#123; state BACKUP #从机配置设置为BACKUP interface eth1 virtual_router_id 51 priority 90 #配置权重小于主机 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 172.16.22.140 &#125;&#125; 从机配置只改变了添加注释的地方，其余与主机配置保持一致即可。 4.4 启动服务 启动web服务12345678910111213# cd /home/zll/web/9001/# sh start.sh start# cd /home/zll/web/9002/# sh start.sh start# jps -lv12977 com.github.cnkeep.WebApplication -XX:MaxPermSize=192M -Xms512M -Xmx512M -XX:+HeapDumpOnOutOfMemoryError12868 com.github.cnkeep.WebApplication -XX:MaxPermSize=192M -Xms512M -Xmx512M -XX:+HeapDumpOnOutOfMemoryError``` &gt; 启动nginx服务 ```text# nginx 启动keepalived服务1# systemctl start keepalived 访问验证 浏览器访问http://172.16.22.140/ 4.5 主备自动切换测试 Nginx主机正常服务时 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#查看主机网卡绑定，eth1网卡绑定这虚拟ip [root@localhost conf]# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:e3:fa:94 brd ff:ff:ff:ff:ff:ff inet 192.168.222.132/24 brd 192.168.222.255 scope global dynamic eth0 valid_lft 1163sec preferred_lft 1163sec inet6 fe80::20c:29ff:fee3:fa94/64 scope link valid_lft forever preferred_lft forever3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:e3:fa:9e brd ff:ff:ff:ff:ff:ff inet 172.16.22.135/24 brd 172.16.22.255 scope global dynamic eth1 valid_lft 2105911sec preferred_lft 2105911sec inet 172.16.22.140/32 scope global eth1 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fee3:fa9e/64 scope link valid_lft forever preferred_lft forever# 查看主机keepalive日志[root@localhost ~]# tail -f -n 100 /var/log/messages Mar 10 01:42:00 localhost Keepalived_vrrp[13487]: (VI_1) Receive advertisement timeout Mar 10 01:42:00 localhost Keepalived_vrrp[13487]: (VI_1) Entering MASTER STATE Mar 10 01:42:00 localhost Keepalived_vrrp[13487]: (VI_1) setting VIPs. Mar 10 01:42:00 localhost Keepalived_vrrp[13487]: Sending gratuitous ARP on eth1 for 172.16.22.140 Mar 10 01:42:00 localhost Keepalived_vrrp[13487]: (VI_1) Sending/queueing gratuitous ARPs on eth1 for 172.16.22.140 Mar 10 01:42:00 localhost Keepalived_vrrp[13487]: Sending gratuitous ARP on eth1 for 172.16.22.140 Mar 10 01:42:00 localhost Keepalived_vrrp[13487]: Sending gratuitous ARP on eth1 for 172.16.22.140 Mar 10 01:42:00 localhost Keepalived_vrrp[13487]: Sending gratuitous ARP on eth1 for 172.16.22.140 Mar 10 01:42:00 localhost Keepalived_vrrp[13487]: Sending gratuitous ARP on eth1 for 172.16.22.140 # 查看备机网卡绑定[root@localhost sbin]# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:49:97:b2 brd ff:ff:ff:ff:ff:ff inet 192.168.222.129/24 brd 192.168.222.255 scope global dynamic eth0 valid_lft 1246sec preferred_lft 1246sec inet6 fe80::20c:29ff:fe49:97b2/64 scope link valid_lft forever preferred_lft forever3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:49:97:bc brd ff:ff:ff:ff:ff:ff inet 172.16.22.136/24 brd 172.16.22.255 scope global dynamic eth1 valid_lft 2466625sec preferred_lft 2466625sec inet6 fe80::20c:29ff:fe49:97bc/64 scope link valid_lft forever preferred_lft forever # 查看备机keepalive日志[root@localhost ~]# tail -f -n 100 /var/log/messages Mar 10 01:42:00 localhost Keepalived_vrrp[24728]: (VI_1) Entering BACKUP STATEMar 10 01:42:00 localhost Keepalived_vrrp[24728]: (VI_1) removing VIPs.Mar 10 01:43:44 localhost dhclient[683]: DHCPREQUEST on eth0 to 192.168.222.254 port 67 (xid=0x4b95ebe1)Mar 10 01:43:45 localhost dhclient[683]: DHCPACK from 192.168.222.254 (xid=0x4b95ebe1)Mar 10 01:43:45 localhost NetworkManager[645]: &lt;info&gt; [1552153425.0060] dhcp4 (eth0): address 192.168.222.132Mar 10 01:43:45 localhost NetworkManager[645]: &lt;info&gt; [1552153425.0063] dhcp4 (eth0): plen 24 (255.255.255.0)Mar 10 01:43:45 localhost NetworkManager[645]: &lt;info&gt; [1552153425.0063] dhcp4 (eth0): gateway 192.168.222.2 Nginx主机宕机时(通过kill keepalived进程)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#查看主机网卡绑定，eth1网卡绑定这虚拟ip [root@localhost conf]# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:e3:fa:94 brd ff:ff:ff:ff:ff:ff inet 192.168.222.132/24 brd 192.168.222.255 scope global dynamic eth0 valid_lft 1163sec preferred_lft 1163sec inet6 fe80::20c:29ff:fee3:fa94/64 scope link valid_lft forever preferred_lft forever3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:e3:fa:9e brd ff:ff:ff:ff:ff:ff inet 172.16.22.135/24 brd 172.16.22.255 scope global dynamic eth1 valid_lft 2105911sec preferred_lft 2105911sec inet6 fe80::20c:29ff:fee3:fa9e/64 scope link valid_lft forever preferred_lft forever# 查看备机网卡绑定[root@localhost sbin]# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:49:97:b2 brd ff:ff:ff:ff:ff:ff inet 192.168.222.129/24 brd 192.168.222.255 scope global dynamic eth0 valid_lft 1246sec preferred_lft 1246sec inet6 fe80::20c:29ff:fe49:97b2/64 scope link valid_lft forever preferred_lft forever3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:49:97:bc brd ff:ff:ff:ff:ff:ff inet 172.16.22.136/24 brd 172.16.22.255 scope global dynamic eth1 valid_lft 2466625sec preferred_lft 2466625sec inet 172.16.22.140/32 scope global eth1 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe49:97bc/64 scope link valid_lft forever preferred_lft forever # 查看备机keepalive日志Mar 10 01:50:03 localhost Keepalived_vrrp[24728]: (VI_1) Backup received priority 0 advertisementMar 10 01:50:03 localhost Keepalived_vrrp[24728]: (VI_1) Receive advertisement timeoutMar 10 01:50:03 localhost Keepalived_vrrp[24728]: (VI_1) Entering MASTER STATEMar 10 01:50:03 localhost Keepalived_vrrp[24728]: (VI_1) setting VIPs.Mar 10 01:50:03 localhost Keepalived_vrrp[24728]: Sending gratuitous ARP on eth1 for 172.16.22.140Mar 10 01:50:03 localhost Keepalived_vrrp[24728]: (VI_1) Sending/queueing gratuitous ARPs on eth1 for 172.16.22.140 可以看到当主机宕机时，keepalived自动做了切换，将虚拟ip绑定到了备机上，而我们通过虚拟ip(172.16.22.140)访问服务未收到影响，实现了高可用的效果。 4.6 遗留问题在上面的测试过程中，我们是通过kill掉主机的keepalived进程来激活主备切换的，但是存在主Nginx进程挂掉，而keepalived存在的情况，这时就无法实现自动的主备切换了，所以我们要提供检测脚本，检测当nginx服务停止时，kill掉keepalived进程，从而激活主备切换。 编写检测脚本 在主nginx上需要编写nginx进程检测脚本（check_nginx.sh），判断nginx进程是否存在，如果nginx不存在尝试重启nginx，若无法启动，就将keepalived进程杀掉，check_nginx.sh内容如下：12345678910111213141516171819202122232425# yum install psmisc #安装killall支持# vi /etc/keepalived/check_nginx.sh #!/bin/sh ################################################################################# #=== 如果进程中没有nginx，尝试重启nginx进程，若还是没有，则将keepalived进程kill掉 ===# ################################################################################# ## 查看是否有nginx进程 把值赋给变量A A=`ps -C nginx --no-header |wc -l` ## 重启nginx进程 if [ $A -eq 0 ];then /usr/local/nginx/sbin/nginx ## 等待时间 sleep 2 ## 还是没有nginx进程 if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then ## 杀掉keepalived killall keepalived exit 1 else exit 0 fi else exit 0 fi 修改keepalived.conf配置 1234567891011121314151617181920212223242526272829303132333435363738394041[root@localhost sbin]# vi /etc/keepalived/keepalived.conf ! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr# vrrp_strict 注释掉这里 vrrp_garp_interval 0 vrrp_gna_interval 0&#125;# 定时监控配置vrrp_script check_nginx &#123; script &quot;/etc/keepalived/check_nginx.sh&quot; ##监控脚本 interval 2 ##时间间隔，2秒 weight -20 ##权重&#125; vrrp_instance WWW-ROOT &#123; state BACKUP #从机配置设置为BACKUP interface eth1 virtual_router_id 51 priority 90 #配置权重小于主机 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 172.16.22.140 &#125; track_script &#123; check_nginx #监控脚本 &#125;&#125; 重启keepalived即可","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"启停命令","date":"2018-06-25T14:33:00.000Z","path":"2018/06/25/04-启停命令/","text":"nginx启停命令前言前面几节简单的了解了nginx的使用，本节针对nginx的启停命令做一个总结介绍。 启停命令命令介绍12345678910111213格式: nginx [-?hvVtTq] [-s signal] [-c filename] [-p prefix] [-g directives]选项: -?,-h : 帮助信息 -v : 显示版本信息 -V : 显示版本信息，配置文件信息 -t : 测试配置文件的额正确性 -T : test configuration, dump it and exit -q : 在检测配置文件期间屏蔽非错误信息 -s signal : 给一个nginx主进程发送信号：stop（强制停止）, quit（优雅退出）, reopen（重启）, reload（重新加载配置文件） -p prefix : 设置前缀路径（默认是：/usr/share/nginx/） -c filename : 设置配置文件 (默认: conf/nginx.conf) -g directives : 设置配置文件外的全局指令 示例 测试配置文件是否正确 123456nginx -t -c conf/ngix.conf``` + 重新加载配置文件 ```textnginx -s reload -c conf/nginx.conf 优雅停止服务 1nginx -s quit","tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://cnkeep.github.io/tags/Nginx/"}]},{"title":"nginx_catelog","date":"2018-06-25T12:33:00.000Z","path":"2018/06/25/00-nginx_catelog/","text":"Tengine: taobao改进的高性能Nginx","tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://cnkeep.github.io/tags/Nginx/"}]},{"title":"设置开机启动项","date":"2018-06-24T13:44:00.000Z","path":"2018/06/24/02-设置开机启动项/","text":"设置开机启动项要是想让nginx开机自启我们就需要进行相关配置了，通过yum安装的无需配置，只需要设置systemctl enable nginx即可，本次我们讨论的是通过压缩包安装的方式实现开机自启的方法。 编写nginx.service脚本 1234567891011121314151617$ vi /user/lib/systemc/system/nginx.service[Unit]Description=Nginx ServiceAfter=network.target[Service]#后台形式运行Type=forking#nginx安装绝对路径ExecStart=/usr/local/nginx/sbin/nginxExecStop=/usr/local/nginx/sbin/nginx -s stop#分配独立的临时空间PrivateTmp=true[Install]WantedBy=multi-user.target 2.建立软连接，映射到启动项目录1234567$ ln -s /usr/lib/systemd/system/nginx.service /etc/systemd/system/multi-user.target.wants/nginx.service ``` &gt; 3.系统配置刷新，开启启动项 ```text$ systemctl daemon-reload$ systemctl [start|stop|status] nginx","tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://cnkeep.github.io/tags/Nginx/"}]},{"title":"Nginx反向代理配置","date":"2018-06-24T12:29:00.000Z","path":"2018/06/24/07-Nginx反向代理配置/","text":"Nginx反向代理服务配置 标签：nginx, 反向代理 前言Nginx作为高性能的HTTP服务器和代理服务器，经常在我们的系统中扮演者反向代理服务器的作用，本节我们来学习一下，如何配置反向代理服务器。 反向代理配置Nginx反向代理配置需要依赖ngx_http_proxy_module模块 反向代理配置 示例配置12345678910111213141516171819202122232425262728293031323334353637#配置一个反向代理server节点server &#123; #监听端口 listen 5100; #域名配置 server_name localhost; set $root_path &quot;/home/html&quot;; location / &#123; root $root_path; index index.html index.htm; &#125; # 配置一个反向代理转发规则 location ~ ^/service/ &#123; #设置一些请求头信息，便于后台获取请求地址 proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Cookie $http_cookie; proxy_cookie_path /service/ /; #关闭缓存代理服务器 proxy_buffering off; #超时设置 proxy_connect_timeout 300s; proxy_send_timeout 300s; proxy_read_timeout 300s; #文件上传最大500M client_max_body_size 500m; # 反向代理的后台服务器 proxy_pass http://127.0.0.1:9000; &#125;&#125; ###","tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://cnkeep.github.io/tags/Nginx/"}]},{"title":"隐藏版本号","date":"2018-06-24T11:49:00.000Z","path":"2018/06/24/03-隐藏版本号/","text":"隐藏Nginx的版本号介绍处于安全考虑，在系统中的Nginx需要隐藏其自身的版本号，防止被不法分子获取后进行攻击。本次我们就来了解下如何隐藏版本号。 操作12345678# vi /usr/local/nginx/conf/nginx.conf# 在http模块配置中增加server_tokens off;即可http &#123; #隐藏nginx版本信息 server_tokens off;&#125;# nginx -s reload 重载配置后，访问原有页面就发现版本号隐藏了。","tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://cnkeep.github.io/tags/Nginx/"}]},{"title":"安装nginx","date":"2018-06-23T15:36:00.000Z","path":"2018/06/23/01-安装nginx/","text":"Nginx是一款轻量级的网页服务器、反向代理服务器。相较于Apache、lighttpd具有占有内存少，稳定性高等优势。它最常的用途是提供反向代理服务。 在Centos下，yum源不提供nginx的安装，可以通过切换yum源的方法获取安装。目前很多像centos7系统已经自带这几个库，所以安装前可以先查看一下本地是否已经存在。存在可直接跳至第四步骤。需要使用安装包编译安装的，如下。以下命令均需root权限执行：首先安装必要的库（nginx 中gzip模块需要 zlib 库，rewrite模块需要 pcre 库，ssl 功能需要openssl库）。选定/usr/local为安装目录，以下具体版本号根据实际改变。 1.安装依赖库12# cd /usr/local/# yum -y install make gcc gcc-c++ zlib zlib-devel openssl openssl-devel pcre pcre-devel 2.安装nginx1234567# cd /usr/local/# sudo tar -zxvf nginx-1.8.0.tar.gz# cd nginx-1.8.0 # sudo ./configure --prefix=/usr/local/nginx #prefix指明安装位置,如果是使用安装包编译的上面几个依赖，需要在在--prefix后面接以下命令:--with-pcre=**** --with-zlib。# sudo make# sudo make install# sudo ln -s /usr/local/nginx/sbin/* /usr/local/sbin 设置软连接，使得可以再任意路径执行nginx命令 3.启动先测试一下配置文件是否正确：12345678910111213141516# /usr/local/nginx/sbin/nginx -t无问题可以启动：# /usr/local/nginx/sbin/nginx检查是否启动成功：打开浏览器访问此机器的 IP，如果浏览器出现 Welcome to nginx! 则表示 Nginx 已经安装并运行成功。部分命令如下：重启：# /usr/local/nginx/sbin/nginx –s reload停止：# /usr/local/nginx/sbin/nginx –s stop测试配置文件是否正常：# /usr/local/nginx/sbin/nginx –t强制关闭：# pkill nginx配置 以上安装方法nginx的配置文件位于123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051## 4.简单的示例 ```text server &#123; listen 5100; server_name localhost; set $root_path &quot;/home/wwwroot&quot;; #charset koi8-r; access_log /home/wwwlogs/host.access.log main; error_log /home/wwwlogs/error.log; location / &#123; root $root_path; index index.html index.htm; &#125; # proxy the Java scripts to JDK listening on 127.0.0.1:9000 location ~ ^/service/ &#123; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Cookie $http_cookie; proxy_cookie_path /service/ /; proxy_buffering off; proxy_connect_timeout 300s; proxy_send_timeout 300s; proxy_read_timeout 300s; proxy_pass http://127.0.0.1:9000; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /usr/share/nginx/html; &#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125;","tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://cnkeep.github.io/tags/Nginx/"}]},{"title":"nginx进程模型","date":"2018-06-23T13:36:00.000Z","path":"2018/06/23/05-nginx进程模型/","text":"nginx进程模型 标签：Nginx 前言Nginx作为一个高性能的网页服务器和代理服务器，其高性能与其架构设计密不可分，其主要体现在两个方面： 异步非阻塞的事件处理模型 多进程单线程的进程模型 本节就来分析一下Nginx的进程模型。 进程模型进程模型介绍Nginx分为单进程和多进程模式，单进程模式常常在开发环境调试使用，生产环境nginx以多进程方式工作对外提供服务。 多进程模式下，系统分为一个master进程和多个work进程(通过查看后台进程即可发现)： master进程负责信号的处理和work进程的管理，包括接收外界信号，向worker进程发送信号，监控work进程的运行状态，不直接对外提供Web服务。 work进程work进程对外提供Web服务，各个work进程之间相互隔离且相互平等，work进程的数目可以在配置文件中配置。 其进程模型如下如所示： 如何处理请求？ 上面提到多个work进程之间平等且相互独立的，对于每个请求的处理机会也是平等的，那么当我们请求时，它又是如何选择处理的呢？ 在master进程中，首先需要建立好监听端口，然后再fork出多个work进程。这样多个进程就可以同时监听同一个IP地址和端口。一般来说，当一个连接进来后，所有的监听进程都会收到通知，但是只有一个进程可以成功建立连接，其他的进程都会失败，这就是所谓的惊群现象。当然Nginx针对这一点做了优化，其提供了一把互斥锁accept_mutex, 每个监听进程在申请处理请求前，先去申请锁，申请成功就完成连接建立，处理请求，否则继续睡眠。","tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://cnkeep.github.io/tags/Nginx/"}]},{"title":"Nginx负载均衡配置","date":"2018-06-23T12:57:00.000Z","path":"2018/06/23/06-Nginx负载均衡配置/","text":"Nginx负载均衡配置 标签：Nginx, 负载均衡 前言Nginx在实际应用做经常作为我们系统的对外访问入口，提供后台服务的反向代理，但是往往后台的服务不会只部署一台，都是集群多态部署的，为了避免请求都打到同一台服务上，导致服务挂掉，这时候就需要nginx提供给我们的负载均衡功能，让我们的请求均衡的打到不同的机器上，从而分摊压力，保证服务可用，原理如下图所示： 负载均衡依赖模块Nginx的负载均衡模块依赖于ngx_http_upstream_module模块。 负载均衡策略本次我们就常见的几种负载均衡策略做介绍 轮询轮询策略是最基本的配置方法，其按照服务列表依次选择下一台提供服务的应用。它是upstream模块默认的负载均衡策略，每个请求都会按照时间顺序注意分配到不同的后端服务器。 参数 参数名 说明 fail_timeout 与max_fails结合使用 max_fails 设置在fail_timeout参数设置的时间内最大的失败次数，如果在这个时间内，所有针对该服务器的请求都失败了，那么任务该服务器停机了 backup 标记该服务器为备用服务器，当列表中的主服务器都停机时，请求会被转发到这里 down 标记服务器永久停机了 特点 缺省配置就是轮询策略； 在轮询过程中，如果服务器down掉了，会被自动剔除； 此策略适用于各个后台服务器配置相当，无状态的服务； 示例123456789101112131415#配置后台服务的ip端口列表upstream polling_load_servers &#123; server backend1.example.com; server backend2.example.com:8080; #这里配置一个备机，普通情况下请求不会转发给备机，只有当其他后台服务器down后才会转发给备机 server backup2.example.com:8080 backup;&#125;server &#123; location / &#123; # 配置请求按照负载均衡列表转发 proxy_pass http://polling_load_servers; &#125;&#125; 权重权重策略类似于优先级的概念，请求会优先转发到权重大的后台服务器上。 特点 每个后台服务需指定权重(weight),按照权重大小优先选择处理请求的后台服务器; 适用于服务器处理能力不同的情景，处理能力强的分配大的权重，处理能力弱的分配较小的权重; 示例1234567891011121314151617181920212223242526272829303132333435363738394041#配置后台服务的ip端口列表upstream weight_load_servers &#123; server backend1.example.com weight 8; server backend2.example.com:8080 weight 2; #这里配置一个备机，普通情况下请求不会转发给备机，只有当其他后台服务器down后才会转发给备机 server backup2.example.com:8080 backup;&#125;server &#123; location / &#123; # 配置请求按照负载均衡列表转发 proxy_pass http://weight_load_servers; &#125;&#125;``` #### ip_hash指定负载均衡器按照基于客户端IP的分配方式，这个方法确保了相同的客户端的请求一直发送到相同的服务器，以保证session会话。这样每个访客都固定访问一个后端服务器，可以解决session不能跨服务器的问题。 &gt; 特点 + 在nginx版本1.3.1之前，不能在ip_hash中使用权重（weight）。 + ip_hash不能与backup同时使用。 + 此策略适合有状态服务，比如session。 + 当有服务器需要剔除，必须手动down掉。 &gt; 示例 ```text#配置后台服务的ip端口列表upstream ip_hash_load_servers &#123; ip_hash; server backend1.example.com ; server backend2.example.com:8080;&#125;server &#123; location / &#123; # 配置请求按照负载均衡列表转发 proxy_pass http://weight_load_servers; &#125;&#125; least_conn把请求转发给连接数较少的后端服务器。轮询算法是把请求平均的转发给各个后端，使它们的负载大致相同；但是，有些请求占用的时间很长，会导致其所在的后端负载较高。这种情况下，least_conn这种方式就可以达到更好的负载均衡效果。 特点 适用于请求时间长短不一造成的服务器过载的情况 示例12345678910111213#配置后台服务的ip端口列表upstream least_conn_load_servers &#123; least_conn; server backend1.example.com ; server backend2.example.com:8080;&#125;server &#123; location / &#123; # 配置请求按照负载均衡列表转发 proxy_pass http://least_conn_load_servers; &#125;&#125; 第三方策略第三方的负载均衡策略的实现需要安装第三方插件。 fair按照服务器端的响应时间来分配请求，响应时间短的优先分配。 12345678910111213#配置后台服务的ip端口列表upstream fair_load_servers &#123; fair; server backend1.example.com ; server backend2.example.com:8080;&#125;server &#123; location / &#123; # 配置请求按照负载均衡列表转发 proxy_pass http://fair_load_servers; &#125;&#125; url_hash按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，要配合缓存命中来使用。 12345678910111213#配置后台服务的ip端口列表upstream url_hash_load_servers &#123; hash $&#123;request_uri&#125;; server backend1.example.com ; server backend2.example.com:8080;&#125;server &#123; location / &#123; # 配置请求按照负载均衡列表转发 proxy_pass http://url_hash_load_servers; &#125;&#125;","tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://cnkeep.github.io/tags/Nginx/"}]},{"title":"参数传递","date":"2018-06-02T17:22:00.000Z","path":"2018/06/03/03-参数传递/","text":"Shell参数传递 转载：菜鸟教程 我们可以在执行 Shell 脚本或者函数时，向脚本传递参数，脚本内获取参数的格式为：$n。n 代表一个数字，1 为执行脚本的第一个参数，2 为执行脚本的第二个参数，以此类推…… 实例 以下实例我们向脚本传递三个参数，并分别输出，其中 $0 为执行的文件名： 123456789101112131415161718192021#!/bin/bash# author:菜鸟教程# url:www.runoob.comecho &quot;Shell 传递参数实例！&quot;;echo &quot;执行的文件名：$0&quot;;echo &quot;第一个参数为：$1&quot;;echo &quot;第二个参数为：$2&quot;;echo &quot;第三个参数为：$3&quot;;``` 为脚本设置可执行权限，并执行脚本，输出结果如下所示 ```text$ chmod +x test.sh $ ./test.sh 1 2 3Shell 传递参数实例！执行的文件名：./test.sh第一个参数为：1第二个参数为：2第三个参数为：3 说明： $0 : 执行的脚本名 $下标：第几个下标的参数，下标从1开始 $#:参数的个数 $@:返回所有参数 $*:返回所有参数 $?:函数返回值 $* 与 $@ 区别： 相同点：都是引用所有参数。 不同点：只有在双引号中体现出来。假设在脚本运行时写了三个参数 1、2、3，，则 “ * “ 等价于 “1 2 3”（传递了一个参数），而 “@” 等价于 “1” “2” “3”（传递了三个参数）。 1234567891011121314151617181920212223#!/bin/bash# author:菜鸟教程# url:www.runoob.comecho &quot;-- \\$* 演示 ---&quot;for i in &quot;$*&quot;; do echo $idoneecho &quot;-- \\$@ 演示 ---&quot;for i in &quot;$@&quot;; do echo $idone#output:# $ chmod +x test.sh # $ ./test.sh 1 2 3# -- $* 演示 ---# 1 2 3# -- $@ 演示 ---# 1# 2# 3 实例数组元素求和123456789101112131415161718192021#!/bin/bashsum()&#123; _sum=0 for e in $@; do # 双括号代表数值计算 _sum=$(($&#123;_sum&#125;+$&#123;e&#125;)) done return $((_sum))&#125;read -p &quot;键盘输入数组元素，采用空格分隔: &quot; arrsum $arr #调用函数echo $? #获取函数返回结果#output:# [root@localhost conf]# sh arr.sh # 键盘输入数组元素，采用空格分隔: 2 1 4# 2 1 4# 7","tags":[{"name":"Shell","slug":"Shell","permalink":"https://cnkeep.github.io/tags/Shell/"}]},{"title":"认识shell","date":"2018-06-02T14:30:00.000Z","path":"2018/06/02/01-认识shell/","text":"认识shell什么是shell&emsp;&emsp;Shell是一个用C语言编写的程序，它是用户使用Linux的桥梁。我们经常说的是shell脚本，它是shell编写的脚本程序，我们可以通过脚本编写各种命令集合和控制我们的程序和系统。 Shell环境&emsp;&emsp;Linux上shell种类繁多，我们常见的有： Bourne Shell（/usr/bin/sh或/bin/sh） Bourne Again Shell（/bin/bash） C Shell（/usr/bin/csh） K Shell（/usr/bin/ksh） Shell for Root（/sbin/sh）….. 一般情况下我们并不区分人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，像 #!/bin/sh，它同样也可以改为 #!/bin/bash。#! 告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 程序。 编写并运行一个shell脚本123456789101112$ vi hello.sh#!/bin/shecho &quot;hello world!&quot;:wq#执行方式1$ sh hello.shhello world!#执行方式2$ chmod +x hello.shhello world! `","tags":[{"name":"Shell","slug":"Shell","permalink":"https://cnkeep.github.io/tags/Shell/"}]},{"title":"变量_数组","date":"2018-06-01T15:18:00.000Z","path":"2018/06/01/02-变量_数组/","text":"Shell数组shell只支持一维数组，并且没有限定数组的大小，类似于java，数组元素的下标从0开始。 定义数组(数组名=(值1 值2 ... 值n))123#!/bin/basharr=(a b c d) 数组元素使用空格分隔 读取元素(${数组名[下标]})1234567891011121314151617181920212223242526272829303132333435#!/bin/basharr=(a b c d)echo $&#123;arr[@]&#125; #获取所有元素echo $&#123;#arr[@]&#125; #获取数组长度echo $&#123;arr[0]&#125; #获取第一位元素#output:# a b c d# 4# a``` * 获取数组所哟元素: ``$&#123;数组名[@]&#125;``* 获取数组长度：``$&#123;#数组名[@]&#125;``* 获取 数组指定下标元素：``$&#123;数组名[下标]&#125;`` &gt; 遍历数组 ```text#!/bin/bashread -p &apos;键盘输入数组元素，元素之间使用空格分隔: &apos; arr #foreach遍历for e in $&#123;arr&#125;;do echo &quot;$&#123;e&#125;&quot;done#output:# 键盘输入数组元素，元素之间使用空格分隔: 1 2 3 4# 1# 2# 3# 4","tags":[{"name":"Shell","slug":"Shell","permalink":"https://cnkeep.github.io/tags/Shell/"}]},{"title":"变量_字符串","date":"2018-06-01T13:05:00.000Z","path":"2018/06/01/02-变量_字符串/","text":"Shell中的变量 参考:http://www.runoob.com/linux/linux-shell-variable.html 介绍无论什么语言，我们在编写时都会使用到各式各样的变量，本节我们就来学习一下Shell中变量的使用. 变量 定义变量，变量名不加$, 例如： 123#!/bin/bashpath=&quot;/home/zll&quot; 使用变量时添加$,例如： 12345678910111213#!/bin/bashpath=&quot;/home/zll&quot;echo $&#123;path&#125;echo $pathecho &quot;path=$&#123;path&#125;&quot;echo &apos;path=$&#123;path&#125;&apos;# output:# /home/zll# /home/zll# path=/home/zll# path=$&#123;path&#125; 变量外面的花括号是可选的，加不加都行，加花括号是为了方便识别变量的边界，建议加上，避免出错! 只读变量，通过添加readonly指定(不常用) 删除变量，通过添加unset指定(不常用) 字符串字符串是shell中最常用的数据类型，字符串可以用单引号，也可以用双引号，亦可以用反引号，但是各自的效果不同。 单引号 1234567#!/bin/bashstr=&apos;this is a string&apos;echo &apos;str=$&#123;str&#125;&apos;# output: # str=$&#123;str&#125; 特点： 单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的； 单引号字串中不能出现单独一个的单引号（对单引号使用转义符后也不行），但可成对出现，作为字符串拼接使用。 双引号1234567#!/bin/bashstr=&quot;this is a string&quot;echo &quot;str=$&#123;str&#125;&quot;# output: # str=this is a string 特点： 双引号里可以有变量，而且变量会被自动替换; 可以包含转义字符; 反引号1234567#!/bin/bashstr=`pwd`echo &quot;$&#123;str&#125;&quot;#output:# /home/zll 特点： 反引号中的内容会被当做命令执行; 拼接字符串1234567891011121314151617181920212223242526#!/bin/bashyour_name=&quot;runoob&quot;# 使用双引号拼接greeting=&quot;hello, &quot;$your_name&quot; !&quot;greeting_1=&quot;hello, $&#123;your_name&#125; !&quot;echo $greeting $greeting_1# 使用单引号拼接greeting_2=&apos;hello, &apos;$your_name&apos; !&apos;greeting_3=&apos;hello, $&#123;your_name&#125; !&apos;echo $greeting_2 $greeting_3#output:# hello, runoob ! hello, runoob !# hello, runoob ! hello, $&#123;your_name&#125; !``` &gt; 获取字符串长度(使用符号#) ```text#!/bin/bashstr=&apos;abcd&apos;echo $&#123;#str&#125;#output:# 4 截取字符串1234567#!/bin/bashstr=&apos;1234&apos;echo $&#123;str:2:4&#125; #截取第2到第4个字符串#ouput:# 234 查找字符串1234567#!/bin/bashstr=&apos;12304&apos;echo `expr index &quot;$&#123;str&#125;&quot; 0` #这里使用反引号执行命令，查找0的位置#output:# 4","tags":[{"name":"Shell","slug":"Shell","permalink":"https://cnkeep.github.io/tags/Shell/"}]},{"title":"03_通过Dockerfile构建自己的镜像文件","date":"2018-05-23T16:39:00.000Z","path":"2018/05/24/01-03_通过Dockerfile构建自己的镜像文件/","text":"通过Dockerfile构建自己的镜像文件目录Dockerfile是什么Dockerfile指令介绍示例-构建jdk镜像Dockerfile是什么&emsp;&emsp;Dockerfile是由一系列命令和参数构成的脚本，这些命令应用于基础镜像并最终创建一个新的镜像。其产出为一个新的可以用于创建容器的镜像。 Dockerfile指令 FROM &emsp;&emsp;FROM指令用于指定当前镜像所使用的的基础镜像，一般写在文件开头，如果想自定义构建docker镜像，那么引用的基础镜像一般是：centos, debian, ubuntu。 指令语法：1234567FROM &lt;image&gt;FROM &lt;image&gt;:&lt;tag&gt;FROM &lt;image&gt;:&lt;digest&gt;示例：FROM centos:v1 MAINTAINER &emsp;&emsp;MAINTAINER用于描述当前Dockerfile的文件信息指令语法：12345MAINTAINER &lt;name&gt;示例：MAINTAINER LeiLi.Zhang &lt;zhangleili924@gmail.com&gt; 3.RUN &emsp;&emsp;运行指定命令，此命令只有在执行docker build构建镜像时才会执行，Dokcerfile中的命令每执行一条即产生一个新的镜像，当前命令总是在最新的镜像上执行，所以为了避免缓存之类的影响，应尽量将多条命令合并为一条执行，每条RUN指令将在当前镜像基础上执行指定命令，并提交为新的镜像。当命令较长时可以使用\\来换行。 指令格式：1234567RUN &lt;command&gt;示例：RUN yum update \\&amp;&amp; yum install openjdk-8-jdk -y \\&amp;&amp; yum clean all 4.CMD &emsp;&emsp;设置容器启动时要执行的命令，只有在执行run 或者 start时才会运行，假如有多条命令只会执行最后一条，执行会覆盖。指令格式：1CMD [&quot;java -version&quot;] 5.EXPOSE 设置容器的暴露端口，注意并不是指暴露到物理机上的端口号！！！指令语法：1EXPOSE port 6.ENV 此指令为设置环境变量指令语法：1234ENV &lt;key&gt; &lt;value&gt;示例：ENV JAVA_HOME /usr/local/jdk 7.ADD 该指令的功能是把宿主机文件复制到镜像中，目录会自动创建。指令格式：12345ADD &lt;src&gt; &lt;dest&gt; src可以是网络资源示例：ADD /usr/local/app/jdk /usr/lib/jdk 绝对路径方式：将宿主机/usr/local/app/jdk目录拷贝到镜像/usr/lib/jdk目录ADD jdk /usr/lib/jdk 相对路径方式：将相对当前Dockerfile文件路径下的jdk目录拷贝至惊醒/usr/lib/jdk目录 8.COPY 此命令与ADD命令功能相似，不同的是，src只能是本地文件，且文件路径是Dockerfile的相对路径指令格式：1234COPY &lt;src&gt; &lt;dest&gt;示例：COPY jdk /usr/lib/jdk 将相对当前Dockerfile文件路径下的jdk目录拷贝至惊醒/usr/lib/jdk目录 9.VLOUME &emsp;&emsp;设置你的卷，在启动容器的时候Docker会在/var/lib/docker/的下一级目录下创建一个卷，以保存你在容器中产生的数据。若没有申明则不会创建。(可以把此指令看成shell中的mkdir）此指令不是独立数据卷，数据会随着容器的停止而消失，如果想数据持久化，请参考docker 简单命令 在run启动容器是加-V 参数！ 指令格式：1VLOUME [&quot;&quot;] 10.WORKDIR 指定容器的工作目录，可以在构建镜像的时候使用，也可以在启动容器的时候使用，构建使用是通过WORKDIR将当前目录切换到指顶目录中，可以理解为shell的cd，启动容器的时候使用的意思为 docker run 启动容器时，默认进入到目录是WORKDIR 指定的。 指令语法：1WORKDIR /usr 11.ENTRYPOINT RNTRYPONT指令与CMD指令的作用类似，都是在容器启动时执行相关的指令，不同的是， CMD中的参数会被启动时指定的动态参数替换掉，而ENTRYPOINT不会被替换掉。 CMD和ENTRYPOINT同时存在时，CMD中的指令会被一般结合这两者进行配置，ENTRYPOINT设置指令，CMD设置参数, 例如： 123#DockerfileENTRYPOINT [&quot;/bin/ping&quot;,&quot;-c&quot;,&quot;3&quot;]CMD [&quot;localhost&quot;] /bin/ping -c 3 localhost 示例-构建jdk镜像这里示例制作一个基于nginx镜像的jdk镜像 1.下载jdk 这里使用的是jdk1.8.0_172，通过工具上传到服务器/usr/local/dock_file目录（请自行事先建立该目录）12$ls /usr/local/docker_fileDockerfile jdk1.8.0_172 2.创建Dockerfile文件1234567891011121314151617181920212223$ cd /usr/local/docker_file$ touch Dockerfile#vi Dockerfile追加以下内容：#这里的基础镜像为nginxFROM nginxMAINTAINER LeiLi.Zhang#切换镜像目录WORKDIR /usrRUN mkdir jdk#将宿主机当前目录下的jdk1.8.0_172拷贝至镜像的/user/jdk目录下ADD jdk1.8.0_172 /usr/jdk$ 设置环境变量ENV JAVA_HOME=/usr/jdkENV JRE_HOME=$JAVA_HOME/jreENV CLASSPATH=.:$CLASSPATH:$JAVA_HOME/bin/dt.jar:$JAVA_HOME/lib/tools.jarENV PATH=$PATH:$JAVA_HOME/binCMD [&quot;java&quot;, &quot;-version&quot;] 3.构建镜像文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556$ docker build -f Dockerfile -t nginx_jdk8:1.0 ./Sending build context to Docker daemon 388.7MBStep 1/10 : FROM nginx ---&gt; 06144b287844Step 2/10 : MAINTAINER LeiLi.Zhang ---&gt; Running in 9fd7dfb2fdd4Removing intermediate container 9fd7dfb2fdd4 ---&gt; 8a1b63746989Step 3/10 : WORKDIR /usr ---&gt; Running in 600d738f937fRemoving intermediate container 600d738f937f ---&gt; 337b6327788cStep 4/10 : RUN mkdir jdk ---&gt; Running in e6533a32955eRemoving intermediate container e6533a32955e ---&gt; d18d4dd904d9Step 5/10 : ADD jdk1.8.0_172 /usr/jdk_8 ---&gt; 5a537bbcd84cStep 6/10 : ENV JAVA_HOME=/usr/jdk_8 ---&gt; Running in 3db8397affdbRemoving intermediate container 3db8397affdb ---&gt; 596cf637b2a7Step 7/10 : ENV JRE_HOME=$JAVA_HOME/jre ---&gt; Running in c16754fc69e0Removing intermediate container c16754fc69e0 ---&gt; b4b8531e6846Step 8/10 : ENV CLASSPATH=.:$CLASSPATH:$JAVA_HOME/bin/dt.jar:$JAVA_HOME/lib/tools.jar ---&gt; Running in d0be05ab96cfRemoving intermediate container d0be05ab96cf ---&gt; 606d80d75a70Step 9/10 : ENV PATH=$PATH:$JAVA_HOME/bin ---&gt; Running in eedc61c6889bRemoving intermediate container eedc61c6889b ---&gt; f5f3ca76f4dbStep 10/10 : CMD [&quot;java&quot; ,&quot;-version&quot;] ---&gt; Running in 5101d2bc1ebcRemoving intermediate container 5101d2bc1ebc ---&gt; 0118d7df925aSuccessfully built 0118d7df925aSuccessfully tagged nginx_jdk8:1.0``` &gt; 4.查看镜像是否成功 ```text$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEnginx_jdk8 1.0 cb6b8f24a584 24 seconds ago 496MBredis latest c188f257942c 7 weeks ago 94.9MBtime69/docker_study centos_base 7121cccf893c 3 months ago 982MBhello-world latest 4ab4c602aa5e 4 months ago 1.84kBtomcat latest 7671687227db 4 months ago 463MBnginx latest 06144b287844 4 months ago 109MBcentos latest 5182e96772bf 5 months ago 200MB 4.使用创建的镜像 123456$ docker run -it --name jdk8 nginx_jdk8:1.0 /bin/bash$ java -versionjava version &quot;1.8.0_172&quot;Java(TM) SE Runtime Environment (build 1.8.0_172-b11)Java HotSpot(TM) 64-Bit Server VM (build 25.172-b11, mixed mode) 5.导出镜像123$ docker save -o jdk_1.8_nginx.tar nginx_jdk8:1.0当面目录生成xxx.tar 6.导入镜像1$ docker load -i jdk_1.8_nginx.tar","tags":[{"name":"Docker","slug":"Docker","permalink":"https://cnkeep.github.io/tags/Docker/"}]},{"title":"02_Docker命令","date":"2018-05-23T13:21:00.000Z","path":"2018/05/23/01-02_Docker命令/","text":"命令列表 删除Docker12$ sudo yum remove docker-ce$ sudo rm -rf /var/lib/docker 搜索可用镜像1$ docker search [name] 拉取镜像123$ docker pull [name]:[version]其中version可以省略 查看镜像列表1$ docker images 运行容器123456789101112$ docket start [container] 运行一个已经存在的容器$ docker run -p 8080:80 --name test -d [image] 利用镜像image新建一个容器并启动$ docker run -d -i -t [image] /bin/bash 后台运行防止直接退出docker run 等价于 docker create + docker startrun: 利用镜像image创建一个容器并启动-p: 端口映射，容器内80端口映射到外部的8080端口--name: 容器命名-d: 后台运行-v: 文件映射 查看容器列表1$ docker ps -a 进入容器1$ docker exec -it [container] /bin/bash 停止容器1$ docker stop [container] 重启docker守护进程12$ systemctl daemon-reload$ systemctl restart docker 查看容器运行日志1$ docker logs [container] 查看容器信息1$ docker inspect [container] 移除容器1234$ docker rm [container]移除所有容器$ docker rm $(docker ps -a -q) 通过Dockerfile构建镜像1$ docker build -it [image] [path] 通过容器构建镜像1234567$ docker commit -a [author] [container] [repository[:tag]]示例：$ docker commit -a &quot;LeiLi.Zhang&quot; -m &quot;jdk8,nginx1.15,tomcat8.5.23&quot; centos_7 my:centos_base通过容器centos_7构建一个镜像-a 作者-m 提交信息 镜像的导出导入12345导出$ docker save -o xxxx.tar [image]导入$ docker load -i xxx.tar 容器的导入导出12$ docker export [container] &gt; xxx.tar$ cat xxx.tar | docker import - [res]:[tag]： DockerHub1234567拉取镜像$ docker login$ docker pull [name:tag]上传镜像$ docker tag [image:tag] [username/repository:tag] 将本地镜像重命名为标准的名称$ docker push [username/repository:tag] 查看容器/镜像的分层1$ docker history [image] 网络操作123456$ docker network [option]|[contain]# ls 查看网卡# inspect 查看网络信息# create 创建新的网卡# connect 连接到新的网卡","tags":[{"name":"Docker","slug":"Docker","permalink":"https://cnkeep.github.io/tags/Docker/"}]},{"title":"01_Docker介绍与安装","date":"2018-05-21T17:19:00.000Z","path":"2018/05/22/01-01_Docker介绍与安装/","text":"Docker目录什么是DockerDocker用来干什么Docker相关的点安装Docker什么是Docker&emsp;&emsp;不同的应用程序可能会有不同的应用环境，如果把他们依赖的软件都安装在一个服务器上就要调试很久，而且很麻烦，还会造成一些冲突。这个时候你就要隔离，我们可以在服务器上创建不同的虚拟机在不同的虚拟机上放置不同的应用，但是虚拟机开销比较高。docker可以实现虚拟机隔离应用环境的功能，并且开销比虚拟机小。 除此之外，它还可以像jvm屏蔽操作系统的底层细节，让我们的应用在不同系统部署变得更加方便。 总结就是：Docker是一个便携的应用容器, 我们的程序可以运行在容器之中。 Docker用来干什么 更快的运行服务，更高效的利用机器资源，更多的服务发布 屏蔽不同系统之间的差异，可以做到处处可部署运行，避免多次搭建环境(再也不会出现开发环境好好地，线上跑不起来了) 容器化带来了安全隔离，不在因为一个服务挂，导致所有服务挂 Docker相关的点Kubernetes, jenkins 安装Docker 本文采用Centos7作为服务器安装Docker, 详情参考官方：https://docs.docker.com/install/linux/docker-ce/centos/. 卸载docker旧版本12345678910$ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 安装工具类123$ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 配置docker仓库1234567891011$ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 会报以下错误： Loaded plugins: fastestmirror adding repo from: https://download.docker.com/linux/centos/docker-ce.repo grabbing file https://download.docker.com/linux/centos/docker-ce.repo to /etc/yum.repos.d/docker-ce.repo Could not fetch/save url https://download.docker.com/linux/centos/docker-ce.repo to file /etc/yum.repos.d/docker-ce.repo : [Errno 14] curl$ 35 - &quot;TCP connection reset by peer 这是由于国内访问不到docker官方镜像的缘故可以通过aliyun的源来完成：1234567$ sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 出现以下内容则表示docker仓库配置成功： Loaded plugins: fastestmirror adding repo from: http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo grabbing file http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo to /etc/yum.repos.d/docker-ce.repo repo saved to /etc/yum.repos.d/docker-ce.repo 参考：Docker CE 镜像源站 安装社区版docker 1234567891011$ sudo yum install docker-ce 内容如下： Installed: docker-ce.x86_64 0:18.03.0.ce-1.el7.centos Dependency Installed: audit-libs-python.x86_64 0:2.7.6-3.el7 checkpolicy.x86_64 0:2.5-4.el7 container-selinux.noarch 2:2.42-1.gitad8f0f7.el7 libcgroup.x86_64 0 libtool-ltdl.x86_64 0:2.4.2-22.el7_3 pigz.x86_64 0:2.3.3-1.el7.centos policycoreutils-python.x86_64 0:2.5-17.1.el7 python-IPy.noarch Complete! 验证是否安装成功123456789101112启动docker：$ sudo systemctl start docker验证docker:$ sudo docker run hello-world则会出现以下异常：Unable to find image &apos;hello-world:latest&apos; locallylatest: Pulling from library/hello-world9bb5a5d4561a: Pulling fs layerdocker: error pulling image configuration: Get https://dseasb33srnrn.cloudfront.net/registry-v2/docker/registry/v2/blobs/sha256/e3/e38bc07ac18eSee &apos;docker run --help&apos;. 镜像加速 上面提到的错误也是网络问题：国内无法访问dockerhub, 我们配置一下加速地址，登录https://www.daocloud.io 注册账号,使用Docker 加速器或者注册阿里云开发者获取加速地址 1$ curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://b481a1dd.m.daocloud.io 该脚本可以将 –registry-mirror 加入到你的 Docker 配置文件 /etc/docker/daemon.json 中（该文件不存在可手动建立）。 12345678910111213141516171819202122232425262728测试是否成功$ docker run hello-worldUnable to find image &apos;hello-world:latest&apos; locallylatest: Pulling from library/hello-worldd1725b59e92d: Pull complete Digest: sha256:523e382ab1801f2a616239b1052bb7ee5a7cce6a06cfed27ccb93680eacad6efStatus: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/ 目录结构默认情况下Docker的存放位置为：/var/lib/docker可以通过docker info命令查看 创建容器时通过-v 命令可以指定容器与宿主机之间的目录映射关系 启动Docker服务 pull命令从远程仓库拉取指定镜像(Image)，或者通过Dockerfile构建(build)新的镜像 使用run或者create+start命令，利用镜像生成容器并启动，一个镜像可以生成多个容器 镜像可以通过save,load命令导入导出，完成镜像的共享转移","tags":[{"name":"Docker","slug":"Docker","permalink":"https://cnkeep.github.io/tags/Docker/"}]},{"title":"maven私服搭建","date":"2018-05-01T16:12:00.000Z","path":"2018/05/02/01-maven私服搭建/","text":"使用Docker搭建maven私服 标签：maven, nexus3 参考： Nexus安装、使用说明、问题总结 从Maven私服获取依赖 Maven私有仓库: 发布release版本报错： Maven私服:Docker安装nexus3 前言作为一个Java程序员不可避免的要使用到maven仓库，但是我们经常遇见这样的情形： 网络受限，无法下载远程仓库的jar 公司内部的jar，无法获取，只能手动安装 远程现在速度太慢 针对以上的问题，我们就需要自己搭建一个Maven私服仓库。 介绍私服是架设在局域网的一种特殊的远程仓库，目的是代理远程仓库及部署第三方构件。有了私服之后，当 Maven 需要下载构件时，直接请求私服，私服上存在则下载到本地仓库；否则，私服请求外部的远程仓库，将构件下载到私服，再提供给本地仓库下载。 安装配置Nexus为了方便操作，我们直接采用docker安装 安装12345678910111213141516$ mkdir /home/nexus3# 搜索镜像$ docker search nexus3#下载镜像$ docker pull sonatype/nexus3# 启动$ docker run -id \\ --name=nexus3 \\ --privileged=true \\ --restart=always \\ -p 8081:8081 \\ -v /home/nexus3:/var/nexus-data \\ sonatype/nexus3 等待几分钟后，访问http://{ip}:8081/ 默认用户名admin，密码admin123 配置 1.配置镜像地址12345678910111213141516171819202122232425262728293031323334353637383940 &lt;mirrors&gt; &lt;!-- 私服镜像 --&gt;&lt;mirror&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://172.16.22.136:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt; &lt;!-- 阿里云镜像 --&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;url&gt;http://172.16.22.136:8081/repository/maven-public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;dev&lt;/activeProfile&gt; &lt;/activeProfiles&gt; 2.配置用户名密码123456789101112&lt;servers&gt; &lt;server&gt; &lt;id&gt;maven-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;maven-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt;&lt;/servers&gt; 3.配置项目pom.xml12345678910111213&lt;!--私服仓库--&gt;&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;maven-releases&lt;/id&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;http://172.16.22.136:8081/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;maven-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;http://172.16.22.136:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; 4.发布1$ mvn deploy 登录到nexus上就可以看到刚才打包的jar, 如果遇到：Return code is: 400, ReasonPhrase: Repository does not allow upd ating assets: maven-releases. 这是因为重复发布导致的，需要设置：","tags":[{"name":"Docker","slug":"Docker","permalink":"https://cnkeep.github.io/tags/Docker/"}]},{"title":"gitlab搭建","date":"2018-04-16T13:01:00.000Z","path":"2018/04/16/01-gitlab搭建/","text":"Docker方式安装gitlab 标签： Gitlab，Docker 开发中如果我们不希望代码托管在第三方平台，我们就可以自己搭建一套git服务端，这里采用流行的Gitlab和Docker搭建 1.安装gitlab1.1 环境介绍 Linux Centos, Linux localhost.localdomain 3.10.0-514.10.2.el7.x86_64 #1 SMP Fri Mar 3 00:04:05 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux docker Docker version 18.09.0, build 4d60db4 内存&amp;硬盘 内存&gt;4G, 硬盘&gt;20G 1.2 下载安装 1.镜像下载&amp;安装 拉取镜像1$ docker pull gitlab/gitlab-ce 建立容器映射文件夹 1234# 提前建立映射文件夹$ mkdir /home/gitlab/config$ mkdir /home/gitlab/data$ mkdir /home/gitlab/logs 启动容器 123456789101112131415$ docker run \\ --d \\ --privileged=true \\ --p 8443:443 \\ --p 8090:8090 \\ #web访问端口 --p 4422:4422 \\ #ssh访问端口 --name gitlab \\ --restart unless-stopped \\ -v /home/gitlab/config:/etc/gitlab \\ -v /home/gitlab/logs:/var/log/gitlab \\ -v /home/gitlab/data:/var/opt/gitlab \\ v /etc/localtime:/etc/localtime \\ gitlab/gitlab-ce:latest \\# 启动较为缓慢，需要等大约2分钟 2.配置端口123456789101112131415$ vi /home/gitlab/config/gitlab.rb## 修改http方式的端口密码 external_url &apos;http://172.16.22.135:8090&apos;## 修改ssh端口gitlab_rails[&apos;gitlab_shell_ssh_port&apos;] = 4422# 修改ssh端口$ docker exec -it gitlab /bin/bash$ vi /assets/sshd_config#修改ssh端口Port 4422#重启配置$gitlab-ctl reconfigure 参见：Gitlab SSH端口不生效 配置邮件服务 邮件服务配置 阿里云邮箱配置12345678910$ vi /home/gitlab/config/gitlab.rbgitlab_rails[&apos;smtp_enable&apos;] = truegitlab_rails[&apos;smtp_address&apos;] = &quot;smtp.mxhichina.com&quot;gitlab_rails[&apos;smtp_port&apos;] = 465gitlab_rails[&apos;smtp_user_name&apos;] = &quot;&lt;your user_name&gt;&quot;gitlab_rails[&apos;smtp_password&apos;] = &quot;&lt;your passwd&gt;&quot;gitlab_rails[&apos;smtp_domain&apos;] = &quot;&lt;your domain&gt;&quot;gitlab_rails[&apos;smtp_authentication&apos;] = &quot;login&quot;gitlab_rails[&apos;smtp_enable_starttls_auto&apos;] = truegitlab_rails[&apos;smtp_tls&apos;] = true 邮件服务测试12345678910111213141516171819202122232425262728293031$ docker exec -it gitlab /bin/bash#重启配置$gitlab-ctl reconfigureroot@8176a338c3ef:/# gitlab-rails console------------------------------------------------------------------------------------- GitLab: 11.6.5 (237bddc) GitLab Shell: 8.4.3 postgresql: 9.6.11-------------------------------------------------------------------------------------Loading production environment (Rails 5.0.7)irb(main):001:0&gt; Notify.test_email('1348555156@qq.com','subject','content').deliver_nowNotify#test_email: processed outbound mail in 173.5msSent mail to 1348555156@qq.com (2970.6ms)Date: Tue, 22 Jan 2019 14:40:57 +0000From: Gitlab &lt;zhangleili@cnkeep.cn&gt;Reply-To: Gitlab &lt;noreply@172.16.22.135&gt;To: 1348555156@qq.comMessage-ID: &lt;5c472b798ae1b_ae3fba61cca5f08927@8176a338c3ef.mail&gt;Subject: subjectMime-Version: 1.0Content-Type: text/html; charset=UTF-8Content-Transfer-Encoding: 7bitAuto-Submitted: auto-generatedX-Auto-Response-Suppress: All&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/loose.dtd\"&gt;&lt;html&gt;&lt;body&gt;&lt;p&gt;content&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;=&gt; #&lt;Mail::Message:70069490324460, Multipart: false, Headers: &lt;Date: Tue, 22 Jan 2019 14:40:57 +0000&gt;, &lt;From: Gitlab &lt;zhangleili@cnkeep.cn&gt;&gt;, &lt;Reply-To: Gitlab &lt;noreply@172.16.22.135&gt;&gt;, &lt;To: 1348555156@qq.com&gt;, &lt;Message-ID: &lt;5c472b798ae1b_ae3fba61cca5f08927@8176a338c3ef.mail&gt;&gt;, &lt;Subject: subject&gt;, &lt;Mime-Version: 1.0&gt;, &lt;Content-Type: text/html; charset=UTF-8&gt;, &lt;Content-Transfer-Encoding: 7bit&gt;, &lt;Auto-Submitted: auto-generated&gt;, &lt;X-Auto-Response-Suppress: All&gt;&gt;irb(main):002:0&gt;","tags":[{"name":"Git","slug":"Git","permalink":"https://cnkeep.github.io/tags/Git/"}]},{"title":"git的原理","date":"2018-04-07T12:25:00.000Z","path":"2018/04/07/01-git的原理/","text":"git的内部原理Git的内部原理&emsp;&emsp;Git本质上是一个内容寻址文件系统，从内部来看它是一个key-value数据库，可以插入任意内容，并返回一个键值，可以通过该键值在任何时候再取出该内容。接下来我们初始化一个本地仓库看看细节原理。 原理解析目录结构首先我们初始化一个本地仓库后，发现生成一个.git文件夹，git的存储和操作都是在操作这些文件(还记得它是一个文件系统吗)我们来看看目录结构以及每个目录的作用：12345678910111213141516├─HEAD 保存当前指向的分支├─config 保存当前项目的git配置选项├─index 保存暂存区信息├─COMMIT_EDITMSG 保存提交记录├─hooks├─logs 提交记录│ ├─HEAD│ └─refs├─info│ └─exclude├─objects git的核心数据存储│ ├─info│ └─pack└─refs 存储指向数据 (分支) 的提交对象的指针 ├─heads └─tags 上面这些目录中最重要的就是index和HEAD, objects和refs, logs这几个部分 原理分析接下来我们从add和commit命令来看git的运行原理。 为什么是内容寻址文件系统 &emsp;&emsp;我们前面提到Git是一个内容寻址文件系统，那么为什么这么说呢？其实Git是采用Key-Value数据存储原理，为每个数据通过SHA-1计算出一个键值key，采用key的前2位分目录创建目录，key的剩余部分为文件名，将原来的内容压缩作为文本内容存储。这样只要我们知道一个key就能轻易找到文件并还原出原文件内容，这就是.git/objects目录的内容结构。我们可以使用git cat-file -p key查看文件内容。 git的三个区域 介绍之前我们先要了解git相关的三个目录区域： 工作区(working directory): 对应我们真是操作的文件目录 暂存区(staged或者叫index): 对应.git/index 本地仓库(repository): 对应.git/objects目录它们之间的关系如图所示： git中的对象 Git中的对象有Commit, Tree, Blob, Tag四种对象，前三种最重要，我们先介绍着几个对象的作用，后面再讲Git是如何通过这些对象完成版本控制的。 Commit: 记录提交记录的信息，包含author, message, parent(前一个commit对象指针)，Tree对象指针 Tree: 用于记录目录结构的一组指针，包含文件类型，文件指针(Tree或者Blob),文件名 Blob: 存储压缩后的内容它们之间的关系如图所示： 正向操作 接下来就最常见的正常操作add，commit命令来看Git的工作原理12345678910111213141516171819202122232425262728293031323334353637383940414243$ git init #初始化一个本地仓库 $ vi readme.txt #创建一个文件$ This is readme. $ find .git/objects/ -type f #查看对象库，为空$ git ls-files --stage #查看暂存区信息，即.git/index内容$ git add readme.txt #文件放入暂存区，这一步会将readme.txt放入对象库并生成key存储在.git/index中$ find .git/objects/ -type f #查看对象库，生成新的文件.git/objects/52/cb6cdb81a64344370c918a301eb153035f915a$ git cat-file -t 52cb6cdb81a64344370c918a301eb153035f915a #查看对象类型blob #blob对象，存储文件内容$ git cat-file -p 52cb6cdb81a64344370c918a301eb153035f915a #查看文件内容This is readme. #文件内容与我们写入的一致$ git ls-file --stage #查看缓存区100644 52cb6cdb81a64344370c918a301eb153035f915a 0 readme.txt #记录着blob对象$ git commit -m &quot;add readme.txt&quot; #提交暂存区到本地仓库中$ find .git/objects/ -type f #查看对象库.git/objects/52/cb6cdb81a64344370c918a301eb153035f915a #Blob对象.git/objects/9b/6f349ad11c58d0e930dd12134a3e536bf5b057 #Tree对象.git/objects/d6/1479babc75f198416b5fd3caece3495b976391 #Commit对象$ vi readme.txtThis is readme.add line.$ git status #查看工作区和暂存区的文件状态，可以知道那些已经被暂存，那些没有On branch masterChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: readme.txtno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)$ git add readme.txt $ git commit -m &quot;change readme.txt&quot;$ find .git/objects/ -type f #查看对象库.git/objects/3a/3cf98cad23cb084fa1753bee60e9f97d08e317 #Tree对象.git/objects/52/cb6cdb81a64344370c918a301eb153035f915a #Blob对象，readme.txt:v1.git/objects/62/c1331ab1c19f93dd776e894404aebc6de14b85 #Blob对象，readme.txt:v2.git/objects/9b/6f349ad11c58d0e930dd12134a3e536bf5b057 #Tree对象，.git/objects/a6/08354310f5aec4436a99feab92c96c35fa895c #Commit对象，commit:2.git/objects/d6/1479babc75f198416b5fd3caece3495b976391 #Commit对象, commit:1 通过上面的操作我们可以分析出原理： git add: 通过将文件生成新的Blob对象，并提交到暂存区，写.git/index文件 git commit:通过暂存区生成Tree对象，Commit对象，提交到版本库，写.git/logs目录 git会为每一个的更改都保存一个副本经过一系列操作，最终形成如下结构: 逆向操作 所谓逆向操作，就是指撤销之前的操作，来分析一下Git的处理原理, 即checkout和reset命令。我们以撤销readme.txt的修改为例。12345678910111213141516171819202122232425262728293031323334353637383940414243444546$ git log #查看当前的commit结点commit a608354310f5aec4436a99feab92c96c35fa895c (HEAD -&gt; master)Author: TIME69 &lt;zhangleili924@gmail.com&gt;Date: Wed Sep 19 01:48:36 2018 +0800 change readme.txtcommit d61479babc75f198416b5fd3caece3495b976391Author: TIME69 &lt;zhangleili924@gmail.com&gt;Date: Wed Sep 19 01:38:42 2018 +0800 add readme.txt$ git rest HEAD^ #将版本库回退到上一个版本，此操作只是将HEAD指针指向前一个Commit对象而已,并将暂存区会退到上一个版本Unstaged changes after reset: #可以看到撤销了暂存区的更改M readme.txt$ git log #查看当前Head, 看到上次更改撤销了commit d61479babc75f198416b5fd3caece3495b976391 (HEAD -&gt; master)Author: TIME69 &lt;zhangleili924@gmail.com&gt;Date: Wed Sep 19 01:38:42 2018 +0800 add readme.txt $ git ls-files --stage #查看暂存区100644 52cb6cdb81a64344370c918a301eb153035f915a 0 readme.txt$ git cat-file -p 52cb6cdb81a64344370c918a301eb153035f915a #暂存区内容已经回退，但是工作区呢？This is readme.$ git diff --stage #查看暂存区和版本库的差异，发现没有差异，是相同的$ cat readme.txt #发现工作区没有回退This is readme.add line.$ git status #On branch masterChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: readme.txtno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)$ git checkout readme.txt #将工作区回退到上一个版本$ cat readme.txt #发现工作区内容变回来了This is readme. 看似很完美，但是这时候有人会说了那我不想撤销了咋办，我找不到记录了吗？怎么会，Git帮你存着呢。所有的提交记录Git都记录下来了(保存在.git/logs目录下的相应文件里)，不用怕丢，我们可以通过git reflog命令查看立即记录。1234$ git reflogd61479b (master) HEAD@&#123;6&#125;: reset: moving to HEAD^a608354 HEAD@&#123;7&#125;: commit: change readme.txtd61479b (master) HEAD@&#123;8&#125;: commit (initial): add readme.txt 我们知道Git操作的都是指针而已，那我们只要把HEAD指针指向下一个Commit结点不就完了，完美！1234$ git reset a608354 #暂存区Unstaged changes after reset:M readme.txt$ git checkout readme.txt #工作区 最终我们解决的问题，只要搞懂了底层机理是不是一下简单了许多，我们把工作区，暂存区，版本库之间的转换总结为下面这一张图： 内存压缩 我们上面说到git会对每一次的提交都保存一个副本Blob对象，那我们想一下那不是有很多冗余，很占存储空间，那能不能像svn那样存储变化的部分呢？其实Git已经考虑到了这一点，所以其内部有一个碎片处理的gc操作，类似于svn，但却有所区别。12345678910111213141516171819202122232425$ git gc #手动执行碎片处理Counting objects: 5, done.Delta compression using up to 4 threads.Compressing objects: 100% (3/3), done.Writing objects: 100% (5/5), done.Total 5 (delta 1), reused 0 (delta 0)$ find .git/objects/ -type f #查看对象库，发现pack目录多了文件，之前的object文件不见了.git/objects/info/packs.git/objects/pack/pack-57cbdc16b7fd157d77451245ef44ba68ea567e14.idx.git/objects/pack/pack-57cbdc16b7fd157d77451245ef44ba68ea567e14.pack$ git verify-pack -v .git/objects/pack/pack-57cbdc16b7fd157d77451245ef44ba68ea567e14.idx #查看pack文件a2d7df5381d7c3086ba998c6e7528725082e7e92 commit 218 157 12a608354310f5aec4436a99feab92c96c35fa895c commit 73 79 169 1 a2d7df5381d7c3086ba998c6e7528725082e7e92d61479babc75f198416b5fd3caece3495b976391 commit 167 125 24862c1331ab1c19f93dd776e894404aebc6de14b85 blob 26 33 373a06a3e45fb33f83522f2459baf4b2d6ebfc196bf tree 38 49 406ffd655096935b0b00e7eac2190ac0e61ea978e2e blob 33 40 4553a3cf98cad23cb084fa1753bee60e9f97d08e317 tree 38 49 4959b6f349ad11c58d0e930dd12134a3e536bf5b057 tree 38 48 54452cb6cdb81a64344370c918a301eb153035f915a blob 16 24 592non delta: 8 objectschain length = 1: 1 object.git/objects/pack/pack-57cbdc16b7fd157d77451245ef44ba68ea567e14.pack: ok 我们看看这两个文件是什么作用： .pack 是包文件，这个文件包含了从文件系统中移除的所有对象的内容 .idx是索引文件，这个文件包含了包文件的偏移信息值得注意的是，git不同于svn的是最后一个版本保存的是完成的文件内容，之前的版本保存的是差异部分，因为git认为这样更高效。 总结我们分析了Git的内部机理，我们来总结一下： Git是一个内容寻址文件系统, 会对每一份内容生成校验和，以便通过校验和再次获取原有数据 Git本质是一个Key-Value数据存储方式 Git存在三个区：工作区，暂存区，版本库，我们操作git就是操作这三个区域 Git理论上会针对每一次修改创建一个副本，但是为了减少存储空间会压缩采用存储差异 Git内部包含这些对象: Tag, Commit(记录提交信息，上一次提交的指针,Tree指针), Tree(记录文件列表，Tree+Blob), Blob(内容对象)","tags":[{"name":"Git","slug":"Git","permalink":"https://cnkeep.github.io/tags/Git/"}]},{"title":"hook钩子","date":"2018-04-06T14:13:00.000Z","path":"2018/04/06/02-hook钩子/","text":"Git中的hook钩子程序原文: Git中文官网-8.3 自定义 Git - Git 钩子 Git钩子&nbsp;&nbsp;Git能在特定的重要动作发生时触发自定义的脚本，俗称钩子(hooks)，类似于事件回调机制。Git中存在两组这样的钩子： 客户端钩子：由诸如提交和合并这样的操作所调用。 服务端钩子：作用域诸如接收被推送的提交这样的联网操作。 安装钩子&nbsp;&nbsp;当我们clone或者init一个仓库后，会在目录下生成.git目录，该目录即我们的git管理目录，其内部存在一个hooks的子目录，该目录下默认防止了一些以.sample结尾的示例脚本，当我们要激活一个钩子时，只需要去掉后缀，改写脚本即可。脚本支持多种语言,可以在首行指定#!/usr/bin/env XXX 这些脚本只对当前项目发挥作用，而且每次都需要从其他仓库复制一份进来，我们可以修改全局的配置（以windows为例），在git安装目录下的mingw64\\share\\git-core\\templates\\hooks目录下存在着全局脚本，我们可以修改这里的脚本，这样每次init后当前仓库中的脚本就会从全局中复制过来。 客户端钩子 pre-commit: 执行git commit命令时触发，常用于检查代码风格 prepare-commit-msg: commit message编辑器呼起前default commit message创建后触发，常用于生成默认的标准化的提交说明 commit-msg: 开发者编写完并确认commit message后触发，常用于校验提交说明是否标准 post-commit: 整个git commit完成后触发，常用于邮件通知、提醒 applypatch-msg: 执行git am命令时触发，常用于检查命令提取出来的提交信息是否符合特定格式 pre-applypatch: git am提取出补丁并应用于当前分支后，准备提交前触发，常用于执行测试用例或检查缓冲区代码 post-applypatch: git am提交后触发，常用于通知、或补丁邮件回复（此钩子不能停止git am过程） pre-rebase: 执行git rebase命令时触发 post-rewrite: 执行会替换commit的命令时触发，比如git rebase或git commit –amend post-checkout: 执行git checkout命令成功后触发，可用于生成特定文档，处理大二进制文件等 post-merge: 成功完成一次 merge行为后触发 pre-push: 执行git push命令时触发，可用于执行测试用例 pre-auto-gc: 执行垃圾回收前触发 服务端钩子 pre-receive: 当服务端收到一个push操作请求时触发，可用于检测push的内容 update: 与pre-receive相似，但当一次push想更新多个分支时，pre-receive只执行一次，而此钩子会为每一分支都执行一次 post-receive: 当整个push操作完成时触发，常用于服务侧同步、通知 这些钩子有如下的关系(颜色深的为常用钩子)： 示例：提交后自动maven打包 如果目录下存在pom.xml则打包(需已安装maven)，不考虑打包失败的情况, 修改post-commit文件`text #!/bin/sh# An example hook script to prepare a packed repository for use overdumb transports.# To enable this hook, rename this file to “post-update”.if [ -f “pom.xml” ];then mvn clean -Dmaven.test.skip=true package installelse echo “[!Error]not found pom.xml” echo “==========================”fi`","tags":[{"name":"Git","slug":"Git","permalink":"https://cnkeep.github.io/tags/Git/"}]},{"title":"vi命令","date":"2018-04-03T14:40:00.000Z","path":"2018/04/03/10-vi命令/","text":"vi命令命令功能&nbsp;&nbsp;vi命令是linux提供的强大的文本编辑工具，接下来我们就常用的功能做一下记录(非全部)。 vi查找 当你用vi打开一个文件后，因为文件太长，如何才能找到你所要查找的关键字呢？ /或者?,在命令模式下敲斜杆(/)这时在状态栏（也就是屏幕左下脚）就出现了 “/”然后输入你要查找的关键字敲回车就可以了。如果你要继续查找此关键字，敲字符n就可以继续查找了。值得注意的是“/”是向下查找，而“?”是向上查找，而在键盘定义上“?”刚好是“/”的上档符。 vi替换： vi/vim 中可以使用 ：s 命令来替换字符串以前只会使用一种格式来全文替换，这里只说部分 123456：s/vivian/sky/ 替换当前行第一个 vivian 为 sky：s/vivian/sky/g 替换当前行所有 vivian 为 sky：n,$s/vivian/sky/ 替换第 n 行开始到最后一行中每一行的第一个 vivian 为 sky：n,$s/vivian/sky/g 替换第 n 行开始到最后一行中每一行所有 vivian 为 sky n 为数字，若 n 为 .，表示从当前行开始到最后一行：%s/vivian/sky/（等同于：g/vivian/s//sky/）替换每一行的第一个 vivian 为 sky：%s/vivian/sky/g（等同于：g/vivian/s//sky/g）替换每一行中所有 vivian 为 sky 鼠标移动操作12345命令模式下``H,J,K,L``字符可以实现鼠标跳转，这几个键都是紧挨着的，操作多方便哦！ H:向前移动J:向下移动K:向上移动L:向后移动 行数操作12345#显示行号:set nu跳转到第10行:10 翻页12Ctrl+B: 上一页Ctrl+F: 下一页 复制，粘贴，撤销，删除1234yy: 复制当前行p: 粘贴u: 撤销更改dd: 删除","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"echo转义&&换行","date":"2018-04-03T12:45:00.000Z","path":"2018/04/03/12-echo转义&&换行/","text":"echo中的转义与换行经常使用echo命令，但是不知道怎么转义可不换行，今天用到了，做一下笔记。 1.原样输出(使用单引号)12345678910111213echo &apos;$name \\n end&apos;#output:# $name \\n end``` &gt; 2.显示转义字符(-e) ```textecho -e &apos;$name \\n end&apos;#output:# $name # end 3.不换行(\\c)12345echo -e &quot;$name \\n end \\c&quot; &amp;&amp; echo &quot;===&quot; #output:# $name # end ===","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"cd命令","date":"2018-04-03T11:57:00.000Z","path":"2018/04/03/01-cd命令/","text":"cd命令1.命令功能 切换当前目录至指定目录下 2.命令格式1cd [dirpath] 3.示例 显示当前目录12$pwd/home/zll 切换目录到当前用户home目录下12345678$cd ~或者$cd ``` &gt; 切换目录到上一次目录下 ```text$cd - 切换到父目录下1$cd ..","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"Https协议配置免输密码","date":"2018-04-03T11:56:00.000Z","path":"2018/04/03/05-Https协议配置免输密码/","text":"Https方式clone的项目每次都要输入用户名密码使用git从远程仓库clone下来的项目时，连接如果是https://, 而不是git@git (ssh)的形式时，我们每次git pull/push到远程仓库时，总提示需要输入账号和密码，太麻烦了，有没有办法呢？ 有！ 解决方案： 12git bash进入项目目录，输入：git config --global credential.helper store 完成配置后，再操作一次git pull, 然后提示输入账号密码，这次输入后就不需要再次输入密码了！","tags":[{"name":"Git","slug":"Git","permalink":"https://cnkeep.github.io/tags/Git/"}]},{"title":"启动脚本中1,2&是什么","date":"2018-04-03T11:53:00.000Z","path":"2018/04/03/05-启动脚本中1,2&是什么/","text":"启动脚本末尾的2&gt;&amp;1 &amp;的含义脚本中2&gt;&amp;1 &amp;的含义 &emsp;&emsp;我们总是在启动脚本中会发现这样的 “2&gt;&amp;1 &amp;”的奇怪部分，那这部分到底是什么含义呢？ linux标准输入输出流的标示&emsp;&emsp;我们知道设备都有输入输出流，那么linux中是如何去标示它们的呢？1230: 标准stdin输入流1：标准stdout输出流2：标准stderr错误流 举例分析 来看这样一个例子 command >2>&1 & ```12345678910我们对命令进行拆分： ![&amp;](images/how_about_&amp;.png) ```text1：我们执行的命令2：命令执行的打印信息流重定向的设备，**/dev/null**表示一个空设备，即重定向到它后不显示任何信息3：代表标准stderr流4：代表标准stdout输出流，这里的**&amp;**表示不把1当做文件看待，不添加&amp;则会把1当做文件看待5：表示以后台job的形式执行命令6：把stderr流重定向到stdout流","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"which_where_find","date":"2018-04-03T11:51:00.000Z","path":"2018/04/03/17-which_where_find/","text":"which, whereis, find的区别","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"EOF的使用","date":"2018-04-03T11:30:00.000Z","path":"2018/04/03/18-EOF的使用/","text":"Linux下EOF的使用1. 介绍如果我们需要往一个文件里自动输入N行内容。如果是少数的几行内容，还可以用echo追加方式，但如果是很多行，那么单纯用echo追加的方式就显得复杂了，这时候就可以使用EOF结合cat命令进行内容的追加了。 2. 用法123&lt;&lt;EOF ...EOF 通过cat配合重定向能够生成文件并追加操作,在它之前先熟悉几个特殊符号:&lt; :输入重定向&gt; :输出重定向&gt;&gt; :输出重定向,进行追加,不会覆盖之前内容&lt;&lt; :标准输入来自命令行的一对分隔号的中间内容. 3.示例1234567# cat &lt;&lt;EOF&gt;test.sh&gt; ssss&gt; lllll&gt; EOF# more test.sh sssslllll","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"tcpdump的使用","date":"2018-04-02T15:43:00.000Z","path":"2018/04/02/19-tcpdump的使用/","text":"tcpdump抓包工具的使用1. 介绍&nbsp;&nbsp;面对一些线上的网络问题排查时，经常需要抓取网络数据包进行分析，windows有大名鼎鼎的winshark, 而在linux就少有图形化的抓包工具，幸好有tcpdump工具的存在。 &nbsp;&nbsp; 它可以使用定义的规则抓取网卡上的数据包，便于我们分析数据。 2. 抓包原理2.1 原理介绍 抓包原理 Linux抓包是通过注册一种虚拟的底层网络协议来完成对网络报文(准确的说是网络设备)消息的处理权。当网卡接收到一个网络报文之后，它会遍历系统中所有已经注册的网络协议，当抓包模块把自己伪装成一个网络协议的时候，系统在收到报文的时候就会给这个伪协议一次机会，让它来对网卡收到的报文进行一次处理，此时该模块就会趁机对报文进行窥探，也就是把这个报文完完整整的复制一份，假装是自己接收到的报文，汇报给抓包模块。 注意事项 必须使用root身份执行 要抓取其他主机的数据包，需要开启混杂模式，即抓取任何经过它的数据包，不管这个数据包是不是发给它或者是它发出的。一般而言，Unix不会让普通用户设置混杂模式，因为这样可以看到别人的信息，比如telnet的用户名和密码，这样会引起一些安全上的问题，所以只有root用户可以开启混杂模式，开启混杂模式的命令是：ifconfig en0 promisc, en0是你要打开混杂模式的网卡。 2.2 命令介绍1. 命令格式12345678tcpdump [ -AdDefIKlLnNOpqRStuUvxX ] [ -B buffer_size ] [ -c count ] [ -C file_size ] [ -G rotate_seconds ] [ -F file ] [ -i interface ] [ -m module ] [ -M secret ] [ -r file ] [ -s snaplen ] [ -T type ] [ -w file ] [ -W filecount ] [ -E spi@ipaddr algo:secret,... ] [ -y datalinktype ] [ -z postrotate-command ] [ -Z user ] [ expression ] 2. 选项介绍-A：以ASCII编码打印每个报文（不包括链路层的头），这对分析网页来说很方便-a：将网络地址和广播地址转变成名字-c&lt;数据包数目&gt;：在收到指定的包的数目后，tcpdump就会停止-C：用于判断用 -w 选项将报文写入的文件的大小是否超过这个值，如果超过了就新建文件（文件名后缀是1、2、3依次增加）-d：将匹配信息包的代码以人们能够理解的汇编格式给出-dd：将匹配信息包的代码以c语言程序段的格式给出-ddd：将匹配信息包的代码以十进制的形式给出-D：列出当前主机的所有网卡编号和名称，可以用于选项 -i-e：在输出行打印出数据链路层的头部信息-f：将外部的Internet地址以数字的形式打印出来-F&lt;表达文件&gt;：从指定的文件中读取表达式,忽略其它的表达式-i&lt;网络界面&gt;：监听主机的该网卡上的数据流，如果没有指定，就会使用最小网卡编号的网卡（在选项-D可知道，但是不包括环路接口），linux 2.2 内核及之后的版本支持 any 网卡，用于指代任意网卡-l：如果没有使用 -w 选项，就可以将报文打印到 标准输出终端（此时这是默认）-n：显示ip，而不是主机名-N：不列出域名-O：不将数据包编码最佳化-p：不让网络界面进入混杂模式-q：快速输出，仅列出少数的传输协议信息-r&lt;数据包文件&gt;：从指定的文件中读取包(这些包一般通过-w选项产生)-s&lt;数据包大小&gt;：指定抓包显示一行的宽度，-s0表示可按包长显示完整的包，经常和-A一起用，默认截取长度为60个字节，但一般ethernet MTU都是1500字节。所以，要抓取大于60字节的包时，使用默认参数就会导致包数据丢失-S：用绝对而非相对数值列出TCP关联数-t：在输出的每一行不打印时间戳-tt：在输出的每一行显示未经格式化的时间戳记-T&lt;数据包类型&gt;：将监听到的包直接解释为指定的类型的报文，常见的类型有rpc （远程过程调用）和snmp（简单网络管理协议）-v：输出一个稍微详细的信息，例如在ip包中可以包括ttl和服务类型的信息-vv：输出详细的报文信息-x:/-xx/-X/-XX：以十六进制显示包内容，几个选项只有细微的差别，详见man手册-w:&lt;数据包文件&gt;：直接将包写入文件中，并不分析和打印出来expression：用于筛选的逻辑表达式； 3. 常用选项 抓取指定数目的包(-c选项) 默认情况下tcpdump将一直抓包，直到按下”ctrl+c”中止，使用-c选项可以指定抓包的数量。 将抓到包写入文件中(-w选项) 使用-w选项，可将抓包记录到一个指定文件中，以供后续分析 读取tcpdump保存文件(-r选项) 对于保存的抓包文件，可以使用-r选项进行读取 抓包时不进行域名解析(-n选项) 默认情况下，tcpdump抓包结果中将进行域名解析，显示的是域名地址而非ip地址，使用-n选项，可指定显示ip地址。 显示完整的包(-s0) 4. 表达式介绍 表达式是一个正则表达式，tcpdump利用它作为过滤报文的条件，如果一个报文满足表达式的条件，则这个报文将会被捕获。如果没有给出任何条件，则网络上所有的信息包将会被截获。在表达式中一般如下几种类型的关键字: 类型关键字主要包括host，net，port，缺省是host 传输方向关键字主要包括src（源地址）, dst(目标地址) ,dst or src, dst and src, 缺省是src or dst 协议关键字主要包括fddi,ip ,arp,rarp,tcp,udp等类型 3. 示例1. 监视指定网络接口的数据包 12# tcpdump -i eth1 如果不指定网卡，默认tcpdump只会监视第一个网络接口上所有流过的数据包，一般是eth0，下面的例子都没有指定网络接口。 2. 监视指定主机的数据包12345678910111213141516171819202122232425截获所有210.27.48.1 的主机收到的和发出的所有的数据包 # tcpdump host 210.27.48.1``` ### 3. TCP连接 这里通过telnet工具连接redis测试tcp连接的报文抓取 ```text [root@localhost redis-5.0.3]# tcpdump -i eth1 -v -s 0 port 6379 tcpdump: listening on eth1, link-type EN10MB (Ethernet), capture size 262144 bytes[1] 21:56:41.602246 IP (tos 0x0, ttl 64, id 54118, offset 0, flags [DF], proto TCP (6), length 52)[2] 172.16.22.235.54586 &gt; localhost.localdomain.6379: Flags [S], cksum 0xbe8b (correct), seq 1436544059, win 64240, options [mss 1460,nop,wscale 8,nop,nop,sackOK], length 0[3] 21:56:41.602294 IP (tos 0x0, ttl 64, id 0, offset 0, flags [DF], proto TCP (6), length 52)[4] localhost.localdomain.6379 &gt; 172.16.22.235.54586: Flags [S.], cksum 0x85b9 (incorrect -&gt; 0xdaf5), seq 3525089865, ack 1436544060, win 29200, options [mss 1460,nop,nop,sackOK,nop,wscale 7], length 0[5] 21:56:41.602446 IP (tos 0x0, ttl 64, id 54119, offset 0, flags [DF], proto TCP (6), length 40)[6] 172.16.22.235.54586 &gt; localhost.localdomain.6379: Flags [.], cksum 0x85d3 (correct), ack 1, win 2053, length 0[7] 21:56:48.665457 IP (tos 0x0, ttl 64, id 54123, offset 0, flags [DF], proto TCP (6), length 40)[8] 172.16.22.235.54586 &gt; localhost.localdomain.6379: Flags [F.], cksum 0x85d2 (correct), seq 1, ack 1, win 2053, length 0[9] 21:56:48.665797 IP (tos 0x0, ttl 64, id 58678, offset 0, flags [DF], proto TCP (6), length 40)[10] localhost.localdomain.6379 &gt; 172.16.22.235.54586: Flags [F.], cksum 0x85ad (incorrect -&gt; 0x8cf1), seq 1, ack 2, win 229, length 0[11] 21:56:48.666220 IP (tos 0x0, ttl 64, id 54124, offset 0, flags [DF], proto TCP (6), length 40)[12] 172.16.22.235.54586 &gt; localhost.localdomain.6379: Flags [.], cksum 0x85d1 (correct), ack 2, win 2053, length 0 ^C 6 packets captured 16 packets received by filter 0 packets dropped by kernel 分析12345678[1]~[6] 3次握手 [7]~[12] 4次挥手拿[1]来看，proto： 指明协议是TCPlength：报文长度srcHost:srcPort &gt; destHost:destPort :指明源地址端口和目标地址端口Flags[*]: 指明包类型，S代表SYN; .代表ACK; F代表FIN","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"git的常见命令","date":"2018-04-02T15:18:00.000Z","path":"2018/04/02/03-git的常见命令/","text":"Git的简单使用前言&emsp;&emsp;开发过程当中难以避免的要使用到版本控制工具，以前使用的SVN, 但随着Git的出现，它以及其优良的特性迅速火热，本节我们就来简单了解一下。 介绍&emsp;&emsp;Git是一个开源的分布式版本控制系统(本质是一个内容寻址文件系统，后面章节会做介绍)，用于敏捷高效地处理任何或小或大的项目。Git 与常用的版本控制工具 CVS, Subversion 等不同，它采用了分布式版本库的方式，不必服务器端软件支持（这点很重要，他可以在服务端无法访问的时候提交到本地仓库，等网络恢复后推送到远程仓库）。 Git 与 SVN的区别 简单使用初始化命令 init 初始化仓库1$ git init clone 克隆仓库12$ git clone https://github.com/repname$ git clone https://github.com/repname myrep #myrep作为本地仓库名 config 配置1234$ git config --list #查看配置$ git config --system user.name #系统级配置$ git config --global user.name #全局配置，系统用户级$ git config user.name #仓库级配置 remote 远程仓库12345$ git remote -v #查看远程仓库详细信息$ git remote show origin #查看远程仓库$ git remote add pb https://github.com/pb #添加远程仓库映射$ git remote rename pb paul #重命名远程仓库映射$ git remote rm paul #移除远程仓库映射关系 ### 基础命令 status 查看文件状态123$ git status$ git status -s #状态简览$ git ls-files --stage #查看缓存区索引文件内容，即.git/index add 暂存已修改文件12$ git add filename$ git add -A #暂存所有已修改文件 commit 提交更新12$ git commit -m &quot;commit message&quot;$ git commit -a -m &quot;commit message&quot; #跳过暂存区，直接提交 push 推送到远程仓库12$ git push$ git push origin master #将本地master分支推动到远程origin仓库 fetch 从远程仓库拉取数据1$ git fetch [remote-name] merge 合并分支123$ git merge --no-ff #推荐的合并方式，会做作一个新的提交，便于历史查询 $ git merge hotfix #把 hotfix 分支，合并到当前分支$ git mergetool #图形化解决冲突的工具 pull ( fetch + merge ) 常用命令 diff 查看修改12$ git diff #比较 暂存区－工作区$ git diff --staged #比较 仓库－暂存区 log 查看提交历史1234567$ git log$ git log --stat #展示提交的简略统计信息$ git log --oneline #简要显示$ git log --grep #类似grep命令，支持正则查找$ git log --since/after/before/until #只是时间点查找$ git log $ git reflog #回退版本后看不到之后的历史记录，此命令可以完成该功能 撤销操作12345$ git commit --amend #重新提交$ git reset HEAD filename #取消暂存的文件$ git reset -soft #暂存区-&gt;工作区, 类似于checkout$ git reset --mixed #版本库-&gt;暂存区 $ git reset --hard #版本库-&gt;暂存区-&gt;工作区 checkout1234567$ git checkout &lt;filename&gt;# 会覆盖工作区文件# 如果暂存区有改动的文件，则从暂存区到工作区# 如果暂存区无改动的文件，则从仓库到工作区#新建分子并切换至新分支$ git checkout -b &lt;branch_name&gt; tag 打标签1234567$ git tag #查看标签$ git tag -a v1.4 -m &quot;my version 1.4&quot; #创建附注标签$ git tag v1.4 #创建轻量标签$ git tag -a v1.2 9fceb02 #对某次提交后期打标签$ git push origin v1.5 #上传某个标签，GIT 默认不会 push 标签到远程仓库$ git push origin --tags #上传所有不在远程仓库的标签$ git checkout -b version2 v2.0.0 #检出标签 rm 移除文件12$ git rm filename #个人感觉效果同 rm$ git rm --cached filename #移除暂存区中的文件 分支命令 branch 创建分支123456789$ git branch #查看分支，前面带星号*的，是当前分支$ git branch testing #创建 testing 分支$ git branch -d testing #删除 testing 分支$ git branch -v #查看每个分支最后一次提交$ git branch --merged #查看已合并到当前分支的分支$ git branch --no-merged #查看未合并到当前分支的分支$ git branch -r #查看远程分支$ git push origin &lt;local_branch&gt;:&lt;remote_branch&gt; #推送本地分支到远程分支，不存在时新建远程分支$ git push origin :&lt;remote_branch&gt; #与上一条不同的时本地分支留空了，这将会删除远程分支 checkout 切换分支12$ git checkout testing$ git checkout -b iss53 #创建分支，并切换到新创建的分支 底层命令 cat-file 读取 GIT 仓库对象1234$ git cat-file -p f8a67de1d4bf0d6dbaaaf8990ffe8394e5fa88ee #查看对象内容$ git cat-file -p master^&#123;tree&#125; #master 分支上最新的提交所指向的 tree 对象$ git cat-file -t f8a67de1d4bf0d6dbaaaf8990ffe8394e5fa88ee #查看对象类型$ git cat-file -s f8a67de1d4bf0d6dbaaaf8990ffe8394e5fa88ee #查看对象大小 gc 生成包文件1234$ git gc#作用：完整保存最新版文件，历史版本文件保存差异#GIT 会根据情况自己执行，一般不需要手动之行$ git verify-pack -v .git/objects/pack/pack-57cbdc16b7fd157d77451245ef44ba68ea567e14.idx 查看对象 $ find .git/object/ -type f #所有对象列表 $ git rev-list --objects --all #blob列表","tags":[{"name":"Git","slug":"Git","permalink":"https://cnkeep.github.io/tags/Git/"}]},{"title":"挂载","date":"2018-04-02T13:56:00.000Z","path":"2018/04/02/16-挂载/","text":"https://blog.csdn.net/csh86277516/article/details/78844830https://blog.csdn.net/qq_39521554/article/details/79501714","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"sed命令","date":"2018-04-02T13:50:00.000Z","path":"2018/04/02/08-sed命令/","text":"sed命令[注：文中的命令参数列表至列出了常用的几个，并不是全部] sed命令 功能 &emsp;&emsp;sed是一种流编辑器，它是文本处理中非常中的工具，能够完美的配合正则表达式使用, 可以完成文件内容的批量替换，删除等。 使用方式及参数列表 1234567891011121314151617181920212223242526sed [options] &apos;command&apos; file(s)参数列表： g 表示行内全面替换。 p 表示打印行。 i 修改源文件 w 表示把行写入一个文件。 x 表示互换模板块中的文本和缓冲区中的文本。 y 表示把一个字符翻译为另外的字符（但是不用于正则表达式） \\1 子串匹配标记 &amp; 已匹配字符串标记 匹配模式： ^ 匹配行开始，如：/^sed/匹配所有以sed开头的行。 $ 匹配行结束，如：/sed$/匹配所有以sed结尾的行。 . 匹配一个非换行符的任意字符，如：/s.d/匹配s后接一个任意字符，最后是d。 * 匹配0个或多个字符，如：/*sed/匹配所有模板是一个或多个空格后紧跟sed的行。 [] 匹配一个指定范围内的字符，如/[ss]ed/匹配sed和Sed。 [^] 匹配一个不在指定范围内的字符，如：/[^A-RT-Z]ed/匹配不包含A-R和T-Z的一个字母开头，紧跟ed的行。 \\(..\\) 匹配子串，保存匹配的字符，如s/\\(love\\)able/\\1rs，loveable被替换成lovers。 &amp; 保存搜索字符用来替换其他字符，如s/love/**&amp;**/，love这成**love**。 \\&lt; 匹配单词的开始，如:/\\&lt;love/匹配包含以love开头的单词的行。 \\&gt; 匹配单词的结束，如/love\\&gt;/匹配包含以love结尾的单词的行。 x\\&#123;m\\&#125; 重复字符x，m次，如：/0\\&#123;5\\&#125;/匹配包含5个0的行。 x\\&#123;m,\\&#125; 重复字符x，至少m次，如：/0\\&#123;5,\\&#125;/匹配至少有5个0的行。 x\\&#123;m,n\\&#125; 重复字符x，至少m次，不多于n次，如：/0\\&#123;5,10\\&#125;/匹配5~10个0的行。 示例 12345678910111.选项-i,匹配file文件中每一行的第一个book替换为books： $ sed -i &apos;s/book/books/g&apos; file2.-n选项和p命令一起使用表示只打印那些发生替换的行： $ sed -n &apos;s/test/TEST/p&apos; file 3.使用后缀 /g 标记会替换每一行中的所有匹配： $ sed &apos;s/book/books/g&apos; file #不会修改源文件 4.替换文件中所有的6379为6380并生成新文件 $ sed &apos;s/6379/6380/g&apos; redis.conf &gt; redis-6380.conf","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"yum工具配置","date":"2018-04-02T13:32:00.000Z","path":"2018/04/02/15-yum工具配置/","text":"yum工具配置介绍yum是一款软件包管理器，能够从指定的服务器自动下载RPM包并且安装，还可以自动处理依赖性关系，yum提供了查找、安装、删除某一个，一组甚至全部软件包的命令，而且命令简洁而又好记。 常用命令介绍 1.查找与显示123456# 查找软件yum search &lt;package&gt;#显示安装包信息yum info &lt;package&gt;#显示已经安装和可以安装的程序包yum list 2.安装1yum install &lt;package&gt; 3.更新与升级12345#更新yum update [&lt;package&gt;]#升级程序yum upgrade &lt;package&gt; 4.移除程序1234#移除程序包yum remove &lt;package&gt;##查看依赖yum deplist &lt;package&gt; 5.缓存12345#缓存清除yum clean #生成缓存yum makecache 配置及目录介绍 1.配置文件/etc/yum.conf 1234567891011121314151617181920212223242526[main]cachedir=/var/cache/yum/$basearch/$releaseverkeepcache=0debuglevel=2logfile=/var/log/yum.logexactarch=1obsoletes=1gpgcheck=1plugins=1installonly_limit=5bugtracker_url=http://bugs.centos.org/set_project.php?project_id=23&amp;ref=http://bugs.centos.org/bug_report_page.php?category=yumdistroverpkg=centos-release# This is the default, if you make this bigger yum won&apos;t see if the metadata# is newer on the remote and so you&apos;ll &quot;gain&quot; the bandwidth of not having to# download the new metadata and &quot;pay&quot; for it by yum not having correct# information.# It is esp. important, to have correct metadata, for distributions like# Fedora which don&apos;t keep old packages around. If you don&apos;t like this checking# interupting your command line usage, it&apos;s much better to have something# manually check the metadata once an hour (yum-updatesd will do this).# metadata_expire=90m# PUT YOUR REPOS HERE OR IN separate files named file.repo# in /etc/yum.repos.d 简单介绍一下： cachedir: yum缓存目录，yum在此存储下载的rpm包和数据库 logfile: 日志文件 2.镜像仓库配置目录/etc/yum.repos.d/123$ ls /etc/yum.repos.d/Centos-7.repo CentOS-CR.repo CentOS-fasttrack.repo CentOS-Sources.repo docker-ce.repo_bakCentOS-Base.repo_bak CentOS-Debuginfo.repo CentOS-Media.repo CentOS-Vault.repo 该目录下面的配置文件指明了镜像的源地址配置，我们可以在此配置新的镜像源地址 3.插件等其他的配置文件目录/etc/yum/yum/12$ ls /etc/yum/yum/fssnap.d pluginconf.d protected.d vars version-groups.conf 这里重点介绍pluginconf.d/目录是相关插件的配置目录，后面介绍的fastestmirror插件配置文件就在这里 拓展添加源添加阿里的镜像源 123#配置域名解析# vi /etc/resolve.conf nameserver 8.8.8.8 方式一：12345678910#备份原有配置$ mv /etc/yum.repos.d/Centos-7.repo /etc/yum.repos.d/Centos-7.repo.bak# 下载阿里镜像配置$ sudo yum-config-manager \\ --add-repo \\ http://mirrors.aliyun.com/repo/Centos-7.repo#清理缓存$ sudo yum clean#构建缓存$ sudo yum makecache 方式二:123456789#备份原有配置$ mv /etc/yum.repos.d/Centos-7.repo /etc/yum.repos.d/Centos-7.repo.bak# 下载阿里镜像配置$ wget http://mirrors.aliyun.com/repo/Centos-7.repo$ mv Centos-7.repo /etc/yum.repos.d/Centos-7.repo#清理缓存$ sudo yum clean all#构建缓存$ sudo yum makecache 方式三：12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 查看缓存存储路径$ yum-config-manager|grep base_persistdirpersistdir = /var/lib/yum/repos/x86_64/7base_persistdir = /var/lib/yum/repos/x86_64/7base_persistdir = /var/lib/yum/repos/x86_64/7$ cd /var/lib/yum/repos/x86_64/7$ vi /etc/yum.conf [main] cachedir=/var/cache/yum/$basearch/$releasever keepcache=0 debuglevel=2 logfile=/var/log/yum.log exactarch=1 obsoletes=1 gpgcheck=1 plugins=1 #将plugins的值修改为0 installonly_limit=5$ sudo yum install yum-plugin-fastestmirror$ vi /etc/yum/pluginconf.d/fastestmirror.conf [main] enabled=1 #配置为1 verbose=0 always_print_best_host = true socket_timeout=3 # Relative paths are relative to the cachedir (and so works for users as well # as root). hostfilepath=timedhosts.txt maxhostfileage=10 maxthreads=15 #exclude=.gov, facebook #include_only=.nl,.de,.uk,.ie $ vi /var/cache/yum/x86_64/7/timedhosts.txt #加入下列内容 mirrors.aliyuncs.com 99999999999 mirrors.cloud.aliyuncs.com 99999999999 mirrors.aliyun.com 2.03075098991#清理缓存$ sudo yum clean all#构建缓存$ sudo yum makecache","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"提交规范","date":"2018-04-02T13:05:00.000Z","path":"2018/04/02/04-提交规范/","text":"Git的提交规范参考： 阮一峰-Commit message 和 Change log 编写指南 并非严格按照此规范执行，可以实际情况实际定制规则，主要为了规范化。 提交格式12345&lt;type&gt;(&lt;scope&gt;) : &lt;subject&gt; &lt;空行&gt; &lt;body&gt; &lt;空行&gt; &lt;footer&gt; 其中 type 的值可以有很多，下面有几个我们常用到的 feature :新功能 fixbug:修复bug doc : 文档改变 style : 代码格式改变 refactor :某个已有功能重构 performance:性能优化 test :增加测试 chore: 修改了改变构建流程、或者增加依赖库、工具等 build :改变了build工具 如 grunt换成了 npm revert: 撤销上一次的 commit scope :用来说明此次修改的影响范围 可以随便填写任何东西,我推荐使用下列 all ：表示影响面大 ，如修改了网络框架 会对真个程序产生影响 loation： 表示影响小，某个小小的功能 module：表示会影响某个模块 如登录模块、首页模块 、用户管理模块等等 subject: 用来简要描述本次改动，概述就好了body:具体的修改信息 应该尽量详细footer: 附加信息，例如fix #*;issue #;ref #*** 1234567891011示例： [feature](user): 新增用户管理 description: 针对用户…… 示例： [fixbug](sqlmapper): issue #1252 sql error desctiption: 修复sql问题 使用插件校验提交信息(validate-commit-msg)依赖：安装npm, 安装node, ghooks, validate-commit-msg 1.跳转到项目根目录下 2.安装ghooks123456npm install ghooks --save-dev``` &gt; 3.安装[validate-commit-msg](https://github.com/conventional-changelog-archived-repos/validate-commit-msg) ```textnpm install --save-dev validate-commit-msg 4.生成package.json1npm init --yes 5.添加hooks配置123456在package.json中增加：&quot;config&quot;: &#123; &quot;ghooks&quot;: &#123; &quot;commit-msg&quot;: &quot;validate-commit-msg&quot; &#125; &#125; 6.测试 规范化辅助插件(commitizen) 1.全局安装commitizennode模块1npm install -g commitizen 2.在项目目录下运行命令1commitizen init cz-conventional-changelog --save --save-exact 3.此时可能会报找不到package.json的错误,使用下面命令来自动生成一个项目的package,然后在运行2中的命令.1npm init --yes 4.运行完以上一律使用git cz 代替git commit来提交代码,同时会显示一下选项来自动生成符合格式的commit message.123456789101112131415$ git czcz-cli@2.10.1, cz-conventional-changelog@2.1.0Line 1 will be cropped at 100 characters. All other lines will be wrapped after 100 characters.? Select the type of change that you&apos;re committing: (Use arrow keys)&gt; feat: A new feature fix: A bug fix docs: Documentation only changes style: Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons, etc) refactor: A code change that neither fixes a bug nor adds a feature perf: A code change that improves performance test: Adding missing tests or correcting existing tests(Move up and down to reveal more choices)","tags":[{"name":"Git","slug":"Git","permalink":"https://cnkeep.github.io/tags/Git/"}]},{"title":"ssh协议配置免密码提交","date":"2018-04-02T12:23:00.000Z","path":"2018/04/02/06-ssh协议配置免密码提交/","text":"ssh协议配置免密码提交 标签：Git, ssh, windows 介绍我们平时在使用git进行版本控制时，为了避免每次都输入密码，可以为账号添加ssh key,这样就可以避免输入账号密码的繁琐步骤。 配置ssh key 笔者这里介绍windows环境(linux环境配置类似)，笔者本地配置了多个远程仓库服务，所以这里是一种通用的配置方式 1.生成公钥123456789101112131415161718192021222324252627282930#任意目录打开git bash##为账号生成公钥$ ssh-keygen -t rsa -C &apos;1348555156@qq.com&apos;Generating public/private rsa key pair.##指定公钥文件的生成位置，这里配置为用户的主目录（前面括号中提示的位置,.ssh为ssh相关的配置目录），文件名随意指定Enter file in which to save the key (/c/Users/zll/.ssh/id_rsa): /c/Users/zll/.ssh/personal_rsa## 键入密码，可选Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /c/Users/zll/.ssh/personal_rsa.Your public key has been saved in /c/Users/zll/.ssh/personal_rsa.pub.The key fingerprint is:SHA256:e2fhKJwQ6vlWGjeHHXIUmoDefqnpGWBGt2XcieqiINs zhangleili@wxchina.comThe key&apos;s randomart image is:+---[RSA 2048]----+| .. .. || . o =.. || ...o B.o || ..o.*. o || =.+ S* .. || + +ooBooo . ||o + oO=oo + ||.+ . o=o o o ||. E o+ |+----[SHA256]-----+## 查看公钥$ cat /c/Users/zll/.ssh/personal_rsa.pubssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDRxhEozNNvtwL+CauYrs5fXznTvHpjzneNUG4RtEVrCkIxn8ld4W9VuFJ9UbC3cKIxB43svDiQqdnDPM08A8RfGDX0Jt686orkk7DAJerEEewoYollxcz79CHy17DhJ58yyz7zhVWW9sht/H6hEZuulliTtZIvtieH3xnL0zZVt/VWKk42pC+L/gEPWNDI0nkgmkVpKHaTxX503+Vh6tGJFf92Xg+t7UnqE+zz2WvZ4XTtX1Fli1y3ES7xS7ZwU5LwreDSrgT0u8EIk5HLCwcS5//9ZHJgkBGY3cdrgN0BUviNdWnYd4fI+4/Qb0C+acuMb/1ow1VxEKlE+6YMr6B7 XXXXXX@wxchina.com 2.服务端配置ssh key 登录到服务端，将上一步中的cat **.pub的输出内容粘贴复制到服务端 3.配置不同的服务端账号和地址 1.配置用户 1234567891011121314151617181920# 配置用户$ git config --global --add user.name &quot;&lt;username&gt;&quot;$ git config --global --add user.email &quot;&lt;email&gt;&quot;或者vi ~/.gitconfig##增加name和email[user] name = ******* email = ********* name = ******** email = *********[http] sslVerify = false[url &quot;https://&quot;] insteadOf = git://[credential] helper = store 2.配置服务端地址123456789101112131415161718192021222324252627#进入用户主目录，第一步中有提示$ cd /c/Users/zll/.ssh/#新建config配置文件$ touch config$ vi config# 配置github.comHost github.com User cnkeep HostName github.com IdentityFile C:\\Users\\zll\\.ssh\\id_rsa PreferredAuthentications publickey # 配置私有gitlabHost 172.16.22.135 User zhangleili #指定用户，在~/.gitconfig中配置的用户名 HostName 172.16.22.135 #指定服务器地址 Port 4422 #指定服务器端口(默认22) IdentityFile C:\\Users\\zll\\.ssh\\personal_rsa #指定公钥的文件 PreferredAuthentications publickey #指定验证策略# 码云Host gitee.com HostName gitee.com IdentityFile C:\\Users\\zll\\.ssh\\mayun_rsa PreferredAuthentications publickey 3.测试配置是否可用123456$ ssh -T git@github.comWarning: Permanently added the RSA host key for IP address &apos;52.74.223.119&apos; to the list of known hosts.Hi cnkeep! You&apos;ve successfully authenticated, but GitHub does not provide shell access.$ ssh -T git@172.16.22.135 Welcome to GitLab, @cnkeep! 4.ssh方式拉取项目12345678910$ git clone ssh://git@172.16.22.135:4422/developer/test.gitCloning into &apos;test&apos;...The authenticity of host &apos;[172.16.22.135]:4422 ([172.16.22.135]:4422)&apos; can&apos;t be established.ECDSA key fingerprint is SHA256:yvJ524f2Cxd60O4onSsE4K8TAtgWQISzWM+g6wi+H7Y.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &apos;[172.16.22.135]:4422&apos; (ECDSA) to the list of known hosts.remote: Enumerating objects: 3, done.remote: Counting objects: 100% (3/3), done.remote: Total 3 (delta 0), reused 0 (delta 0)Receiving objects: 100% (3/3), done. 结束语 这些都是笔者在搭建私有gitlab是亲自测试过的操作，可能因为不同环境有所差异。如有错误欢迎指正！","tags":[{"name":"Git","slug":"Git","permalink":"https://cnkeep.github.io/tags/Git/"}]},{"title":"git和svn有什么区别","date":"2018-04-02T12:20:00.000Z","path":"2018/04/02/02-git和svn有什么区别/","text":"Git和Svn的区别以前有Svn这种工具来进行版本控制，为什么还要用Git呢，两者有什么区别? 其实Git和Svn都是版本控制工具，但是Git更倾向于分布式，而且效率高，功能更强大。 Git和Svn的主要差别： 在Git 中的绝大多数操作都只需要访问本地文件和资源，不必联网就可以看到所有的历史版本记录，而SVN 却需要联网。 &nbsp;&nbsp;因为 Git 在本地磁盘上就保存着所有当前项目的历史更新，所以处理起来速度飞快，但我们需要浏览项目的历史更新摘要，Git 不用跑到外面的服务器上去取数据回来，而直接从本地数据库读取后展示给你看。如果想要看当前版本的文件和一个月前的版本之间有何差异，Git 会取出一个月前的快照和当前文件作一次差异运算。 SVN 断开网络或者断开VPN就无法commit代码，但是Git 可以先commit到本地仓库, svn断网就傻了 Git 克隆一个完整项目的速度非常快，SVN 非常慢。 Git 只关心文件数据的整体是否发生变化，而SVN这类版本控制系统则只关心文件内容的具体差异。 &nbsp;&nbsp;这类系统（如SVN）每次记录有哪些文件作了更新，以及都更新了哪些行的什么内容，然而Git 并不保存这些前后变化的差异数据。实际上，Git更像是把变化的文件作快照后，记录在一个微型的文件系统中。每次提交更新时，它会纵览一遍所有文件的指纹信息并对文件作一快照，然后保存一个指向这次快照的索引。为提高性能，若文件没有变化，Git 不会再次保存，而只对上次保存的快照作一链接。 Git分支管理比svn强大太多 在 SVN 这类的版本控制系统上，分支（branch）是一个完整的目录，且这个目录拥有完整的实际文件。如果工作成员想要开启新的分支，那将会影响“全世界”！每个人都会拥有和你一样的分支。如果你的分支是用来对系统模块进行安全检查测试的，那将会像传染病一样，你改一个分支，还得让其他人重新切分支重新下载，而且这些代码很可能对稳定版本还是具有破坏性的。 在 Git上，每个工作成员可以任意在自己的本地版本库开启无限个分支。举例：当我想尝试破坏自己的程序（安检测试），并且想保留这些被修改的文件供日后使用，我可以开一个分支，做我喜欢的事。完全不需担心妨碍其他工作成员。只要我不合并及提交到主要版本库，没有一个工作成员会被影响。等到我不需要这个分支时， 我只要把它从我的本地版本库删除即可，无痛无痒。","tags":[{"name":"Git","slug":"Git","permalink":"https://cnkeep.github.io/tags/Git/"}]},{"title":"重定向符号区别","date":"2018-04-02T11:34:00.000Z","path":"2018/04/02/04-重定向符号区别/","text":"&gt; 和 &gt;&gt; 区别 功能 &emsp;&emsp;都表示重定向到新的设备。 区别 两者的区别主要发生在重定向的设备已经存在时： &gt;会覆盖源文件 &gt;&gt;不会覆盖源文件，而是追加到源文件末尾","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"head&tail命令","date":"2018-04-01T14:46:00.000Z","path":"2018/04/01/11-head&tail命令/","text":"head &amp; tail命令命令功能&nbsp;&nbsp;倒序或者顺序查看文件内容 命令格式12$tail [filename]$head [filename] 常用参数示例 倒序查看100行1$tail -n 100 [filename] 倒序查看文件动态刷新，用于日志观察1$tail -f [filename] 查看文件前10行1$head -n 10 [filename]","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"wc命令","date":"2018-04-01T14:33:00.000Z","path":"2018/04/01/13-wc命令/","text":"1234567891011wc -l #统计行数 -c, --bytes print the byte counts -m, --chars print the character counts -l, --lines print the newline counts --files0-from=文件 从指定文件读取以NUL 终止的名称，如果该文件被 指定为&quot;-&quot;则从标准输入读文件名 -L, --max-line-length 显示最长行的长度 -w, --words 显示单词计数 --help 显示此帮助信息并退出 --version 显示版本信息并退出","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"开机启动项","date":"2018-04-01T14:25:00.000Z","path":"2018/04/01/14-开机启动项/","text":"开机启动项 标签：Redis, systemctl, chkconfig参考：Linux实现开机自动运行普通用户脚本参考：systemctl管理Redis启动、停止、开机启动 前言最近在玩Redis时，因为是放在虚拟机里跑的，但是虚拟机需要经常关机和开机，导致每次都要手动重启redis, 但是我受够了想让它开机自启，于是就有了今天的内容。 设置开机自启方案方案一:使用/etc/rc.d/rc.local自启动脚本文件实现开机自动运行普通用户脚本。 把需要开机启动的脚本程序直接写入/etc/rc.d/rc.local文件中，这样子开机时就会自动执行这些脚本程序，运行对应的服务程序。需要在root环境下编辑。 方案二:使用chkconfig和/etc/init.d 我们都了解/etc/init.d目录下的所有文件都是脚本文件，这个目录下的脚本文件，在设置到开机自启动后，会在开机时自动执行。 1.root账号编写自启动脚本12345678$ vi /etc/init.d/redis#!/bin/bash# redis auto start scripts#chkconfig: 235 80 30 --235指定的启动级别，在哪写启动级别下启动；--80 启动的优先级；--30 关闭的优先级su /usr/local/app/redis-5.0.3/src/redis-server /usr/local/app/redis-5.0.3/redis.conf --daemonize no 等级0表示：表示关机等级1表示：单用户模式等级2表示：无网络连接的多用户命令行模式等级3表示：有网络连接的多用户命令行模式等级4表示：不可用等级5表示：带图形界面的多用户模式等级6表示：重新启动 2.添加执行权限1$ chmod +x /etc/init.d/redis 3.加入启动项配置1234#假如启动项$ chkconfig --add redis #设置开机启动$ chkconfig redis on 4.查看启动项1$ chkconfig --list 方案三(推荐):使用systemctl和/lib/systemd/system/ 1.编写脚本1234567891011121314$ vi /lib/systemd/system/redis.service#写入以下内容[Unit]Description=Redis_5.0.1After=network.target[Service]#redis安装绝对路径ExecStart=/usr/local/app/redis-5.0.3/src/redis-server /usr/local/app/redis-5.0.3/redis.conf --daemonize noExecStop=/usr/local/app/redis-5.0.3/src//redis-cli -h 127.0.0.1 -p 6379 shutdown[Install]WantedBy=multi-user.target [Unit] 表示这是基础信息 Description 是描述 After 是在那个服务后面启动，一般是网络服务启动后启动 [Service] 表示这里是服务信息 ExecStart 是启动服务的命令 ExecStop 是停止服务的指令 [Install] 表示这是是安装相关信息 WantedBy 是以哪种方式启动：multi-user.target表明当系统以多用户方式（默认的运行级别）启动时，这个服务需要被自动运行。 详细请移步至：CoreOS实践指南（八）：Unit文件详解 2.设置开机启动123456789$ ln -s /lib/systemd/system/redis.service /etc/systemd/system/multi-user.target.wants/redis.service#刷新配置$ systemctl daemon-reload#开启开机自启功能$ systemctl enable redis$ systemctl [start|stop|restart|status] redis 3.查看启动项1$ systemctl list-unit-files *","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"user_group_chmod命令","date":"2018-04-01T13:46:00.000Z","path":"2018/04/01/09-user_group_chmod命令/","text":"user相关 &amp; group相关 &amp; chmod命令 本文中的命令参数选项并非全部选项，仅包含常用选项 用户系统&emsp;&emsp;linux是一个多用户多任务的系统，它有用户，用户组的概念，一个用户必须属于一个组。 user相关 与用户相关的配置文件1234567891011121314151617181920212223242526272829303132333435/etc/passwd 用户的配置文件/etc/shadow 用户的影子口令``` &gt; 与用户相关的命令 ```text1. useradd 功能：新建用户 用法：useradd [选项] 登录 useradd -D useradd -D [选项] 选项： -b, --base-dir BASE_DIR 新账户的主目录的基目录 -d, --home-dir HOME_DIR 新账户的主目录 -e, --expiredate EXPIRE_DATE 新账户的过期日期 -f, --inactive INACTIVE 新账户的密码不活动期 -g, --gid GROUP 新账户主组的名称或 ID -G, --groups GROUPS 新账户的附加组列表 -m, --create-home 创建用户的主目录 -M, --no-create-home 不创建用户的主目录 -p, --password PASSWORD 加密后的新账户密码 -r, --system 创建一个系统账户 示例： $ useradd -g zll_group -G root zll #新建用户zll, 用户主组zll_group, 附组root $ passwd zll #设置密码 $ id zll #查看用户zll的组 uid=1122(zll_group) gid=1125(zll_group) groups=1125(zll_group),0(root) $ useradd -s /sbin/nologin test #创建一个不能登录的用户2. usermod 功能：修改用户3. userdel 功能：删除用户 group相关 group相关配置文件 1/etc/group group相关命令 123456789101112131415161. groupadd 功能：新建用户组 用法：groupadd [选项] 用户组 选项： -g GID 指定新用户组的组标识号（GID）。 -o 一般与-g选项同时使用，表示新用户组的GID可以与系统已有用户组的GID相同。 示例： $ groupadd zll_group2. groupmod 功能：修改用户组3. groupdel 功能：删除用户组 文件权限&emsp;&emsp;linux的文件系统拥有严格访问权限，文件的可读可写，所属人，所属组都有严格的限制，我们也可以人为控制修改，这时候就要用到chmod命令了。我们先看看文件都有什么权限：123456789101112131415161718192021222324252627282930311：代表文件类型，为目录是为d2: 代表文件的宿主权限，由三位表示，4：可读，2：可写，1：可执行 3：代表文件的所属组权限4：代表其他用户的权限5：代表文件的所属用户6：代表文件的所属组``` &gt; chmod命令可以修改文件的相关权限 ```text语法： chmod [-cfvR] [--help] [--version] mode file...参数说明： [ugoa...][[+-=][rwxX]...][,...] 其中： u 表示该文件的拥有者，g 表示与该文件的拥有者属于同一个群体(group)者，o 表示其他以外的人，a 表示这三者皆是。 + 表示增加权限、- 表示取消权限、= 表示唯一设定权限。 r 表示可读取，w 表示可写入，x 表示可执行，X 表示只有当该文件是个子目录或者该文件已经被设定过为可执行。 其他参数说明： -c : 若该文件权限确实已经更改，才显示其更改动作 -f : 若该文件权限无法被更改也不要显示错误讯息 -v : 显示权限变更的详细资料 -R : 对目前目录下的所有文件与子目录进行相同的权限变更(即以递回的方式逐个变更) --help : 显示辅助说明 --version : 显示版本 示例： $ chmod +x start.sh #增加执行权限 chown可以修改文件的饿所属者 12345678910111213141516171819语法 chown [-cfhvR] [--help] [--version] user[:group] file...参数 : user : 新的文件拥有者的使用者 ID group : 新的文件拥有者的使用者组(group) -c : 显示更改的部分的信息 -f : 忽略错误信息 -h :修复符号链接 -v : 显示详细的处理信息 -R : 处理指定目录以及其子目录下的所有文件 --help : 显示辅助说明 --version : 显示版本实例 #将文件 file1.txt 的拥有者设为 users 群体的使用者 runoob : $ chown runoob:users file1.txt #将目前目录下的所有文件与子目录的拥有者皆设为 users 群体的使用者 lamport : $ chown -R lamport:users *","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"centos7防火墙","date":"2018-04-01T13:20:00.000Z","path":"2018/04/01/06-centos7防火墙/","text":"centos防火墙1234567891011121314151617181920212223242526272829303132333435363738391、firewalld的基本使用启动： systemctl start firewalld查看状态： systemctl status firewalld 停止： systemctl disable firewalld禁用： systemctl stop firewalld 2.systemctl是CentOS7的服务管理工具中主要的工具，它融合之前service和chkconfig的功能于一体。启动一个服务：systemctl start firewalld.service关闭一个服务：systemctl stop firewalld.service重启一个服务：systemctl restart firewalld.service显示一个服务的状态：systemctl status firewalld.service在开机时启用一个服务：systemctl enable firewalld.service在开机时禁用一个服务：systemctl disable firewalld.service查看服务是否开机启动：systemctl is-enabled firewalld.service查看已启动的服务列表：systemctl list-unit-files|grep enabled查看启动失败的服务列表：systemctl --failed3.配置firewalld-cmd查看版本： firewall-cmd --version查看帮助： firewall-cmd --help显示状态： firewall-cmd --state查看所有打开的端口： firewall-cmd --zone=public --list-ports更新防火墙规则： firewall-cmd --reload查看区域信息: firewall-cmd --get-active-zones查看指定接口所属区域： firewall-cmd --get-zone-of-interface=eth0拒绝所有包：firewall-cmd --panic-on取消拒绝状态： firewall-cmd --panic-off查看是否拒绝： firewall-cmd --query-panic 那怎么开启一个端口呢添加firewall-cmd --zone=public --add-port=80/tcp --permanent （--permanent永久生效，没有此参数重启后失效）重新载入firewall-cmd --reload查看firewall-cmd --zone= public --query-port=80/tcp删除firewall-cmd --zone= public --remove-port=80/tcp --permanent","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"时间同步","date":"2018-04-01T12:53:00.000Z","path":"2018/04/01/07-时间同步/","text":"Centos7时间不同步总是早8小时转载-CentOS 7系统时间与实际时间差8个小时 问题场景&emsp;&emsp;自己安装在虚拟机中的Centos时间总是早8个小时，每次都需要我手动改，太麻烦，今天终于决定彻底结局它。 结局方案123456789101112131415161718192021222324252627282930313233$ timedatectl #查看时间 Local time: 三 2018-10-24 23:30:48 CST Universal time: 三 2018-10-24 15:30:48 UTC RTC time: 三 2018-10-24 15:30:48 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: n/aNTP synchronized: no RTC in local TZ: no DST active: n/a $ ls /usr/share/zoneinfo/ #查看时区列表Africa Australia Cuba Etc GMT-0 Indian Kwajalein Navajo posix ROK UTCAmerica Brazil EET Europe GMT+0 Iran Libya NZ posixrules Singapore WETAntarctica Canada Egypt GB Greenwich iso3166.tab MET NZ-CHAT PRC Turkey W-SUArctic CET Eire GB-Eire Hongkong Israel Mexico Pacific PST8PDT UCT zone.tabAsia Chile EST GMT HST Jamaica MST Poland right Universal ZuluAtlantic CST6CDT EST5EDT GMT0 Iceland Japan MST7MDT Portugal ROC US$ rm /etc/localtime #删除原有的时区rm：是否删除符号链接 &quot;/etc/localtime&quot;？y$ sudo ln -s /usr/share/zoneinfo/Universal /etc/localtime #设置新的时区$ timedatectl Local time: 三 2018-10-24 15:46:55 UTC Universal time: 三 2018-10-24 15:46:55 UTC RTC time: 三 2018-10-24 15:46:54 Time zone: Universal (UTC, +0000) NTP enabled: n/aNTP synchronized: no RTC in local TZ: no DST active: n/a[root@localhost default]# date2018年 10月 24日 星期三 15:46:58 UTC","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"proc目录探查系统信息","date":"2018-04-01T12:29:00.000Z","path":"2018/04/01/16-proc目录探查系统信息/","text":"/proc目录探查系统信息 标签：/proc 介绍/proc 文件系统下的多种文件提供的系统信息不是针对某个特定进程的, 而是能够在整个系统范围的上下文中使用。可以使用的文件随系统配置的变化而变化。命令procinfo 能够显示基于其中某些文件的多种系统信息。包含：内存，硬盘等 使用 CPU1$ cat /proc/cpuinfo Memory12$ cat /proc/meminfo$ free -m 硬盘12$ fdisk -l$ df -h 其他 123456netstat -lntp # 查看所有监听端口 netstat -antp # 查看所有已经建立的连接 w # 查看活动用户 id # 查看指定用户信息 last # 查看用户登录日志 rpm -qa # 查看所有安装的软件包","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"git是什么","date":"2018-04-01T12:02:00.000Z","path":"2018/04/01/01-git是什么/","text":"Git是什么？ 作为一个Coder, 在编写代码过程中不可避免的要提交和修改文件，如何没有版本控制工具，我们想象一下，不小心删除了代码，恢复不了，昨天改了哪些，总会遇到这样对我问题，哪有没有一种工具能保存我们的历史修改记录，方便我们自由的切换到任意一个版本呢？ &nbsp;&nbsp;Git就是这样一个分布式版本控制工具, 能帮助我们记录文件的历史修改记录，可以自由的切换到文件的历史版本，再也不怕文件丢了！当然git远不止做了这些，它还提供了各种对比，合并，统计的功能。","tags":[{"name":"Git","slug":"Git","permalink":"https://cnkeep.github.io/tags/Git/"}]},{"title":"lrzsz上传下载工具","date":"2018-04-01T11:41:00.000Z","path":"2018/04/01/03-lrzsz上传下载工具/","text":"lrzsz上传下载工具应用场景&emsp;&emsp;我们使用linux时，经常需要与本机完成文件的传输，我们可以使用xftp, 但是还有更简单的命令。 lrzsz的使用 123$ yum install lrzsz$ rz #弹框选择文件上传到linux当前目录 $ sz [file] #从Linux下载文件","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"grep命令","date":"2018-04-01T11:34:00.000Z","path":"2018/04/01/02-grep命令/","text":"grep命令[注：文中的命令参数列表至列出了常用的几个，并不是全部] grep命令 功能 &emsp;&emsp;Linux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来. 使用方式及参数列表 1234567891011121314151617181920212223242526272829grep [option] pattern file参数列表： -a --text #不要忽略二进制的数据。 -A&lt;显示行数&gt; --after-context=&lt;显示行数&gt; #除了显示符合范本样式的那一列之外，并显示该行之后的内容。 -b --byte-offset #在显示符合样式的那一行之前，标示出该行第一个字符的编号。 -B&lt;显示行数&gt; --before-context=&lt;显示行数&gt; #除了显示符合样式的那一行之外，并显示该行之前的内容。 -c --count #计算符合样式的列数。 -C&lt;显示行数&gt; --context=&lt;显示行数&gt;或-&lt;显示行数&gt; #除了显示符合样式的那一行之外，并显示该行之前后的内容。 -d &lt;动作&gt; --directories=&lt;动作&gt; #当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。 -e&lt;范本样式&gt; --regexp=&lt;范本样式&gt; #指定字符串做为查找文件内容的样式。 -E --extended-regexp #将样式为延伸的普通表示法来使用。 -f&lt;规则文件&gt; --file=&lt;规则文件&gt; #指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。 -F --fixed-regexp #将样式视为固定字符串的列表。 -G --basic-regexp #将样式视为普通的表示法来使用。 -h --no-filename #在显示符合样式的那一行之前，不标示该行所属的文件名称。 -H --with-filename #在显示符合样式的那一行之前，表示该行所属的文件名称。 -i --ignore-case #忽略字符大小写的差别。 -l --file-with-matches #列出文件内容符合指定的样式的文件名称。 -L --files-without-match #列出文件内容不符合指定的样式的文件名称。 -n --line-number #在显示符合样式的那一行之前，标示出该行的列数编号。 -q --quiet或--silent #不显示任何信息。 -r --recursive #此参数的效果和指定“-d recurse”参数相同。 -s --no-messages #不显示错误信息。 -v --revert-match #显示不包含匹配文本的所有行。 -V --version #显示版本信息。 -w --word-regexp #只显示全字符合的列。 -x --line-regexp #只显示全列符合的列。 -y #此参数的效果和指定“-i”参数相同 示例 12345678910111213141516171. 进程查找 $ ps -ef|grep redis 2. 查找指定进程个数 $ ps -ef|grep -c svn 3. 从文件中读取关键词进行搜索 $ cat test.txt | grep -f test2.txt 4. 找出已u开头的行内容 $ cat test.txt |grep ^u 5. 去除注释和空格显示 $ cat redis.conf |grep -v &quot;#&quot;|grep -v &quot;^$&quot; &gt; redis-template.conf 6. 显示匹配行后面几行 $ grep -A &apos;options&apos; my.cnf","tags":[{"name":"Linux","slug":"Linux","permalink":"https://cnkeep.github.io/tags/Linux/"}]},{"title":"Condition_diff_wait_notify","date":"2017-11-22T18:24:00.000Z","path":"2017/11/23/07-Condition_diff_wait_notify/","text":"Condition与wait,notify的对比","tags":[{"name":"Lock","slug":"Lock","permalink":"https://cnkeep.github.io/tags/Lock/"}]},{"title":"Condition原理","date":"2017-11-22T18:01:00.000Z","path":"2017/11/23/06-Condition原理/","text":"Condition原理 在线程同步时可以使一个线程阻塞，释放锁并把执行权交给其他线程，我们称之为信号通知机制。在传统的使用synchronized关键字时，我们可以使用wait(),notify()方法来实现这种等待和唤醒的功能，那么concurrent包有没有为我们提供同样的机制呢，答案是肯定的，concurrent包下的Condition就是用来实现该功能的。 了解一下ConditionCondition作为一个接口，为我们提供了以下几个方法： 来看一个实例，这是jdk提供的实例：1234567891011121314151617181920212223242526272829303132333435363738class BoundedBuffer &#123; final Lock lock = new ReentrantLock(); final Condition notFull = lock.newCondition(); final Condition notEmpty = lock.newCondition(); final Object[] items = new Object[100]; int putptr, takeptr, count; public void put(Object x) throws InterruptedException &#123; lock.lock(); try &#123; //这里使用循环是为了防止过早通知 while (count == items.length) notFull.await(); items[putptr] = x; if (++putptr == items.length) putptr = 0; ++count; notEmpty.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; public Object take() throws InterruptedException &#123; lock.lock(); try &#123; while (count == 0) notEmpty.await(); Object x = items[takeptr]; if (++takeptr == items.length) takeptr = 0; --count; notFull.signal(); return x; &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; 这是一个利用Condition实现的生产者消费者模型。 Condition原理所有Lock的实现类都提供了newCondition();方法来获得Condition对象，而最终这些方法都是回调AbstractQueuedSynchronizer 的ConditionObject对象。其基本实现原理和基本使用方法如下： Condition提供了await()方法将当前线程阻塞，并提供signal()方法唤醒其他的阻塞线程。 与wait(), notify()需要在同步代码块中类似，Condition的相关曹组需要在获取锁的前提下进行。 线程调用await()方法时，将当前线程构造成结点加入到等待队列，同时释放锁，挂起当前线程。 其他线程调用signal()方法前也必须获取锁，当执行signal()方法时将等待队列的节点移入到同步队列，当线程退出临界区释放锁的时候，唤醒同步队列的首个节点。 关键源码分析 1.等待队列使用链表结构1234567891011121314151617181920212223242526272829303132333435363738394041424344 /** First node of condition queue. */ private transient Node firstWaiter; /** Last node of condition queue. */ private transient Node lastWaiter;``` 这里之所以头和尾结点没有像Lock那样使用volatile修饰，是因为基于Condition的操作都是在已经获得锁的情况下进行的，所以不存在竞争。 &gt; 2.调用``await()``阻塞当前线程 ```java public final void await() throws InterruptedException &#123; // step1: 判断是否中断，中断则直接抛出异常 if (Thread.interrupted()) throw new InterruptedException(); // step2: 将当先线程构造成新节点追加至Condition维护的等待队列队尾 Node node = addConditionWaiter(); // step3: 释放当前线程拥有的锁，通过修改state实现 int savedState = fullyRelease(node); int interruptMode = 0; /**step4: * 判断当前节点是否已经在同步队列中 * 如果是则退出循环; * 如果不是就阻塞当前线程; *其他线程如果发出了signal信号之后，会把等待队列的线程移入同步队列，此时就会退出循环，进入下面的重新获取锁的acquireQueued **/ while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; //step5: 其他发出signal信号的线程释放锁之后，该线程被唤醒并重新竞争锁 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled //step6: unlinkCancelledWaiters(); if (interruptMode != 0) //step7: reportInterruptAfterWait(interruptMode); &#125; 来看看step2: addConditionWaiter()123456789101112131415private Node addConditionWaiter() &#123; Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node;&#125; 将当前线程构建成一个waitStatus为CONDITION的结点并追加到最后一个有效结点的后面，这里代码稍微简单不做过多介绍。 在追加完成如等待队列之后我们就需要释放锁，如果不释放锁，就会出现死锁，所以调用fullyRelease（）释放锁：1234567891011121314151617181920212223242526final int fullyRelease(Node node) &#123; boolean failed = true; try &#123; int savedState = getState(); if (release(savedState)) &#123; failed = false; return savedState; &#125; else &#123; throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; // 释放锁失败后，将当前节点状态设置为CANCELLED // 后序会被清理出条件队列 if (failed) node.waitStatus = Node.CANCELLED; &#125;&#125;public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 这里因为已经获取了锁，不存在竞争，所以就简单的cas操作修改状态，并唤醒同步队列中的阻塞的线程即可，如果失败则直接抛出异常。 3.signal()唤醒等待线程 其他线程调用signal/signalAll方法，将等待队列的节点移入同步队列(signalAll只是循环执行signal而已)，signal调用doSignal public final void signal() { // 检查当前线程是否已经获取的锁，这是后序操作的前提 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) // 唤醒头结点 doSignal(first); } private void doSignal(Node first) { // 遍历等待队列 do { if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null;//得到firstWaiter } while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); } //将节点从等待队列移入同步队列 final boolean transferForSignal(Node node) { //cas节点状态错误，说明已经cancell了，直接返回false，doSignal()方法会继续尝试唤醒当前节点的后继节点 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; Node p = enq(node);//加入同步队列 int ws = p.waitStatus; //设置前置节点状态为signal，为了唤醒线程而设置 if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread);//特殊情况下唤醒线程并重新同步，一般情况下这里不会执行 return true; } 总结 Condition的原理与Lock类似，两者都维护着阻塞列表，Condition通过await和signal方法来完成等待队列和同步队列的交互。","tags":[{"name":"Lock","slug":"Lock","permalink":"https://cnkeep.github.io/tags/Lock/"}]},{"title":"volatile探究","date":"2017-11-22T13:58:00.000Z","path":"2017/11/22/02-volatile探究/","text":"volatile探究前言 上节01-并发中的关键性问题及解决思路.md一文中提到在happens-before原则的基础上使用volatile关键字可以实现原子操作的并发访问，那为什么volatile是如何实现的，本文就深入探讨一下。 volatile的使用我们来看看如何使用volatile实现原子操作的并发访问，注意：仅限原子操作! // public class Volatile{ private volatile int num = 0; private void get(){ System.out.println(String.format(\"num=%d\",num)); } private void set(int num){ this.num = num; } public static void main(String[] args){ final Volatile threadTest = new Volatile(); new Thread(()-&gt;{ threadTest.set(1); java.util.concurrent.TimeUnit.MILLISECONDS.sleep(1); },\"set\").start(); new Thread(()-&gt;{ threadTest.get(); },\"get\").start(); } } 上面这段代码可能不太恰当，但是不妨碍我们说明问题。一个写线程前去设置值，后一个读线程去读取值，我们由内存模型知读线程读取的不一定是修改后的值但是我们加了volatile关键字后，后面的读线程读取的永远是最新的值。 volatile原理volatile关键字提供了两层语义： 保证不同线程之间的内存可见性，但仅限于原子操作。 禁止了指令的重排序。 可见性 修改变量时会强制将变量的值刷新回主内存，并通知其他工作线程值失效，需要从主存重新获取。 禁止重排序 为volatile变量的操作使用内存屏障来禁止重排序，内存屏障分为四种类型：LoadLoad屏障：抽象场景：Load1; LoadLoad; Load2Load1 和 Load2 代表两条读取指令。在Load2要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 StoreStore屏障：抽象场景：Store1; StoreStore; Store2Store1 和 Store2代表两条写入指令。在Store2写入执行前，保证Store1的写入操作对其它处理器可见 LoadStore屏障：抽象场景：Load1; LoadStore; Store2在Store2被写入前，保证Load1要读取的数据被读取完毕。 StoreLoad屏障：抽象场景：Store1; StoreLoad; Load2在Load2读取操作执行前，保证Store1的写入对所有处理器可见。StoreLoad屏障的开销是四种屏障中最大的。 在一个变量被volatile修饰后，JVM会为我们做两件事：1.在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障。2.在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障。","tags":[{"name":"Lock","slug":"Lock","permalink":"https://cnkeep.github.io/tags/Lock/"}]},{"title":"Lock_diff_synchronize","date":"2017-11-21T17:18:00.000Z","path":"2017/11/22/05-Lock_diff_synchronize/","text":"Lock和synchronized的对比前面几章针对线程并发做了简单的介绍，我们知道要解决并发问题主要在三个方面： 保证内存一致性 禁止重排序 原子操作（并行转变为串行） 我们讲到java提供的并发解决方案有volatile, synchronized,Lock三种，那本章我们就来看看synchonized和Lock之间的区别。 使用方式的不同我们来看看两者的使用方式有什么不同：12345678910111213141516171819202122232425262728293031323334// synchronizedpublic class SynchronizedTest&#123; private int num; public synchronized void increment(int add)&#123; num += add; &#125; public synchronized int get()&#123; return num; &#125; &#125;// lock public class LockTest&#123; private int num; private ReentrantLock lock = new java.util.concurrent.locks.ReentrantLock(); public void increment(int add)&#123; lock.lock(); try&#123; num += add; &#125;finally&#123; lock.unlock(); &#125; &#125; public int get()&#123; lock.lock(); try&#123; return num; &#125;finally&#123; lock.unlock(); &#125; &#125;&#125; 从上面的例子可以看到两者在使用上的区别，synchronized是隐式锁，不需要显式的加锁释放锁; lock则是显式锁, 需要我们手动的去控制锁的 获取和释放。 中断的响应 synchronized加锁的方式是在等待获取锁的过程中是无法响应中断的，就只能一直傻傻的等待，不能做其他的操作，而lock可以通过lockInterruptibly() 方法来响应在等待锁的过程中发生的中断，避免一直主语等待的状态。 能否判断是否已经获取了锁 由于通过synchronized关键字的加锁方式属于隐式锁，其上层程序员无法干预，也无从知晓是否已经获得了锁; 而lock不同，它可以通过tryLock()的方法来获取锁 同时也可以知道是否获取锁成功。 是否支持超时 synchronized的加锁方式是不支持超时获取锁失败的操作的，它只能一直等，知道获取锁为止; 而lock不同，可以通过tryLock(long,TimeUnit)方法来达到 超时获取失败时直接返回的目的。 是否支持读写锁，公平锁 在某些场景下，我们希望锁的形式可以多样化一些，比如读写锁，公平锁，而synchronized属于非公平的互斥锁，达不到这些目的，而Lock锁提供了这些以适用于不同的场景。","tags":[{"name":"Lock","slug":"Lock","permalink":"https://cnkeep.github.io/tags/Lock/"}]},{"title":"ReentrantLock原理","date":"2017-11-21T14:53:00.000Z","path":"2017/11/21/04-ReentrantLock原理/","text":"ReentrantLock原理学习concurrent并发包为我们提供了多种并发工具，其中最吸引人的当属相关的锁了，这次就常用的互斥锁ReentrantLock做一个学习的记录，本人水平有限，存在错误欢迎指正！ 前言在各种多线程并发的处理中经常出现ReentrantLock的影子，它为我们提供了高效易用的并发实现，其利用volatile, CAS, AQS来实现，下面我们就具体来分析其内部原理。 什么是AQSAQS(AbstractQueueSynchronizer), 抽象队列同步器，它是concurrent包中各类锁的实现基础。AQS没有锁的概念，它通过被volatile修饰的state变量的改变来标示锁的状态, 同时使用一个双向队列存放阻塞的等待线程，直接分析AQS的代码比较抽象，所以下面就结合实现类：ReentrantLocak来分析。 公平锁和非公平锁1234567public ReentrantLock()&#123; sync = new NonfairSync();&#125;public ReentantLock(boolean fair)&#123; sync = fair ? new FairSync() : new NonfairSync();&#125; ReentrantLock的内部类Sync继承了AQS，分为公平锁和非公平锁： 公平锁： 线程获取锁的顺序和调用锁的顺序一致，即FIFO; 非公平锁：线程获取锁的顺序和调用锁的顺序无关; ReentrantLock默认采用非公平锁，这是为了性能考虑，公平锁为了保证线程规规矩矩地排队，需要增加阻塞和唤醒的时间开销。如果直接插队获取非公平锁，跳过了对队列的处理，速度会更快。 尝试获取锁123456final void lock()&#123;acquire(1);&#125;public final void acquire(int arg)&#123; if(!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.Exclusive),args)) selfInterrupt();&#125; 先来看公平锁的实现，lock方法直接调用AQS的acquire方法，而这个方式调用的tryAcquire方法是委托由子类去实现的，来看ReentrantLock的实现：12345678910111213141516171819protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123;// ① if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123;// ② int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false;&#125; 获取锁成功分为两种情况：①：当前state=0说明此时锁没有线程占有，接着判断队列中是否存在线程正在等待锁，不存在的话CAS操作修改state的值，获取锁成功，setExclusiveOwnerThread将线程记录为独占锁的线程。②：当前独占锁线程是当前线程，因为ReentrantLock是可重入锁，所以此时是重入的情况，线程可以不停的lock来增加state的值对应的unlock来解锁，减少state的值，直到state为0。假如获取锁失败，就需要将当前线程封装为一个新的结点追加到等待队列队尾。 线程进入等待队列AQS内部维护着一个双向的队列用来存放获取锁失败等待的线程，每个线程被包装为一个Node结点，包含线程对象和等待状态等信息。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061static final class Node &#123; /** Marker to indicate a node is waiting in shared mode */ static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ static final Node EXCLUSIVE = null; static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; volatile int waitStatus; volatile Node prev; volatile Node next; volatile Thread thread; Node nextWaiter; final boolean isShared() &#123; return nextWaiter == SHARED; &#125; final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; Node() &#123; // Used to establish initial head or SHARED marker &#125; Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; Node(Thread thread, int waitStatus) &#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125; &#125;``` 来看入等待队列的实现： ```java private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; //@1 start node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; //@1 end enq(node); return node; &#125; 当尾结点不为空时，说明有其他线程正在等待锁，先尝试去设置尾结点，设置失败再调用enq方法循环CAS设置。当尾结点为空时，表明没有线程持有锁123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize @1 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 上面的方法采用自旋的方式来加入队列，众所周知，CLH算法需要初始化一个head结点，但是head结点并不代表一个等待获取锁的线程AbstractQueuedSynchronzier选择初始化head,tail的时机为第一次产生锁争用的时候。@1处为初始化head,tail,设置成功后，初始化后，再将新添加的节点放入到队列的尾部， 阻塞等待线程接着看acquireQueued方法：1234567891011121314151617181920 final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); // @1 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // @2 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt() ) //@3 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 首先@1，获取当前结点的上一个有效结点如果前一个结点是头结点，可以尝试去获取锁，因为前一个结点在释放锁或者响应中断时会唤醒下一个结点，而且此时只有一个当前结点之前没有其他等待线程如果获取锁成功，则将自己修改为head；如果获取失败则进行阻塞，等待被唤醒下次再尝试获取锁。 1234567891011121314private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) return true; if (ws &gt; 0) &#123; do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 前节点状态是SIGNAL时，当前线程需要阻塞； 前节点状态是CANCELLED时，通过循环将当前节点之前所有取消状态的节点移出队列； 前节点状态是其他状态时，需要设置前节点为SIGNAL。 如果线程需要阻塞，有parkAndCheckInterrupt方法进行阻塞操作。1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 释放锁通过上面我们已经知道头结点是获取锁的线程，那么释放锁的话就要先将头结点移除队列，再通知后面的结点获取锁。123public void unlock() &#123; sync.release(1);&#125; ReentrantLock的unlock方法很简单地调用了AQS的release：123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 和lock的tryAcquire一样，unlock的tryRelease同样由ReentrantLock实现：123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 因为锁是可以重入的，所以每次lock会让state加1，对应地每次unlock要让state减1，直到为0时将独占线程变量设置为空，返回标记是否彻底释放锁。最后，调用unparkSuccessor将头节点的下个节点唤醒：123456789101112131415private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 寻找头结点的下一个可用结点是队尾向前查找的，这里为什从后向前查找呢？因为在这个队列中，任何一个结点都有可能被中断，只是有可能，并不代表绝对的，但有一点是确定的，被中断的结点会将结点的状态设置为CANCELLED状态，标识这个结点在将来的某个时刻会被踢出；踢出队列的规则很简单，就是该结点的前驱结点不会指向它，而是会指向它的后面的一个非CANCELLED状态的结点；而这个将被踢出的结点，它的next指针将会指向它自己；所以设想一下，如果我们从head往后找，一旦发现这么一个处于CANCELLED状态的结点，那么for循环岂不是就是死循环了；但是所有的这些结点当中，它们的prev前驱结点还是没有被谁动过，所以从tail结点向前遍历最稳妥 非公平锁分析完公平锁，再来看非公平锁，两者的主要区别是获取锁的过程不同。123456final void lock()&#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125; 先尝试去抢占锁，抢占成功就直接返回，否则继续执行acquire.123456789101112131415161718final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false;&#125; nonfaireTryAcquire和tryAcquire乍一看几乎一样，差异只是缺少hasQueuedPredecessors();方法，这一点体现出了公平锁和非公平锁的不同，即公平锁会关注排队情况，而非公平锁不会关注排队情况而是一有机会就直接去抢占。非公平锁的释放与公平锁是一致的。","tags":[{"name":"Lock","slug":"Lock","permalink":"https://cnkeep.github.io/tags/Lock/"}]},{"title":"synchronized","date":"2017-11-20T18:12:00.000Z","path":"2017/11/21/03-synchronized/","text":"synchronized实现原理前言 应用中我们经常会出现多个线程访问同一资源，但是访问要求必须是互斥的,即同一时刻只能有一个线程操作改共享资源。来看一个例子，开20个线程，其中10个线程去进行加操作，另外10个线程进行减操作，最后输出结果。 预期结果：0 实际结果：不确定的任意值 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class SynchronizedTest &#123; public volatile int inc = 0; public void increase() &#123; try &#123; TimeUnit.MILLISECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; inc++; &#125; public void sub()&#123; try &#123; TimeUnit.MILLISECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; inc--; &#125; public static void main(String[] args) throws InterruptedException &#123; final SynchronizedTest test = new SynchronizedTest(); final CountDownLatch latch = new CountDownLatch(20); for (int i = 0; i &lt; 10; i++) &#123; new Thread() &#123; public void run() &#123; for (int j = 0; j &lt; 100; j++) &#123; test.increase(); &#125; latch.countDown(); &#125; &#125;.start(); &#125; for (int i = 0; i &lt; 10; i++) &#123; new Thread() &#123; public void run() &#123; for (int j = 0; j &lt; 100; j++) &#123; test.sub(); &#125; latch.countDown(); &#125; &#125;.start(); &#125; latch.await(); System.out.println(test.inc); &#125;&#125; 在increase()和sub()方法上添加synchronized关键字，结果正常。 synchronized的用法 同步代码块：使用指定的对象作为锁对象。 同步方法：使用this作为锁对象。 同步静态方法：使用Class对象作为锁对象。 探索synchronized底层原理 Java 虚拟机中的同步(Synchronization)基于进入和退出管程(无论是显式同步(有明确的 ```monitorenter``` 和 ```monitorexit``` 指令, 1234567891011121314即同步代码块)还是隐式同步都是如此。* 同步代码块是由 monitorenter和 monitorexit 指令来实现同步的,其锁对象存储在对象头里。* 同步方法是由方法调用指令读取运行时常量池中方法的 ```ACC_SYNCHRONIZED``` 标志来隐式实现的。#### &gt;1. 同步代码块```java public class Test&#123; public static void main(String[] args)&#123; synchronized(Test.class)&#123; System.out.println(&quot;.&quot;); &#125; &#125; &#125; 可以看到同步代码块是通过和 ```monitorexit``` 指令来完成的，而且它是可重入锁，为了避免程序异常而导致的死锁的出现, 123456789101112131415161718192021222324252627&gt; 增加了异常处理器，可以看到后面多了一个moniterexit执行，保证当异常出现时，可能正常释放锁。而这些都是通过对象头部的标识来完成的。 &gt; 我们来看一下对象头的结构： ![对象头](images/object_head.png) &gt;* 实例变量：存放类的属性数据信息，包括父类的属性信息，如果是数组的实例部分还包括数组的长度，这部分内存按4字节对齐。&gt;* 填充数据：由于虚拟机要求对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐。&gt;* 对于顶部，则是Java头对象，它实现synchronized的锁对象的基础,其主要结构是由Mark Word 和 Class Metadata Address 组成，其结构说明如下： ![对象头结构](images/object_head_detail.png) 从字节码中可知同步语句块的实现使用的是monitorenter 和 monitorexit 指令，其中monitorenter指令指向同步代码块的开始位置，monitorexit指令则指明同步代码块的结束位置，当执行monitorenter指令时，当前线程将试图获取 objectref(即对象锁) 所对应的功。monitor 的持有权，当 objectref 的 monitor 的进入计数器为 0，那线程可以成功取得 monitor，并将计数器值设置为 1，取锁成如果当前线程已经拥有 objectref 的 monitor 的持有权，那它可以重入这个 monitor (关于重入性稍后会分析)，重入时计数器的值也会加1。倘若其他线程已经拥有 objectref 的 monitor 的所有权，那当前线程将被阻塞，直到正在执行线程执行完毕，即monitorexit指令被执行, 执行线程将释放 monitor(锁)并设置计数器值为0 ，其他线程将有机会持有 monitor 。值得注意的是编译器将会确保无论方法通过何种方式完成，方法中调用过的每条 monitorenter 指令都有执行其对应 monitorexit 指令，而无论这个方法是正常结束还是异常结束。为了保证在方法异常完成时monitorenter 和 monitorexit 指令依然可以正确配对执行，编译器会自动产生一个异常处理器，这个异常处理器声明可处理所有的异常，它的目的 就是用来执行 monitorexit 指令。从字节码中也可以看出多了一个monitorexit指令，它就是异常结束时被执行的释放monitor 的指令。#### &gt;2. 同步方法```java public class SyncMethod &#123; public int i; public synchronized void syncTask()&#123; i++; &#125; &#125; javap -v 反编译查看字节码123456789101112131415161718192021222324252627282930313233343536373839404142Classfile /C:/Users/zll/Desktop/SyncMethod.class Last modified 2018-5-14; size 284 bytes MD5 checksum 01295dba4bbecdc08221daf4367aac4f Compiled from \"SyncMethod.java\"public class SyncMethod SourceFile: \"SyncMethod.java\" minor version: 0 major version: 51 flags: ACC_PUBLIC, ACC_SUPERConstant pool: &#123; public int i; flags: ACC_PUBLIC //省略没必要的字节码 //==================syncTask方法====================== public SyncMethod(); flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return LineNumberTable: line 1: 0 public synchronized void syncTask(); //方法标识ACC_PUBLIC代表public修饰，ACC_SYNCHRONIZED指明该方法为同步方法 flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #2 // Field i:I 5: iconst_1 6: iadd 7: putfield #2 // Field i:I 10: return LineNumberTable: line 6: 0 line 7: 10&#125; 方法的同步并没有通过指令monitorenter和monitorexit来完成（理论上其实也可以通过这两条指令来实现），不过相对于普通方法，其常量池中多了ACC_SYNCHRONIZED标示符。JVM就是根据该标示符来实现方法的同步的：当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。 其实本质上没有区别，只是方法的同步是一种隐式的方式来实现，无需通过字节码来完成。 相对于volatile来讲，synchronized关键字提供了原子操作，禁止重排序，保证内存一致性的语义。其中同步代码块通过monitorenter和monitorexit指令来实现，同步方法通过方法区的acc_synchronized标示来判断方法是否需要同步操作，如果为非静态方法（没有ACC_STATIC标志），使用调用该方法的对象作为锁对象；如果为静态方法（有ACC_STATIC标志），使用该方法所属的Class类在JVM的内部对象表示Klass作为锁对象，锁的处理是隐式的。 虚拟机对synchronized的优化jdk1.6后针对synchronized做了很多优化，包含偏向锁、自旋锁、轻量级锁、重量级锁，针对不同的场景采用不同的锁。 自旋锁由于线程阻塞后进入阻塞队列和从阻塞队列中的唤醒都需要CPU在内核态和用户态之间切换，花费时间太多，尤其是竞争激烈的情况下。统计发现很多线程持有锁的时间是较短的，如果这时候在内核态和用户态之间来回切换太费时间了。于是引入了自旋锁，所谓自旋锁就是对于等待的线程，不先加到等待队列中，而是去执行一个无意义的循环，一直到运行的线程结束之后去竞争锁。但是明显自旋锁使得synchronized的对象锁方式在线程之间引入了不公平，而且CPU在等待自旋锁时不做任何有用的工作，仅仅是等待，浪费资源，但是这样可以保证大吞吐率和执行效率。但是由于CPU的自旋消耗比较大，因此自旋是有范围的，超过这个范围就会进入排队队列，即重量级锁的机制。自适应自旋锁，就是自旋的次数是通过JVM在运行时收集的统计信息，动态调整自旋锁的自旋次数上界。 偏向锁jvm的设计者发现在大都数的情况下，都不存在锁竞争，而且总是相同的线程再次的获取锁，为此引入了偏向锁。在无竞争的情况下，只需要简单的CAS操作设置对象头信息即可。 加锁 当同步块的对象头处于无锁状态时，把对象头中的标示为设置为“01”，即偏向锁模式，同时使用CAS操作将Mark Word中的偏向线程ID设置为当前线程。 操作成功后持有偏向锁的线程以后每次进入这锁相关的同步块时，直接检查ThreadId是否和当前线程一致。 如果一致，那么表示线程已经获取了锁，那么直接执行同步代码块，不需要加锁。 如果不一致，那么表示存在竞争。此时需要判断对象头状态，如果此时是无锁状态，则执行第一步加锁过程，如果仍是偏向锁状态，那么转化为轻量锁。 解锁 线程不会主动去释放偏向锁，需要等到全局安全点(在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。 轻量级锁 加锁流程： 线程在执行同步块之前，JVM会在当前线程的栈帧中创建用于存储锁记录的空间，并把对象头中的Mark Word复制到锁记录空间中，官方称为Displaced Mark Word，然后线程尝试持有CAS把对象头中的Mark Word替换成指向锁记录的指针，如果成功，当前线程获得锁，如果失败表示有其他线程竞争锁，当前线程尝试使用自旋来获取锁，获取失败就升级成重量级锁。 解锁流程： 会使用CAS操作来把Displaced Mark Word替换回对象头，如果成功表示没有竞争发生，如果失败，升级成重量级锁。 不同锁的优缺点&amp;适用场景","tags":[{"name":"Lock","slug":"Lock","permalink":"https://cnkeep.github.io/tags/Lock/"}]},{"title":"并发中的关键性问题及解决思路","date":"2017-11-20T17:05:00.000Z","path":"2017/11/21/01-并发中的关键性问题及解决思路/","text":"并发中的关键性问题及解决思路目录 前言并发问题的来源 内存模型 线程通信模型 指令重排序 要解决的问题解决之道 前言 作为一个java程序员，无论是面试还是工作中，毫无例外的都需要用到多线程编程，尤其是多线程的并发问题更是考量一个优秀程序员的重要方面。各位java同胞可能有的只是会使用多线程编程(本人级别)，有的写得一手多线程并发代码，更有甚者对并发问题的原理有深入的了解，我想大家都想做第三类人，毕竟层面越高越多金.Are you ready? 并发问题的来源 既然要说并发问题的来源，那我们得先了解一下计算机执行的细节，我们从虚拟机的内存模型和线程通信模型、指令重排序入手。 内存模型 上面的图就是JVM逻辑上的内存模型(当然真正的实现是一些内存，缓存，寄存器之间的相互操作，但是作为上层的程序员，这太底层了，于是将这些进行了抽象（让你抽象,哒哒哒…..）,便于我们理解原理)，我们就不介绍每个部分的作用，只做一个简单的介绍： 线程共享：方法区、堆 线程私有：虚拟机栈、本地方法栈、程序计数器 线程通信模型 计算机所有的操作都是通过指令执行完成的，而指令的执行依赖于CPU, 但是CPU是一个雷厉风行的家伙，做事效率很高，但是碍于自己的处理速度和内存的读写速度不在一个数量级上，就像程序访问数据库一样，我的程序跑的很溜，数据库太慢，操作一次太慢，怎么办？ 好办，上缓存！对，用缓存，CPU也有自己的一二三级缓存。抽象到java上就是每个线程都有自己的工作内存，工作内存中包含主内存的副本，线程操作自己的副本，在合适的时候将副本写会到主存让其他的线程都知道。 我们看到线程的执行模型，当线程A和线程B共享同一份数据时，就需要两者之间通过主内存通讯，这需要以下几步： 1.线程A修改自己的工作内存中的副本，线程A将工作内存中的副本更新到主内存 2.通知线程B更新工作内存副本至最新 3.线程B操作副本，并将工作内存中的副本更新到主内存 这样看着好像没有什么问题，但是我们要知道第2步操作什么时候执行不确定。考虑这样的情形,当线程A修改完数据后，线程B获取到的值不是最新的，因为这时候可能线程A的工作内存中的副本还没更新到主内存，线程B从主内存读取的数据可能还是旧值。这时候问题就出现了,线程B操作的是旧值，最后再更新回主内存，这样数据就出错了。那么问题出在哪里呢？出在第二步，我们需要一个通讯机制来告诉其他线程数据已经更新,即保证内存的一致性。 指令重排序处理器和编译器为了提高程序的并行性，在不改变程序执行结果的前提下，在不改变单线程（注意是单线程）执行结果的情况下，编译器和处理器可以重新安排语句的执行顺序。然而这个却为多线程带来了问题，因为重排序只保证单线程语义不变，却不保证多线程，我们举个例子看看： public class ThreadTest{ private boolean canRead = false; private List&lt;Integer&gt; memory = new java.util.ArrayList&lt;&gt;(1); private void read(){ if(canRead){//step4 Integer num = memory.remove(0);//step5 System.out.println(num); canRead = false;//step6 } } private void write(){ if(!canRead){//step1 memory.add(0);//step2 canRead = true;//step3 } } public static void main(String[] args){ final ThreadTest threadTest = new ThreadTest(); new Thread(()-&gt;{ threadTest.write(); },\"Write\").start(); new Thread(()-&gt;{ threadTest.read(); },\"Read\").start(); } } 上面的程序模拟内存的操作，一个线程完成写内存，一个线程完成读内存的操作，那么重排序会导致什么问题呢，来分析一下。 理想的执行流程： step1 -&gt; step2 -&gt; step3 -&gt; step4 -&gt; step5 -&gt; step6 根据重排序的原则，单线程下不影响结果的语句都可以进行重排序,那么step2和step3可以重排序，再加上多线程cpu执行权限的切换，多线程下就出现了这样的执行流程： step1 -&gt; step3 -&gt; step4 -&gt; step5 -&gt; step6 -&gt; step2 问题出现了，当执行step4时就抛错了。如何解决这个问题我想我们很容易就想到：禁止重排序，但是禁止重排序问题就解决了吗，没有！为什么因为多线程并发执行 时机不确定，只有原子的操作禁止重排序才能保证执行准确，所以只要保证read和write都是原子操作就可以了，这就是并发要解决的同步问题。 要解决的问题 经过上面的了解我们对并发要解决的问题有了了解。我们总结一下并发要解决的问题： 线程之间如何通信 —— 线程之间如何交换信息,保证内存可见性 线程之间如何同步 —— 控制线程的相对执行顺序，保证原子性 两种解决思路： 隐式通信，显示同步 —— 线程之间通过共享内存中的公共状态来隐式通信，那么就必须显示的指定线程见的互斥来实现同步 显式通信，隐式同步 —— 线程之间无公共状态，通过明确的发送消息进行通信，那么由于消息的发送在消息接收之前，就可以实现隐式的同步 Java选择了共享内存的方式来解决并发中的两个关键问题，因此Java中线程的通信是隐式的，对程序员透明，但需要程序员自己来控制线程的同步，如使用互斥锁等。 解决之道 上面我们已经了解到并发要解决的两个问题(同步+通讯)，实际上分为三个点：原子性，内存一致性，顺序性。那我们有没有方法去解决或者避免这些问题呢，答案是有的！ 值得庆幸的是：jvm为了解决多线程并发的问题，为我们开发者提供了Happens-before原则来保证了顺序性和内存一致性，我们只要在此基础上做文章即可。 happens-before规则： 单线程规则：同一个线程中的每个操作都happens-before于出现在其后的任何一个操作。 对一个监视器的解锁操作happens-before于每一个后续对同一个监视器的加锁操作。 对volatile字段的写入操作happens-before于每一个后续的对同一个volatile字段的读操作。 Thread.start()的调用操作会happens-before于启动线程里面的操作。 一个线程中的所有操作都happens-before于其他线程成功返回在该线程上的join()调用后的所有操作。 一个对象构造函数的结束操作happens-before与该对象的finalizer的开始操作。 传递性规则：如果A操作happens-before于B操作，而B操作happens-before与C操作，那么A动作happens-before于C操作。 编写线程安全的代码，我们可以在此基础上使用volatile,synchronized,其他锁来满足需求 总结 并发就是要解决线程通信和同步的问题，即保证内存一致性和原子操作，我们可以依托happens-before原则，通过volatile和锁机制来完成。","tags":[{"name":"Lock","slug":"Lock","permalink":"https://cnkeep.github.io/tags/Lock/"}]},{"title":"AQS","date":"2017-11-20T14:28:00.000Z","path":"2017/11/20/AQS/","text":"AQS AQS -&gt; ReentrantLock -&gt; Condition -&gt; Lock -&gt; ThreadAQS&nbsp;、CAS What it is? AQS(AbstactQueueSynchronizer):抽象的队列式同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock/Semaphore/CountDownLatch…12345### How does it works?&gt; ![figure-01](images/aqs-1.png) *入口acquire(int args); public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } 1&gt;我们把这个方法拆分来看 public final void acquire(int arg) { /** 尝试去独占资源，此方法由子类实现**/ boolean fastAcquire = tryAcquire(args); /**尝试独占资源失败**/ if(!fastAcquire){ /**将当前线程包装成新节点，并且插入到等待队列的队尾，并返回当前线程所在的结点**/ Node node = addWaiter(Node.EXCLUSIVE); /**当前线程进入等待状态，ps:有可能在此过程中独占资源成功，返回是否在过程中存在中断**/ boolean acquireQueued = acquireQueued(node,arg); /**响应中断**/ if(acquireQueued){ selfInterrupt(); } } } /** * 再来细细看一下将当前线程加入到等待队列的过程 */ private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); /** 先尝试去添加一次（本地CAS操作）， * 1.成功则返回当前节点; * 2.失败则利用CAS操作设置直至成功 */ Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } enq(node); return node; } /** * 可以看到enq就是典型的CAS操作 */ private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } /** * 在队列中休眠等待，CAS操作直到获取锁了才返回 */ final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor();//获取前驱节点 /**前驱节点是头结点，尝试独占资源，（被唤醒或者中断导致）**/ if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } /**检查是否需要被阻塞 * 1：前一个节点设置了自身获得资源时唤醒后继节点； * 2：之前的节点有的节点放弃了获取，则找到最近的一个设置了获取资源会唤醒后继节点的节点，然后将当前节点追加到其后。 */ if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) //parkAndCheckInterrupt():检查线程是否发生了中断，这里会清除中断标示位，所以需要selfInterrupt():让当前线程自己产生一个中断。 interrupted = true; } } finally { if (failed) cancelAcquire(node); } } // 返回“当前线程是否应该阻塞” private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { // 前继节点的状态 int ws = pred.waitStatus; // 如果前继节点是SIGNAL状态，则意味这当前线程需要被unpark唤醒。此时，返回true。 if (ws == Node.SIGNAL) return true; // 如果前继节点是“取消”状态，则设置 “当前节点”的 “当前前继节点” 为 “‘原前继节点’的前继节点”。 if (ws &gt; 0) { do { node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { // 如果前继节点为“0”或者“共享锁”状态，则设置前继节点为SIGNAL状态。 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; } ` LockSupport：此类与wait()和notify()操作线程的挂起和唤醒功能相同，不同的是它不需要像wait和notify要写在同步代码块内。它是并发包下的一个工具，依托于Unsafe类完成线程阻塞和唤醒的功能Unsafe：java提供的访问系统底层硬件的工具，其中最常用的就是CAS、线程的阻塞和唤醒 转载：Java中CAS详解转载：Java并发之AQS详解转载：java并发包系列—LockSupport","tags":[{"name":"Lock","slug":"Lock","permalink":"https://cnkeep.github.io/tags/Lock/"}]},{"title":"线程池介绍","date":"2017-11-03T11:22:00.000Z","path":"2017/11/03/01-线程池介绍/","text":"线程池介绍 当我们进行程序设计时，为了充分发挥多核计算机的计算能力，经常会使用多线程来异步执行任务，但是如果不加控制，反而会对系统造成负担。线程本身需要占内存空间， 线程之间相互切换也需要消耗资源，线程的创建和销毁都会给系统造成负担。所以线程属于珍贵资源。为了避免重复的创建和销毁线程，产生了线程池，当需要处理任务时 从池中获取一个线程执行，当工作完成后，并不直接关闭线程，而是将这个线程归还给线程池供其他任务使用。 线程池的架构 接口：Executor,CompletionService,ExecutorService，ScheduledExecutorService抽象类：AbstractExecutorService实现类：ExecutorCompletionService，ThreadPoolExecutor，ScheduledThreadPoolExecutor工具类：Executors(根据阿里开发者规约，不推荐使用这种屏蔽了重要参数的使用方式) 线程池的分类常见的几种线程池都包含在Executors工具类。 可回收的线程池(cachedThreadPool)创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 这种线程池的特点： 工作线程的创建数量几乎没有限制(其实也有限制的,数目为Interger. MAX_VALUE), 这样可灵活的往线程池中添加线程。 如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间(默认为1分钟)，则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重新创建一个工作线程。 在使用CachedThreadPool时，一定要注意控制任务的数量，否则，由于大量线程同时运行，很有会造成系统瘫痪。 固定线程数线程池(fixedThreadPool)创建一个指定工作线程数量的线程池。每当提交一个任务就创建一个工作线程，如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到池队列中。 单线程线程池(singleThreadPool)只创建唯一的工作者线程来执行任务，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。如果这个线程异常结束，会有另一个取代它，保证顺序执行。单工作线程最大的特点是可保证顺序地执行各个任务，并且在任意给定的时间不会有多个线程是活动的。 定时线程池(ScheduleThreadPool)一个定长的线程池，而且支持定时的以及周期性的任务执行，支持定时及周期性任务执行. 使用123456789101112131415161718192021222324252627import java.util.concurrent.*;public class ThreadPoolTest&#123; public static void main(String[] args)&#123; final AtomicLong threadCount = new AtomicLong(0); ThreadFactory threadFactory = (runnable)-&gt; &#123; Thread thread = new Thread(runnable,\"Thread-\"+threadCount.getAndIncrement()); return thread; &#125;; int availableProcessors = Runtime.getRuntime().availableProcessors(); ThreadPoolExecutor poolExecutor = new ThreadPoolExecutor(availableProcessors, availableProcessors, 0, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory, new AbortPolicy()); final int taskCount = 10; for(int i = 0; i &lt; taskCount; i++) &#123; poolExecutor.execute(()-&gt;&#123; System.out.println(\"do task!\"); &#125;); &#125; poolExecutor.shutdown(); &#125;&#125;","tags":[{"name":"ThreadPool","slug":"ThreadPool","permalink":"https://cnkeep.github.io/tags/ThreadPool/"}]},{"title":"线程池解析","date":"2017-11-02T13:24:00.000Z","path":"2017/11/02/02-线程池解析/","text":"线程池解析前言上一节介绍了线程池的使用场景以及分类，这一节来分析线程池是如何工作的。 线程池原理线程池的状态在分析线程池的原理之前我们先来看看线程池有哪几种状态。 如上图所示线程池共有5种状态，这四种状态之间相互转化，从而控制任务的执行。 running线程池处在RUNNING状态时，能够接收新任务，以及对已添加的任务进行处理,线程池被一旦被创建，就处于RUNNING状态，并且线程池中的任务数为0。 shutdown线程池处在SHUTDOWN状态时，不接收新任务，但能处理已添加的任务。 调用线程池的shutdown()接口时，线程池由RUNNING -&gt; SHUTDOWN。 stop线程池处在STOP状态时，不接收新任务，不处理已添加的任务，并且会中断正在处理的任务。调用线程池的shutdownNow()接口时，线程池由(RUNNING or SHUTDOWN ) -&gt; STOP。 tidying当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现。当线程池在SHUTDOWN状态下，阻塞队列为空并且线程池中执行的任务也为空时，就会由 SHUTDOWN -&gt; TIDYING。当线程池在STOP状态下，线程池中执行的任务为空时，就会由STOP -&gt; TIDYING。 terminate线程池彻底终止，就变成TERMINATED状态。 线程池处在TIDYING状态时，执行完terminated()之后，就会由 TIDYING -&gt; TERMINATED。 线程池采用3个bit位来代表线程池状态，28个bit位表示线程池的线程数12345678910private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;// runState is stored in the high-order bitsprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; 线程池的参数构造一个线程池需要7个参数，如下：123456789public ThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 各个参数的含义如下： 参数名 参数作用 corePoolSize 核心线程数 maximumPoolSizes 最大线程数 keepAliveTime 空闲线程过多久被回收的时间限制 unit keepAliveTime 的时间单位 workQueue 阻塞任务队列 threadFactory 创建线程的线程工厂 RejectedExecutionHandler 当线程池不能处理任务时的拒绝策略 执行流程 任务被提交到线程池，先判断当前线程数是否小于corePoolSize，如果小于则创建线程来 执行提交的任务，否则将任务放入workQueue队列中，如果workQueue满了，则判断当前线程数量是否小于MaxPoolSize，如果小于则创建线程执行任务，否则就调用 rejectHandler，拒绝相应的任务。 执行流程可以通过execute方法看到：12345678910111213141516171819202122//获取当前线程数int c = ctl.get();if (workerCountOf(c) &lt; corePoolSize) &#123; //当前线程数小于核心线程数，则新建线程,返回 if (addWorker(command, true)) return; c = ctl.get();&#125;//任务添加至任务队列if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false);&#125;//任务队列已满，添加失败，则尝试新建线程，线程数小于maxPoolSizeelse if (!addWorker(command, false)) //创建失败，执行拒绝策略 reject(command); 添加工作线程(addWorker)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // 判断当前线程池状态是否支持继续执行任务 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); //判断当前线程数是否超载 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; &#125; &#125; //创建工作线程，并启动 boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; 工作线程执行(runWorker)123public void run() &#123; runWorker(this);&#125; 上一步我们看到，添加工作线程后就启动了线程，而线程的run方法调用的是runWorker方法，来看看这个方法的执行逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; //从阻塞队列中后去任务 while (task != null || (task = getTask()) != null) &#123; w.lock(); // 响应中断 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; //执行任务 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125; &#125; 我们看到其类似于生产消费者模型，worker线程作为消费者，死循环从队列中获取任务执行, 而控制线程池状态从而让工作线程终止，超时回收正是通过getTask来实现的(getTask返回null即退出)。 获取任务(getTask)123456789101112131415161718192021222324252627282930313233343536373839404142private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // 判断线程池状态， // stop：退出, stop状态会将任务列表返回； // shutdown+任务队列为空：退出，shutdown状态会执行完所有任务在退出； if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // 是否配置了超时回收空闲线程 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; //线程数超载或者空闲线程到达超时时间，返回null, 工作线程终止循环退出 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; //case1: 配置了空闲线程超时回收，利用超时时间去任务队列获取任务，获取不到即表示当前无任务执行，可以返回，回收线程 //case2: 没有配置空闲线程回收，则阻塞直到获取到任务 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125; &#125; 如果程池状态为stop或者(shutdown+任务队列为空)则返回null, runWorker循环将推出，从而工作线程终止回收。 如果配置了空闲线程超时回收，利用超时时间去任务队列获取任务，获取不到即表示当前无任务执行，可以返回，回收线程 如果没有配置空闲线程回收，则阻塞直到获取到任务 提交任务提交任务到线程池主要有2类方法： execute方法无返回值，不关注任务返回值，执行状态时使用。 submit通过返回Future对象可以控制任务的执行状态和执行结果。 关闭线程池优雅关闭线程池有2种方式： shutDown()该方法关闭线程池后，线程池进入shutdown状态，新的任务不能提交，正在执行的任务和任务队列中等待执行的任务会继续执行，等这些任务完全执行完成后进入terminate状态。 shutDownNow()该方法关闭线程池后，线程池进入stop状态，新的任务不能提交，正在执行的任务会继续执行，任务队列中等待执行的任务不会执行将直接作为返回值返回，等任务完全执行完成后进入terminate状态。 需要强调一点的是，调用完shutdownNow和shuwdown⽅法后，并不代表线程池已经完成关闭操作，它只是异步的通知线程池进行关闭处理。如果要同步等待线程池彻底关闭后才继续往下执行，需要调⽤awaitTermination⽅法进⾏同步等待。 线程池的监控通过线程池提供的参数进行监控。线程池里有一些属性在监控线程池的时候可以使用 taskCount：线程池需要执行的任务数量。 completedTaskCount：线程池在运行过程中已完成的任务数量。小于或等于taskCount。 largestPoolSize：线程池曾经创建过的最大线程数量。通过这个数据可以知道线程池是否满过。如等于线程池的最大大小，则表示线程池曾经满了。 getPoolSize:线程池的线程数量。如果线程池不销毁的话，池里的线程不会自动销毁，所以这个大小只增不减。 getActiveCount：获取活动的线程数。 通过扩展线程池进行监控。通过继承线程池并重写线程池的beforeExecute，afterExecute和terminated方法，我们可以在任务执行前，执行后和线程池关闭前干一些事情。如监控任务的平均执行时间，最大执行时间和最小执行时间等。这几个方法在线程池里是空方法。如：","tags":[{"name":"ThreadPool","slug":"ThreadPool","permalink":"https://cnkeep.github.io/tags/ThreadPool/"}]},{"title":"类加载机制","date":"2017-10-14T15:04:00.000Z","path":"2017/10/14/02-类加载机制/","text":"类加载机制 日期:2018/12/14 &nbsp;&nbsp;转载：Java 类加载机制(阿里面试题)-何时初始化类转载：深入理解Java类加载器(ClassLoader)标签: JAVA基础, ClassLoader, 类加载 【目录】 什么是类加载器类加载器与类的”相同”判断类加载器种类双亲委派模型类加载过程 什么是类加载器&nbsp;&nbsp;Java类加载器（Java Classloader）是Java运行时环境（Java Runtime Environment）的一部分，负责动态加载Java类到Java虚拟机的内存空间中，即读取Java字节码，并转换成Class对象的一个工具。 类加载器与类的”相同”判断&nbsp;&nbsp;类加载器除了用于加载类外，还可以用来确定类在Java虚拟机中的唯一性。即便是同样的字节代码，被不同的类加载器加载之后所得到的的类，也是不同的。可以使用，isAssignableFrom, isInstance, instanceof判断。 类加载器种类 启动类加载器(Bootstrap ClassLoader) &nbsp;&nbsp;启动类加载器主要加载的是JVM自身需要的类，这个类加载使用C++语言实现的，是虚拟机自身的一部分，他负责将&lt;JAVA_HOME&gt;/lib路径下的核心类库或者-Xbootclasspath参数指定的路径下的jar加载到内存中，注意由于虚拟机是按照文件名识别加载jar包的，如rt.jar，如果文件名不被虚拟机识别，即使把jar包丢到lib目录下也是没有作用的(出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类)。 扩展类加载器(Extension) &nbsp;&nbsp;扩展类加载器是指Sun公司(已被Oracle收购)实现的sun.misc.Launcher$ExtClassLoader类，由Java语言实现的，是Launcher的静态内部类，它负责加载&lt;JAVA_HOME&gt;/lib/ext目录下或者由系统变量-Djava.ext.dir指定位路径中的类库，开发者可以直接使用标准扩展类加载器. 系统类加载器(System) &nbsp;&nbsp;也称应用程序加载器，负责加载系统类路径java -classpath或者-D java.class.path指定路径下的类库。Java虚拟机对class文件采用的是按需加载的方式，也就是说当需要使用该类时才会将它的class文件加载到内存生成class对象，而且加载某个类的class文件时，Java虚拟机采用的是双亲委派模式即把请求交由父类处理，它一种任务委派模式。 双亲委派模型工作原理 双亲委派模式要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器，请注意双亲委派模式中的父子关系并非通常所说的类继承关系，而是采用组合关系来复用父类加载器的相关代码，类加载器间的关系如下： &nbsp;&nbsp;如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，一次递归，请求最终将到达顶层的启动类加载器，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载。 优势 保护核心包的安全，无法被覆盖加载 类加载过程 加载 类加载过程的一个阶段：通过一个类的完全限定查找此类字节码文件，并利用字节码文件创建一个Class对象，同一个类加载器已经加载过的Class不会被二次加载 验证 目的在于确保Class文件的字节流中包含信息符合当前虚拟机要求，不会危害虚拟机自身安全。主要包括四种验证，文件格式验证，元数据验证，字节码验证，符号引用验证。 准备 为类变量(即static修饰的字段变量)分配内存并且设置该类变量的初始值即0(如static int i=5;这里只将i初始化为0，至于5的值将在初始化时赋值)，这里不包含用final修饰的static，因为final在编译的时候就会分配了，注意这里不会为实例变量分配初始化，类变量会分配在方法区中，而实例变量是会随着对象一起分配到Java堆中。 解析 主要将常量池中的符号引用替换为直接引用的过程。符号引用就是一组符号来描述目标，可以是任何字面量，而直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。有类或接口的解析，字段解析，类方法解析，接口方法解析(这里涉及到字节码变量的引用，如需更详细了解，可参考《深入Java虚拟机》)。 初始化 类加载最后阶段，若该类具有超类，则对其进行初始化，执行静态初始化器和静态初始化成员变量(如前面只初始化了默认值的static变量将会在这个阶段赋值，成员变量也将被初始化)。 类加载的时机什么情况下虚拟机会初始化加载一个类呢？在虚拟机规范中这是有严格的规定的，虚拟机有且只有以下五种情况才会发生类加载： 遇到new, getstatic, putstatic或者invokestatic这个四条字节码指令，数组触发的只是数组类型本身的初始化，例如 new String[],只会触发String[]类的初始化，也就是[Ljava.lang.String的初始化，而不是直接触发String类的初始化。 使用new关键字实例化对象的时候； 读取或者设置一个类的静态字段(被final修饰，已在编译器把结果放入常量池的静态字段除外)的时候； 调用一个类的静态方法的时候； 使用反射调用时，如果类没有被初始化过，则需要触发加载初始化 当虚拟机启动时，用户需要指定一个要执行的主类(包含main()方法的类)，虚拟机会先初始化这个主类。 以下情况不会发生类加载： 通过子类引用父类的静态字段，不会导致子类加载 123456789101112131415161718192021public class SuperClass&#123; static &#123; System.out.println(\"super class load\"); &#125; public static int num = 0;&#125;public class SubClass extends SuperClass&#123; static &#123; System.out.println(\"sub class load\"); &#125;&#125;public class TestDemo&#123; public static void main(String[] args)&#123; System.out.println(SubClass.num); /*** * super class load */ &#125;&#125; 通过数组定义来引用类，不会触发此类的初始化 12345public class TestDemo&#123; public static void main(String[] args)&#123; SubClass[] arr = new SubClass[10]; &#125;&#125; 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化 12345678910111213141516public class ConstClass&#123; static&#123; System.out.println(\"ConstClass init!\"); &#125; public static final String CONSTANT = \"hello world\"; &#125; public class TestDemo&#123; public static void main(String[] args)&#123; System.out.println(ConstClass.CONSTANT); /** Output: * hello world */ &#125; &#125;","tags":[{"name":"Java","slug":"Java","permalink":"https://cnkeep.github.io/tags/Java/"}]},{"title":"重载和重写","date":"2017-10-14T12:40:00.000Z","path":"2017/10/14/03-重载和重写/","text":"方法的重载和重写 注：本文为记录笔记，如有错误，欢迎留言讨论。 由JAVA基础特性产生的遐想 &nbsp;&nbsp;学习JAVA入门时，我们就知道Java的三大特性：封装,继承, 多态。 为了切入今天的主题，我们就来讲讲多态。多态分为：静态绑定和动态绑定，分别对应重载和重写。 overload重载 &nbsp;&nbsp;重载是指同一个类中存在方法名相同，参数列表不同的方法。123456789101112131415161718192021222324252627282930313233343536public class OverloadDemo&#123; public int methodA(int a,String str)throws Exception&#123; return 0; &#125; /** * 访问控制符改变，不属于重载，编译不通过 */ private int methodA(int a,String str)throws RuntimeException&#123; return 0; &#125; /** * 返回类型改变，不属于重载，编译不通过 */ public String methodA(int a,String str)throws RuntimeException&#123; return \"\"; &#125; /** * 抛出异常改变，不属于重载，编译不通过 */ public String methodA(int a,String str)throws NullPointerException&#123; return \"\"; &#125; /** * 参数列表发生该表，属于重载 */ public int methodA(int a,String str,int b)&#123; return 0; &#125; public static void main(String[] args)&#123; OverloadDemo demo = new OverloadDemo(); demo.methodA(0,\"hello\"); demo.methodA(0,\"hello\",0); &#125;&#125; 通过例子我们看到重载有以下特点： 发生在同一个类中 方法名必须相同 参数列表必须不同（包括参数类型，顺序，个数） 其他修饰符可以相同，也可以不同 可以抛出不同异常 返回类型可以不同 我们常见的重载就是构造函数的重载了 override重写 我们经常讲面向接口编程，编写接口，提供不同的实现，即子类对象指向父类引用，子类实现或者覆盖父类的方法就叫做重写。1234567891011121314151617class Animal&#123; public void eat()&#123; System.out.println(\"animal eat\"); &#125;&#125;class Dog implements Animal&#123; @Override public void eat()&#123; System.out.println(\"dog is eating.\"); &#125;&#125;public class OverrideDemo&#123; public static void main(String[] args)&#123; Animal animal = new Dog(); animal.eat(); &#125; &#125; 上面的例子当我执行时最终调用的是子类的eat方法。方法重写有如下的特点： 发生在两个存在父子关系的类中 方法名、参数列表、返回值类型都必须相同 访问修饰符必须大于或等于被重写的方法 重写的方法中，不能抛出新的异常或被重写的方法更多、更大的异常，但一定会抛出异常。也就是说，只能抛出相同的异常或是被重写方法异常的子异常，还可以抛出非编译异常(RuntimeException) 重写方法只会存在于具有继承关系的子类中，而当父类中的方法用private修饰时，即使子类中有重名方法，也不叫方法的重写 非静态方法不能被重写成静态方法","tags":[{"name":"Java","slug":"Java","permalink":"https://cnkeep.github.io/tags/Java/"}]},{"title":"异常机制","date":"2017-10-13T16:42:00.000Z","path":"2017/10/14/01-异常机制/","text":"异常机制 日期:2018/12/13 &nbsp;&nbsp; 转载：https://blog.csdn.net/hl_java/article/details/76837141标签: JAVA基础, Exception 前言没有完美的程序，程序总有可能出错，发生异常，那java中的异常机制是什么样的，本次我们就来了解一下。 异常机制先了解一下异常的类层次结构： 所有的异常都继承自Throwable, 其子类又分为2个大类：Error, Exeption。 Error &nbsp;&nbsp;程序无法处理的错误，表示应用程序中较严重的问题，例如，Java虚拟机运行错误（Virtual MachineError），当 JVM 不再有继续执行操作所需的内存资源时，将出现 OutOfMemoryError。这些异常发生时，Java虚拟机（JVM）一般会选择线程终止。这些错误表示故障发生于虚拟机自身、或者发生在虚拟机试图执行应用时，如Java虚拟机运行错误（Virtual MachineError）、类定义错误（NoClassDefFoundError）等。这些错误是不可查的，因为它们在应用程序的控制和处理能力之 外，而且绝大多数是程序运行时不允许出现的状况。对于设计合理的应用程序来说，即使确实发生了错误，本质上也不应该试图去处理它所引起的异常状况。在 Java中，错误通过Error的子类描述。 Exception &nbsp;&nbsp;是程序本身可以处理的异常，包含：checked exception(检查异常), unchecked exception(非检查异常): unchecked exception(非检查异常): 也叫运行时异常，例如常见的：NullPointerException, IndexOutOfBoundsException.对于这种异常，编译器不要求必须进行捕获(catch), 由程序员自行决定。 checked exception(检查异常): 非运行时异常，可能导致程序崩溃，编译器强制要求必须进行捕获，例如常见的IOException, SQLException,不进行捕获，程序编译时都无法通过。 异常机制的应用异常处理 针对可能出现的异常进行捕获处理123456789101112131415161718192021222324252627282930313233343536public class LoginController&#123; //service层，这里省却 private LoginService loginService; public JsonResp login(String userName,String password)&#123; try&#123; loginService.login(userName,password); &#125;catch (org.apache.shiro.authc.AccountException e)&#123; //账号状态yic &#125;catch(Exception e)&#123; //登录失败 &#125; &#125;&#125;``` ### 异常抛掷上层处理&gt; 自己不处理异常，当时声明自身可能发生的异常，并抛出异常至上层处理 ```java/*** * 声明抛出异常*/public void login(String userName,String password)throws AccountException&#123; //业务代码&#125;/*** 转换为自定义异常*/public void login(String userName,String password)throws MyException&#123; try&#123; //业务代码 &#125;catch(Exception e)&#123; throw new MyException(e); &#125;&#125;","tags":[{"name":"Java","slug":"Java","permalink":"https://cnkeep.github.io/tags/Java/"}]},{"title":"看懂UML类图","date":"2017-10-04T13:31:00.000Z","path":"2017/10/04/看懂UML类图/","text":"看懂UML类图前言&nbsp;&nbsp;作为一个程序员，除了基础的编码工作外，经常还需要输出各种各样的文档，例如：接口说明，系统设计等。其中作为系统设计的一部分，UML类图能直观的表达出各个类之间的关系，尤为重要，那么UML类图中中的图形，线条都是什么意思呢，今天我们就来学习一下，会看然后再用。 从实例开始举个例子，一家公司，有好几个开发部门，每个开发部门有多个程序员，每个程序员都有自己的身份证，通过PC工作。其UMl类图如下： 在这其中包含了如下关系： 实现关系，例如Person继承了Entity接口，即接口实现，采用空心箭头表示 泛化关系，例如Programmer是Person中的一类，即子类继承，采用实心箭头表示 关联关系，例如Programmer与IdCard的关联关系，即作为成员变量，采用实线箭头表示 依赖关系，例如Programmer工作依赖于Computer,但是可以随便换电脑， 即作为参数依赖，采用虚线箭头表示 聚合关系，例如Programmer聚合在一起成了部门，但是部门散了，程序员还在，部分不完全依赖于全局，可单独存在，用空心菱形表示 组合关系，例如部门组合成了公司，当公司倒闭，部门也就不在了，部分依赖于全局的存在, 不能单独存在，用实心菱形表示","tags":[{"name":"UML","slug":"UML","permalink":"https://cnkeep.github.io/tags/UML/"}]},{"title":"多项目依赖加载同名Class的问题排查","date":"2017-09-14T15:26:00.000Z","path":"2017/09/14/01-多项目依赖加载同名Class的问题排查/","text":"01-多项目依赖加载同名Class的问题排查1.问题概要&nbsp;&nbsp;旧平台有一个用户导入的功能，是基于tomcat比较老了，现在要将这个接口做成独立服务以供外界调用。当我开始接手时，就在想选什么技术，照搬旧系统？ What the fuck! 那么旧的技术架构，那么繁重，还是webapps老式的tomcat war包哎，排查问题太复杂了，最终还是决定选用springboot,采用内置servlet容器去重新发布服务。&nbsp;&nbsp;终于代码写完了，本地eclipse跑通了，打包发布到虚拟机中测试，运行不了？？？？？ 明明有的方法，却报方法不存在的错误…… 问题排查 bug第一步，日志看一看 字面看是Mybatis报的错，SimpleUser类中没有set方法，跳转到代码中查看，该方法是存在的，怎么回事。 猜想：是不是重名了？ 全文检索SimpleUser看看 还真有重名了，再看看项目依赖结构： 发现自己的项目依赖了web-common模块，而web-common模块中存在重名的SimpleUser类, 而web-common模块中的该类确实没有set方法。怀疑：因为重名加载了web-common中的class 验证 通过在jvm启动参数中添加配置，使其打印类加载日志。(-XX:+TraceClassLoading或-verbose:class) 通过日志检索，发现果然是因为加载了web-common下的类导致的。 解决方案 既然已经知道是因为类加载导致的，那我们就强制指定前加载我们正确的类。 12345之前的脚本：java -d64 -XX:MaxPermSize=192M -Xms500M -Xmx1000M -XX:+HeapDumpOnOutOfMemoryError -cp conf/:lib/* Starter 2&gt;&amp;1 &amp;修改后的脚本：java -d64 -XX:MaxPermSize=192M -Xms500M -Xmx1000M -XX:+HeapDumpOnOutOfMemoryError -cp conf/:lib/web-importer.jar:/lib/web-common.jar:lib/* Starter 2&gt;&amp;1 &amp; 启动服务，查看类加载日志问题解决 知识回顾jvm的类加载采用双亲委托模型，一旦类被类加载器加载一次后就不会再加载第二次，一旦我们项目中出现重名的类，就有可能因为类加载器的问题，导致bug出现。 拓展疑问 问什么之前基于war包的tomcat部署方式没有出现过这种问题呢？ tomcat重写了自己的类加载器，加载顺序如下： $java_home/lib 目录下的java核心api $java_home/lib/ext 目录下的java扩展jar包 java -classpath/-Djava.class.path所指的目录下的类与jar包 $CATALINA_HOME/common目录下按照文件夹的顺序从上往下依次加载 $CATALINA_HOME/server目录下按照文件夹的顺序从上往下依次加载 $CATALINA_BASE/shared目录下按照文件夹的顺序从上往下依次加载 我们的项目路径/WEB-INF/classes下的class文件 我们的项目路径/WEB-INF/lib下的jar文件 而旧项目的重写类都在classes目录下，所以优先加载，就没有问题喽~~~","tags":[{"name":"Bugs","slug":"Bugs","permalink":"https://cnkeep.github.io/tags/Bugs/"}]},{"title":"bugs_catalog","date":"2017-09-12T17:38:00.000Z","path":"2017/09/13/00-bugs_catalog/","text":"bug记录分析集 记录遇到的各种bug, 以及解决方案 01-多项目依赖加载同名Class的问题排查","tags":[{"name":"Bugs","slug":"Bugs","permalink":"https://cnkeep.github.io/tags/Bugs/"}]},{"title":"widows连不通github","date":"2017-08-05T18:47:00.000Z","path":"2017/08/06/007-widows连不通github/","text":"window连不通github 标签：Git 前言最近家里换了宽带，发现从github来拉取代码一致报EOF错误，网上各种说法都试过，无济于事。突然想到，会不会我根本就ping不通，一试，果然如此，最后解决了这个问题，在这里记录一下。 正文github无法ping通12345678910C:\\Users\\zll&gt;ping github.com正在 Ping github.com [13.250.177.223] 具有 32 字节的数据:请求超时。请求超时。请求超时。请求超时。13.250.177.223 的 Ping 统计信息: 数据包: 已发送 = 4，已接收 = 0，丢失 = 4 (100% 丢失)， 查询github的ip，尝试是否可以连通这里推荐一个查询ip的工具网站通过此工具站查询github.com的对应ip，github有多个机房，这里多查询几次，取几个相对稳定的ip，即可。 配置本地DNS我本机是win10，配置host文件即可:C:\\Windows\\System32\\drivers\\etc\\hosts, 注意一定要以超级管理员的权限编辑。 添加域名映射：12345678192.30.253.113 github.com 192.30.252.131 github.com 185.31.16.185 github.global.ssl.fastly.net 74.125.237.1 dl-ssl.google.com 173.194.127.200 groups.google.com 192.30.252.131 github.com 185.31.16.185 github.global.ssl.fastly.net 74.125.128.95 ajax.googleapis.com 成功保存之后，再尝试ping就可以了。","tags":[{"name":"Tools","slug":"Tools","permalink":"https://cnkeep.github.io/tags/Tools/"}]},{"title":"idea安装lombok插件","date":"2017-08-05T16:55:00.000Z","path":"2017/08/06/005-idea安装lombok插件/","text":"idea安装lombok插件介绍 Lombok是一个可以通过简单的注解形式来帮助我们简化消除一些必须有但显得很臃肿的Java代码的工具，通过使用对应的注解，可以在编译源码的时候生成对应的方法。 官方地址:https://projectlombok.org/ github地址:https://github.com/rzwitserloot/lombok idea安装lombok插件尝试在线安装(本人操作失败) 尝试离线安装 获取资源包 https://github.com/mplushnikov/lombok-intellij-plugin/releases 或者 http://plugins.jetbrains.com/plugin/6317-lombok-plugin 下载对应的版本 安装 依次进入IDEA–&gt;Settings/Preferences–&gt;Plugins 选择install plugin from disk选中下载的插件，等待安装完成即可。 使用引入依赖&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.18&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; 使用在对应的累活方法上使用对应的注解即可 Lombok有哪些注解 @Setter @Getter @Data @Log(这是一个泛型注解，具体有很多种形式) @AllArgsConstructor @NoArgsConstructor @EqualsAndHashCode @NonNull @Cleanup @ToString @RequiredArgsConstructor @Value @SneakyThrows @Synchronized 官网介绍","tags":[{"name":"Tools","slug":"Tools","permalink":"https://cnkeep.github.io/tags/Tools/"}]},{"title":"idea快捷键","date":"2017-08-05T16:20:00.000Z","path":"2017/08/06/002-idea快捷键/","text":"Idea快捷键 激活 License Server: http://idea.iteblog.com/key.php 360打开 https://licensez.com/ 快捷键 切换工作空间： ctrl+alt+]/] 搜索类中的方法： ctrl+F12 搜索类： ctrl+N or 双击shift 替换： ctrl+R 全局搜索： ctrl+shift+R 格式化代码： ctrl+alt+L 移除不用的import: ctrl+alt+O 查看注释： ctrl+Q 提示： ctrl+shift+space,alt+/ 建议： alt+enter 调用层次： ctrl+H 重写、覆盖方法： ctrl+o 删除一行： ctrl+x 复制一行： ctrl+V/D 移动一行： alt+shift+up/down 快速surround by: ctrl+alt+T 大小写切换: ctrl+shift+U get/set: alt+insert 去除多余import: ctrl+alt+O 查看最近打开的文件: ctrl+E 自动补全分号，大括号: ctrl+shift+enter 查看方法的实现: ctrl+alt+B","tags":[{"name":"Tools","slug":"Tools","permalink":"https://cnkeep.github.io/tags/Tools/"}]},{"title":"XShell快捷键","date":"2017-08-05T14:46:00.000Z","path":"2017/08/05/006-XShell快捷键/","text":"XShell快捷键 清屏： ctrl+L 切换tab: ctrl+Tab 新建连接： ctrl+O 复制： ctrl+Insert 粘贴： shift+Insert","tags":[{"name":"Tools","slug":"Tools","permalink":"https://cnkeep.github.io/tags/Tools/"}]},{"title":"idea配置全局代码注释模板","date":"2017-08-05T14:45:00.000Z","path":"2017/08/05/001-idea配置全局代码注释模板/","text":"idea设置全局注释模板 作为程序员代码要与代码规范，规范中必不可少的就是代码注释了，但是每次都手敲太麻烦，今天我们就来看看如何利用idea来配置自动生成代码注释。 配置新建class时自动生成注释 1.进入setting设置，搜索template关键词，出现下面俩个选项，就是我们要操作的功能： 2.选中File and Code Template, 在右侧Files页面菜单下，找到Class, Interface, Enum, AnnotationType(idea支持直接检索) 3.在最右侧的编辑区，填写需要的注释格式，也可以添加相关变量。 4.新建Class文件，就会发现自动生成了代码注释。 配置快捷键自动生成注释&nbsp;&nbsp;上面的方式只会在新建的Class文件中自动添加注释，但是对已经存在的文件无能为了，需要问么手动添加，我们可以采用全局替换去实现，但是，这里我提供一种快捷键的方式，在引申到自动生成Logger代码段上。 1.进入setting设置，搜索template关键词 2.选中Live Templates 3.点击右侧加号，添加我们自定义的快捷操作： 4.选中Template Group,新建custom分组，再新建Live Template 5.配置相关规则 Abbreviation:填写我们的匹配触发规则，这里填写了/**,即但我们键盘输入/**时会触发生成注释； Description:填写说明，便于查看具体功能； Teamplate Text:填写具体的生成规则 6.配置应用的对象，我么选择最下面的No applicable contexts yet. Define, 选择java 7.Class文件中输入/**然后按Tab键就会生成注释。 配置自动生成Logger对象&nbsp;&nbsp;我们编写业务代码经常要记录日志，每个类中都要写Logger属性，能不能手动生成呢？ 可以的，利用快捷操作，就行输入sout自动生成打印语句一样。 1.进入setting设置，搜索template关键词 2.选中Live Templates 3.点击右侧加号，添加我们自定义的快捷操作： 4.选中Template Group,新建custom分组，再新建Live Template 5.配置相关规则 Abbreviation: 我们填写logger, 只要页面键入logger就会出现提示，回车后就可自动生成Logger对象。 Description:填写说明，便于查看具体功能； Teamplate Text: private static final Logger LOGGER = LoggerFactory.getLogger($CLASS$.class); 6.配置应用的对象，我么选择最下面的No applicable contexts yet. Define, 选择java 7.Class文件中输入logger然后出现提示，回车即可生成Logger对象。","tags":[{"name":"Tools","slug":"Tools","permalink":"https://cnkeep.github.io/tags/Tools/"}]},{"title":"windows激活","date":"2017-08-04T16:49:00.000Z","path":"2017/08/05/003-windows激活/","text":"windows激活系统安装完毕后，首先以管理员身份打开CMD命令行窗口，按下Win+X，选择命令提示符(管理员)。说明：kms.xspace.in是kms服务器地址，可能会失效，如果激活失败，可以自行搜索kms服务器地址，将kms.xspace.in替换成新的地址即可，比如换成kms.03k.org123456789win10专业版用户请依次输入：slmgr /ipk W269N-WFGWX-YVC9B-4J6C9-T83GXslmgr /skms kms.xspace.inslmgr /atowin10企业版用户请依次输入：slmgr /ipk NPPR9-FWDCX-D2C8J-H872K-2YT43slmgr /skms kms.xspace.inslmgr /ato 网上搜了一大堆。一点作用没有。结果看到这句话 换了一下还真成功了~将kms.xspace.in替换成新的地址即可，比如换成kms.03k.org 查看到期时间：slmgr.vbs -xpr 来自 https://tieba.baidu.com/p/5592942485?red_tag=0307692371&amp;traceid=","tags":[{"name":"Tools","slug":"Tools","permalink":"https://cnkeep.github.io/tags/Tools/"}]},{"title":"几个github高效插件","date":"2017-08-04T14:31:00.000Z","path":"2017/08/04/008-几个github高效插件/","text":"几个github高效插件前言作为一个程序员相信你一定知道而且经常使用github, 但是我们经常会有这样的尴尬： 怎么样直接在项目中搜索关键字啊 我能直接查看项目的结构吗 我能直接像在IDE中那样点击跳转到对应的文件中吗 我可以告诉大家，这些都可以，接下来讲给大家推荐几款优秀的github插件(躲开，我要开始装逼了)！ 本文介绍的插件均属于chrome插件，并且默认大家可以访问外网(插件搜索安装需要外网访问) 插件项目目录左侧树形展示(Octotree)Octotree插件让你直接可以查看项目的目录结构，而且支持选中文件直接跳转，有没有IDE的一点味道了。 安装完成后点击进入任意一个项目，就会发现浏览器左侧多一个按钮，点击或者鼠标放置就会出现树形结构 类名点击直接跳转(OctoLinker)OctoLinker让你像使用IDE一样的实现类名点击跳转。 按住Ctrl键，鼠标移动到类名上就会出现跳转提示，点击跳转即可完成跳转。 项目搜索(Sourcegraph)Sourcegraph支持项目中变量搜索 彩蛋 这里再为大家推荐几款笔者使用的插件 护眼助手: 眼镜是心灵的窗口，此插件让我们的网页的颜色变为暖色系，保护视力 JSON-handle: 漂亮的json数据查看插件 crxMouse: 浏览器鼠标手势玩起来，随便滑动前进后退，上翻下翻，不用再点击鼠标和滚轮了 Chrome清洁剂: 一键清理浏览器缓存，下载文件 SetupVPN - Lifetime Free:chrome免费的翻墙插件，YouTube也能玩，之前用的是谷歌访问助手，但是在笔者电脑上有问题，所以换了，其实访问助手真的很不错的 有道词典Chrome划词插件: 划词翻译，英语差的也能读懂文档了 Infinity: 好看，好玩，又实用的标签页插件","tags":[{"name":"Tools","slug":"Tools","permalink":"https://cnkeep.github.io/tags/Tools/"}]},{"title":"eclipse中maven项目jar包不会自动下载解决办法","date":"2017-08-03T18:45:00.000Z","path":"2017/08/04/004-eclipse中maven项目jar包不会自动下载解决办法/","text":"eclipse中maven项目jar包不会自动下载解决办法 Eclipse中maven从远程仓库中下载jar包有时会很慢，有些甚至进度停止不动，这个时候我们可能会终止当前下载，但是终止jar包下载后会出现一个问题，再次打开Eclipse时，你会发现提示你项目中依赖的jar包找不到. 如下图所示，项目右键打—》Build Path—》Configure Build Path 打开项目的 Java Build Path 在 Libraries 页签下Maven Dependenicies 你会发现报错提示 依赖的jar包 missing如下图所示 此时我们可以通过如下方案解决: 找到我们的本地maven仓库目录 我的是 H:\\Java\\maven\\Repository 搜索出该目录下的*lastUpdated.properties文件并删除，如下图所示，可以通过模糊搜索匹配出这样的文件 Maven 更新当前项目，maven就会继续下载缺失的依赖jar包，直至缺失jar包下载完成，上述问题就解决了。 自动删除脚本 1234567891011# 1. 新建clean.bat# 2. 输入以下内容，修改REPOSITORY_PATH为自己的本地仓库路径# 3. 执行脚本set REPOSITORY_PATH=E:\\maven\\reporem 正在搜索...for /f &quot;delims=&quot; %%i in (&apos;dir /b /s &quot;%REPOSITORY_PATH%\\*lastUpdated&quot;&apos;) do ( del /s /q %%i)rem 搜索完毕pause","tags":[{"name":"Tools","slug":"Tools","permalink":"https://cnkeep.github.io/tags/Tools/"}]}]